@INPROCEEDINGS{10440949,
  author={Swain, Abhipsa and Panda, Sanjaya Kumar and Sathua, Sujaya Kumar},
  booktitle={2023 IEEE 20th India Council International Conference (INDICON)}, 
  title={An Efficient Physiological Record System Using Osmotic Computing Paradigm}, 
  year={2023},
  volume={},
  number={},
  pages={1030-1035},
  abstract={The rapid surge in digitalization necessitates the seamless integration of a multitude of technologies, including the Internet of Things (IoT), edge computing, cloud computing, artificial intelligence (AI), machine learning and others. Many providers now offer some of these technologies on a unified platform, making them easily accessible to users. The convergence of IoT, edge computing, and cloud computing gives rise to an innovative paradigm, osmotic computing. Osmotic computing has the potential to tackle various challenges related to resource allocation, latency, scalability, migration, and other aspects of computing. It is relevant in scenarios related to hospitals, disasters, and transportation that necessitate real-time solutions. In particular, creating, updating, retrieving, and maintaining hospital records pose significant challenges and require in-depth exploration with the latest technologies to ensure the safety and well-being of individuals. This paper introduces an efficient physiological record system that leverages the osmotic computing paradigm. The system manages the records of a vast number of patients and facilitates access to these records by various stakeholders, including doctors, government agencies, insurance companies, and others, as and when the need arises. Finally, this paper highlights the challenges related to the physiological record system within the framework of osmotic computing.},
  keywords={Cloud computing;Hospitals;Transportation;Physiology;Internet of Things;Surges;Edge computing;Osmotic Computing;Internet of Things;Edge Computing;Cloud Computing;Physiological Record System;Osmotic Membrane;Osmotic Orchestrator},
  doi={10.1109/INDICON59947.2023.10440949},
  ISSN={2325-9418},
  month={Dec},}@INPROCEEDINGS{10437143,
  author={Maia, Adyson Magalhães and Ghamri-Doudane, Yacine},
  booktitle={GLOBECOM 2023 - 2023 IEEE Global Communications Conference}, 
  title={A Deep Reinforcement Learning Approach for the Placement of Scalable Microservices in the Edge-to-Cloud Continuum}, 
  year={2023},
  volume={},
  number={},
  pages={479-485},
  abstract={The recent proliferation of computing paradigms, and among them the more prominent ones at the two endpoints of the network infrastructure, i.e. the edge and the cloud, paves the way for an edge-to-cloud continuum of resources and services that is able to meet the stringent Quality of Service (QoS) requirements of emerging applications. However, deploying modern microservice-based applications on such highly distributed and heterogeneous edge-to-cloud infrastructure is a complex challenge to be addressed. To overcome this challenge, we jointly investigate the placement and load distribution problems for applications composed of dependent microservices that can be deployed and scaled across the continuum. Furthermore, we propose a Deep Reinforcement Learning (DRL) based solution for solving this joint problem and we demonstrate through simulations that our proposal outperforms baseline methods in terms of QoS satisfaction and deployment cost.},
  keywords={Costs;Microservice architectures;Quality of service;Deep reinforcement learning;Proposals;Global communication;Load modeling;edge-to-cloud continuum;microservice placement;load distribution;deep reinforcement learning},
  doi={10.1109/GLOBECOM54140.2023.10437143},
  ISSN={2576-6813},
  month={Dec},}@INPROCEEDINGS{10436967,
  author={Dutta, Joy and Puthal, Deepak and Yeun, Chan Yeob},
  booktitle={GLOBECOM 2023 - 2023 IEEE Global Communications Conference}, 
  title={Next Generation Healthcare with Explainable AI: IoMT-Edge-Cloud Based Advanced eHealth}, 
  year={2023},
  volume={},
  number={},
  pages={7327-7332},
  abstract={This article provides in-depth experimental studies of XAI (EXplainable Artificial Intelligence) in the IoT-Edge-Cloud continuum. Within the different available XAI frameworks, such as Local Interpretable Model-Agnostic Explanations (LIME) and SHapley Additive exPlanations (SHAP) frameworks are utilized here as they are the most suitable feature map-based, model-agnostic, posthoc frameworks that match our requirements for getting real-time prediction explanations in the healthcare domain. In order to evaluate LIME and SHAP in this continuum and to make black box AI (BBAI)-based decisions interpretable, we have considered the real-world electronic health record (EHR)-based large cloud database (which could be a very large database–VLDB) and IoMT based real-time streams as edge databases for the prediction of cardiac arrest in the real-world. We have also verified the effectiveness of automated counterfactual explanations in this context for taking remedial actions. Thus, our proposed model is capable of making significant advancements in the healthcare industry by offering conscious healthcare monitoring automation along with an AI-based self-explanatory system that serves as a personalized health assistant for individuals, paving the way for the next major upgrade in healthcare.},
  keywords={Explainable AI;Databases;Medical services;Transforms;Predictive models;Real-time systems;Next generation networking;IoMT;XAI;Interpretability;counterfactuals;Edge Computing;Cloud Computing;eHealth},
  doi={10.1109/GLOBECOM54140.2023.10436967},
  ISSN={2576-6813},
  month={Dec},}@INPROCEEDINGS{10430653,
  author={Mishra, Sambit Kumar and Cherukuri, Chandan and Dheeraj, Pavuluri Venkata and Puthal, Deepak},
  booktitle={2023 OITS International Conference on Information Technology (OCIT)}, 
  title={A Hybrid Encryption Approach using DNA-Based Shift Protected Algorithm and AES for Edge-Cloud System Security}, 
  year={2023},
  volume={},
  number={},
  pages={781-786},
  abstract={The modern applications, such as smart cities, connected homes, and crisis management systems, has driven the emergence of the edge-cloud continuum to enable data processing to occur closer to the source, reducing latency and enhancing data processing efficiency. However, due to the distributed nature of edge nodes and cloud environments, data security remains a critical concern. Malicious actors may intercept or eavesdrop on communication channels between edge devices and the cloud. DNA computing, a groundbreaking security concept inspired by biological DNA, offers a promising solution to address these security challenges. This paper proposes a DNA-based cryptographic method for secure data transfer and communication in edge-cloud computing environments. The research also examines into various data security threats in the edge-cloud continuum and explores potential countermeasures.},
  keywords={Data privacy;Smart cities;DNA;Data transfer;Encryption;Information technology;DNA computing;Cloud computing;Encryption;DNA-based Encryption;Edge computing;Security},
  doi={10.1109/OCIT59427.2023.10430653},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10430671,
  author={Bhoi, Sourav Kumar},
  booktitle={2023 OITS International Conference on Information Technology (OCIT)}, 
  title={Sand Dune Computing (SDC): A New Framework for Efficient Execution of User Requests to Support Device-Server Model}, 
  year={2023},
  volume={},
  number={},
  pages={226-230},
  abstract={In the current world of computing, due to tremendous rise of smart devices all over the world it is difficult to get quick service from the limited servers in the heterogeneous environment as some servers are highly loaded with device requests. So, there should be a model or framework to analyze the requests and server traffic in the device-server model with some solution that can execute the device tasks very efficiently. Sand Dune Computing (SDC) is a new computing framework proposed whose main architecture is mainly motivated from a natural process in the environment that is formation of Sand Dunes in areas where the sand grains or smaller loose particles of sands are blown by wind, and accumulated as a temporary hill like structure called as Dune. Here, in the SDC architecture the Sand Grains are mainly considered as the device requests from multiple smart devices to get service from the servers, where server with more traffic is considered as the Sand Dune where the waited device requests are queued. Wind is assumed as the rate of requests from the smart devices. This architecture of SDC will help the current generation technologies or systems such as Internet of Things, cloud computing, edge/fog computing, osmotic computing, ad hoc and sensor networks, distributed computing, AI, etc. to analyze the device requests and server loads based on Sand Area, Dune Area, Dune Size, Dune Frequency, Wind Speed, and Wind Frequency. Also, in this paper some applications of SDC and research challenges are discussed.},
  keywords={Cloud computing;Wind speed;Computational modeling;Computer architecture;Servers;Smart devices;Load modeling;Sand Dune Computing;SDC;Device;Server;Device-Server Model;Request Traffic},
  doi={10.1109/OCIT59427.2023.10430671},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10419237,
  author={Marcelino, Cynthia and Nastic, Stefan},
  booktitle={2023 IEEE/ACM Symposium on Edge Computing (SEC)}, 
  title={CWASI: A WebAssembly Runtime Shim for Inter-Function Communication in the Serverless Edge-Cloud Continuum}, 
  year={2023},
  volume={},
  number={},
  pages={158-170},
  abstract={Serverless Computing brings advantages to the Edge-Cloud contin-uum, like simplified programming and infrastructure management. In composed workflows, where serverless functions need to exchange data constantly, serverless platforms rely on remote services such as object storage and key-value stores as a common approach to exchange data. In WebAssembly, functions leverage WebAssembly System Interface to connect to the network and exchange data via remote services. As a consequence, co-located serverless functions need remote services to exchange data, increasing latency and adding network overhead. To mitigate this problem, in this paper, we intro-duce CWASI: a WebAssembly OCI-compliant runtime shim that determines the best inter-function data exchange approach based on the serverless function locality. CWASI introduces a three-mode communication model for the Serverless Edge-Cloud continuum. This communication model enables CWASI Shim to optimize inter-function communication for co-located functions by leveraging the function host mechanisms. Experimental results show that CWASI reduces the communication latency between the co-located serverless functions by up to 95% and increases the communication throughput by up to 30x.},
  keywords={Runtime;Serverless computing;Programming;Throughput;Edge computing;WebAssemly;Inter-function;Edge-Cloud Continuum;Serverless;Shim},
  doi={10.1145/3583740.3626611},
  ISSN={2837-4827},
  month={Dec},}@INPROCEEDINGS{10383752,
  author={Miloradović, Branko and Papadopoulos, Alessandro Vittorio},
  booktitle={2023 62nd IEEE Conference on Decision and Control (CDC)}, 
  title={Multi-Criteria Optimization of Application Offloading in the Edge-to-Cloud Continuum}, 
  year={2023},
  volume={},
  number={},
  pages={4917-4923},
  abstract={Applications are becoming increasingly data-intensive, requiring significant computational resources to meet their demand. Cloud-based services are insufficient to meet such demand, leading to a shift of the computation towards the devices closer to the edge of the network, leading to the emergence of an Edge-to-Cloud computing Continuum (E2C). An application can offload part of its computation toward the E2C. The allocation of applications to a set of available computing nodes is a challenging problem, as the allocation needs to take into account several factors, including the application requirements and demands as well as the optimization of the resource utilization in the E2C infrastructure and the minimization the CO2 footprint of the executed applications. Control and optimization techniques provide a vast array of tools for optimizing the Edge-to-Cloud continuum's management. This paper provides a mathematical formulation for the application offloading with specific requirements in the cloud computing domain. The problem is modeled as integer linear programming and constraint programming models and implemented in commercially available software. Finally, we provide the results of performed comparison between the two models.},
  keywords={Performance evaluation;Cloud computing;Computational modeling;Minimization;Mathematical models;Software;Regulation},
  doi={10.1109/CDC49753.2023.10383752},
  ISSN={2576-2370},
  month={Dec},}@INPROCEEDINGS{10377703,
  author={Ancilotto, Alberto and Paissan, Francesco and Farella, Elisabetta},
  booktitle={2023 IEEE/CVF International Conference on Computer Vision (ICCV)}, 
  title={XiNet: Efficient Neural Networks for tinyML}, 
  year={2023},
  volume={},
  number={},
  pages={16922-16931},
  abstract={The recent interest in the edge-to-cloud continuum paradigm has emphasized the need for simple and scalable architectures to deliver optimal performance on computationally constrained devices. However, resource-efficient neural networks usually optimize for parameter count and thus use operators such as depthwise convolutions, which do not maximally exploit the efficiency of resource-constrained devices. In this article, we propose XiNet, a novel convolutional neural architecture that targets edge devices. We derived the XiNet architecture from an extensive real-world efficiency analysis of various neural network operators (e.g., standard, depthwise, and pointwise convolutions). Compared to other mobile architectures, our approach substantially improves the performance-complexity trade-off by optimizing the number of operations, parameters, and working memory (RAM). Moreover, we show how XiNet can be easily adapted to different devices thanks to Hardware Aware Scaling (HAS), which enables disjoint optimization of RAM, FLASH, and operations count. We analyze the scaling properties of our architecture under different hardware constraints and validate it on the image classification task. Finally, we evaluate the performance of XiNet for object detection on the MS-COCO and VOC-2012 benchmarks and compare it with state-of-the-art mobile neural networks, achieving a 70% reduction in energy requirements with similar performance.},
  keywords={Performance evaluation;Scalability;Neural networks;Random access memory;Computer architecture;Object detection;Hardware},
  doi={10.1109/ICCV51070.2023.01556},
  ISSN={2380-7504},
  month={Oct},}@INPROCEEDINGS{10380819,
  author={Martino, Beniamino Di and Pezzullo, Gennaro Junior and Beggiato, Claudio},
  booktitle={2023 IEEE International Workshop on Technologies for Defense and Security (TechDefense)}, 
  title={Towards optimized Design and Deployment of a Military Supply Chain on Federated Cloud Continuum supported by simulation-based Performance Evaluation}, 
  year={2023},
  volume={},
  number={},
  pages={423-428},
  abstract={This research, situated within the military context, primarily aims to design and subsequently simulate a collaborative supply chain. In this document, we will analyze the initial part of the work: the design. To achieve this, the first step involves creating a logical structure that provides insights into how various actors in the supply chain should operate. Following this foundation, an architectural model will be developed that can map the individual operations of the actors into components. Only then a porting across the cloud continuum will be conducted, from the core to the edge, identifying the necessary patterns to integrate the entire infrastructure within this environment, thus achieving a cloud federation. These stages are essential as preparatory work for the upcoming research phase. The ultimate goal, to be pursued in the future, is to simulate the entire system based on the proposed cloud federation architecture},
  keywords={Performance evaluation;Conferences;Supply chains;Collaboration;Security},
  doi={10.1109/TechDefense59795.2023.10380819},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10380886,
  author={Gribaudo, Marco and Iacono, Mauro and Levis, Alexander H.},
  booktitle={2023 IEEE International Workshop on Technologies for Defense and Security (TechDefense)}, 
  title={Evaluating defense services performance on military cloud continuum systems}, 
  year={2023},
  volume={},
  number={},
  pages={406-411},
  abstract={A Battlefield Management System (BMS) is a tactical Command and Control system which supports military operations on the battlefield to provide a continuous and coherent representation of the state of a tactical scenario. The implementation of a BMS may benefit from the possibilities offered by Cloud Continuum technologies, while considering the security requirements when exploiting their infrastructure. Cloud Continuum may be used in place of the existing solutions, provided that proper performance evaluation techniques are available to assess its effectiveness and account for the impact of security constraints.In this paper we propose a modeling approach for a Battlefield Management System based on Cloud Continuum technologies and a performance evaluation framework to support its design and management before and during a mission.},
  keywords={Performance evaluation;Command and control systems;Conferences;Security},
  doi={10.1109/TechDefense59795.2023.10380886},
  ISSN={},
  month={Nov},}@ARTICLE{10373409,
  author={Gigli, Lorenzo and Zyrianoff, Ivan and Zonzini, Federica and Bogomolov, Denis and Testoni, Nicola and Felice, Marco Di and De Marchi, Luca and Augugliaro, Giuseppe and Mennuti, Canio and Marzani, Alessandro},
  journal={IEEE Transactions on Industrial Informatics}, 
  title={Next Generation Edge-Cloud Continuum Architecture for Structural Health Monitoring}, 
  year={2023},
  volume={},
  number={},
  pages={1-14},
  abstract={Assessing the integrity of industrial and civil appliances has become a priority worldwide. Noteworthy, this goal requires a strong synergy between multiple tools, disciplines, and approaches to be attained via a joint hardware-software co-design of the different Structural Health Monitoring (SHM) system components. This work proposes the $\sf{MAC4PRO}$ architecture, a sensor-to-cloud monitoring platform that seamlessly integrates sensing and software technologies for accurate data measurement, transmission, and analysis. The developed solution stands out for its interoperability and versatility, making it a promising candidate for integration in the next generation of smart structures. Our platform was validated during extensive experimental campaigns targeted at various industrial scenarios. The results show that the $\sf{MAC4PRO}$ architecture can identify subtle changes, such as 1mm size leakage events in pipeline circuits, or less than 1% frequency drifts in civil buildings after seismic excitation, while ensuring more than 90% reduction in the edge-to-cloud data transfer process.},
  keywords={Computer architecture;Monitoring;Sensors;Cloud computing;Software;Vibrations;Next generation networking;Edge-cloud continuum;Internet of Things;interoperability;structural health monitoring},
  doi={10.1109/TII.2023.3337391},
  ISSN={1941-0050},
  month={},}@INPROCEEDINGS{10361369,
  author={Mishra, Sambit Kumar and Sanisetty, Mohana Lasya and Shaik, Apsareena Zulekha and Thotakura, Sai Likitha and Aluru, Sai Likhita and Puthal, Deepak},
  booktitle={2023 IEEE Intl Conf on Dependable, Autonomic and Secure Computing, Intl Conf on Pervasive Intelligence and Computing, Intl Conf on Cloud and Big Data Computing, Intl Conf on Cyber Science and Technology Congress (DASC/PiCom/CBDCom/CyberSciTech)}, 
  title={LiDAR-based Building Damage Detection in Edge-Cloud Continuum}, 
  year={2023},
  volume={},
  number={},
  pages={0252-0257},
  abstract={In recent years, natural disasters such as earth-quakes and hurricanes have caused significant damage to buildings and infrastructure worldwide. As a result, there has been an increasing demand for efficient and accurate methods of assessing the extent of building damage to facilitate effective recovery efforts. One emerging technology that shows great promise in this area is Light Detection and Ranging (Li-DAR). Therefore, this paper proposes a novel detection framework utilizing textural feature extraction strategies for Li-DAR-based building damage detection. Li-DAR, a remote sensing technology, has ability to create detailed maps of buildings and other infrastructure, allowing for precise identification and measurement of damage caused by natural disasters. Integration of the popular paradigm Edge cloud continuum extends cloud's capabilities to the edge of the network, enabling more effective post-disaster recovery efforts. Smart Li-DAR sensors pre-process the captured data and send it to the nearest edge device for further processing.. Inclusion of machine learning algorithms like K-means clustering algorithm here is used to classify the buildings into damaged and undamaged classes by analyzing the extracted textural features. The scheme can detect various types of building damage. The cloud server is utilized to store the processed maps. The integration of the Edge-Cloud Continuum (ECC) has added more value by reducing the network usage, and latency of the Li-DAR-based building damage detection system. ECC enables processing and analysis of data at the point of origin as well as large-scale data processing and storage in cloud-based systems. This proposed framework has shown promising results in preliminary experiments and has the potential to revolutionize post-disaster recovery efforts by providing efficient building damage maps.},
  keywords={Deep learning;Satellites;Machine learning algorithms;Image edge detection;Buildings;Optical computing;Feature extraction;Light Detection and Ranging (Li-DAR);Building Damage Detection;K-means Clustering;Edge-cloud Continuum;Network usage;Latency;Post disaster recovery},
  doi={10.1109/DASC/PiCom/CBDCom/Cy59711.2023.10361369},
  ISSN={2837-0740},
  month={Nov},}@INPROCEEDINGS{10355630,
  author={Le-Tuan, Anh and Bowden, David and Le-Phuoc, Danh},
  booktitle={2023 IEEE 31st International Conference on Network Protocols (ICNP)}, 
  title={Semantic Programming for Device-Edge-Cloud Continuum}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={This position paper presents ThothSP, a Semantic Programming framework with the aim of lowering the coding effort in building smart applications on the Device-Edge-Cloud continuum by leveraging semantic knowledge. It introduces a novel neural-symbolic stream fusion mechanism, which enables the specification of data fusion pipelines via declarative rules, with degrees of learnable probabilistic weights. Moreover, it includes an adaptive federator that allows the Thoth⊳runtime to be distributed across multiple compute nodes in a network, and to coordinate their resources to collaboratively process tasks by delegating partial workloads to their peers. To demonstrate ThothSP's capability, we report a case study on a distributed camera network to show ThothSP's behaviour against a traditional edge-cloud setup.},
  keywords={Protocols;Semantics;Pipelines;Data integration;Programming;Probabilistic logic;Cameras;edge computing;autonomous system;distributed AI;semantic computing},
  doi={10.1109/ICNP59255.2023.10355630},
  ISSN={2643-3303},
  month={Oct},}@INPROCEEDINGS{10355613,
  author={Ahearne, Sean and Khalid, Ahmed and Ron, Martin and Burget, Pavel},
  booktitle={2023 IEEE 31st International Conference on Network Protocols (ICNP)}, 
  title={An AI Factory Digital Twin Deployed Within a High Performance Edge Architecture}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={The exponential proliferation of big data and computation-intensive tasks, such as Artificial Intelligence (AI) applications in factories, poses a significant challenge for the current datacenter-focused technological architecture. The “Big data pRocessing and Artificial Intelligence at the Network Edge” (BRAINE) project addresses this problem by introducing an innovative system architecture designed explicitly for compute-intensive edge deployments. BRAINE focuses on decentralizing the computation tasks, enabling a significant reduction in latency, and optimizing the placement of applications within a cloud-edge continuum to ensure optimal operational efficiency. This paper presents the design, implementation, and testing of our novel system architecture in the context of an AI digital twin for factory robotics. Our empirical results indicate substantial improvements in performance metrics such as processing speed and latency compared to traditional architectures and approaches.},
  keywords={Measurement;Service robots;Systems architecture;Computer architecture;Big Data;Production facilities;Digital twins;Edge;AI/ML;Latency;Motif Discovery;multi-agent systems;digital twin},
  doi={10.1109/ICNP59255.2023.10355613},
  ISSN={2643-3303},
  month={Oct},}@INPROCEEDINGS{10355594,
  author={Nanos, Anastasios and Kretsis, Aristotelis and Mainas, Charalampos and Ntouskos, George and Ferikoglou, Aggelos and Danopoulos, Dimitrios and Kokkinis, Argyris and Masouros, Dimosthenis and Siozios, Kostas and Soumplis, Polyzois and Kokkinos, Panagiotis and Olmos, Juan Jose Vegas and Varvarigos, Emmanouel},
  booktitle={2023 IEEE 31st International Conference on Network Protocols (ICNP)}, 
  title={Hardware-Accelerated FaaS for the Edge-Cloud Continuum}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={We present an end-to-end solution to facilitate the seamless execution of hardware-accelerated compute-intensive tasks on heterogeneous hardware platforms spanning the Cloud-Edge continuum. Our approach includes a programming interface, orchestration, application management components, the vAccel framework, and a library of hardware-accelerated kernels. These components enable a Function-as-a-Service (FaaS) based operational flow that supports numerous diverse use cases while minimizing the time required for the developer to integrate their code and for the vendor to provide hardware acceleration capabilities to end users. Experimental results showcase the merits of our approach.},
  keywords={Protocols;Serverless computing;Full stack;Focusing;Programming;Libraries;Kernel;Cloud-Edge Continuum;Serverless;Function-as-a-Service;Hardware Acceleration},
  doi={10.1109/ICNP59255.2023.10355594},
  ISSN={2643-3303},
  month={Oct},}@INPROCEEDINGS{10355606,
  author={Murphy, Seán Óg and Roedig, Utz and Sreenan, Cormac J. and Khalid, Ahmed},
  booktitle={2023 IEEE 31st International Conference on Network Protocols (ICNP)}, 
  title={Towards Trust-Based Data Weighting in Machine Learning}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={In distributed environments, data for Machine Learning (ML) applications may be generated from numerous sources and devices, and traverse a cloud-edge continuum via a variety of protocols, using multiple security schemes and equipment types. While ML models typically benefit from using large training sets, not all data can be equally trusted. In this work, we examine data trust as a factor in creating ML models, and explore an approach using annotated trust metadata to contribute to data weighting in generating ML models. We assess the feasibility of this approach using well-known datasets for both linear regression and classification problems, demonstrating the benefit of including trust as a factor when using heterogeneous datasets. We discuss the potential benefits of this approach, and the opportunity it presents for improved data utilisation and processing.},
  keywords={Training;Solid modeling;Protocols;Computational modeling;Soft sensors;Linear regression;Machine learning;edge computing;machine learning;data confidence fabric;linear regression;clustering;data weighting},
  doi={10.1109/ICNP59255.2023.10355606},
  ISSN={2643-3303},
  month={Oct},}@INPROCEEDINGS{10355592,
  author={Caron, Eric and Gracia-Tinedo, Raúl},
  booktitle={2023 IEEE 31st International Conference on Network Protocols (ICNP)}, 
  title={The Nanoservices Framework: Co-Locating Microservices in the Cloud-Edge Continuum}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={Today, the microservices paradigm has emerged as one of the most widely adopted patterns to develop, package, and deploy software on a large scale. However, as they were originally designed for the cloud, the direct application of microservices DevOps practices to resource-constrained environments like the Edge may not be optimal. Specifically, deploying each piece of software as an individual microservice may result in a significant resource footprint (e.g., storage space and network bandwidth related to managing base images, CPU, and memory). In this work, we explore the concept of opportunistically grouping microservice code within the same container to reduce resource footprint when deploying multiple microservices at the Edge. To materialize this concept, we present the N anoservices framework: a framework that formalizes and provides practical means for developers to build and deploy groups of microservices on the same container (a.k.a., Nanoservices). Our early results show that with Nanoservices we can achieve a significant resource footprint reduction (base image storage, CPU, memory) with minimal effort from the developer's viewpoint.},
  keywords={Protocols;Codes;Image edge detection;Microservice architectures;Bandwidth;Containers;Software;Microservices;Edge;DevOps;Containers},
  doi={10.1109/ICNP59255.2023.10355592},
  ISSN={2643-3303},
  month={Oct},}@INBOOK{10364623,
  author={},
  booktitle={Cloud and Edge Networking}, 
  title={The Cloud Continuum}, 
  year={2023},
  volume={},
  number={},
  pages={19-30},
  abstract={The Cloud Continuum refers to the continuity in the types of Clouds that can be set up. The Cloud Core can be divided into two types of data centers: hyperscalers and core data centers. Core data centers are large, more traditional data centers with several hundred to several hundred thousand servers. The embedded data center can embed an intelligent processor that accelerates artificial intelligence processes in the algorithmics of complex systems. The digitization of companies aims to produce new values in the world of production, in business models, in business software and more globally in the internal capabilities of companies to support new business processes. The big web companies were the first to set up a high&#x2010;level digital infrastructure with a vision of the Cloud Continuum. They started with large Cloud or hyperscale data centers and then started to develop Edges especially in the enterprise context.},
  keywords={Data centers;Cloud computing;Virtual machining;Companies;5G mobile communication;Business;Wireless fidelity},
  doi={10.1002/9781394257461.ch2},
  ISSN={},
  publisher={Wiley},
  isbn={9781394257447},
  url={https://ieeexplore.ieee.org/document/10364623},}@INBOOK{10364613,
  author={},
  booktitle={Cloud and Edge Networking}, 
  title={Cloud Continuum in Vehicular Networks}, 
  year={2023},
  volume={},
  number={},
  pages={181-197},
  abstract={Vehicular networks are a rapidly developing environment. The transition to reality is close and will become a reality with the autonomy of vehicles that will need to interconnect to talk to each other and make decisions together. Intelligent Transport Systems encompass a wide variety of solutions to achieve vehicle&#x2010;to&#x2010;vehicle communications. These solutions are designed to increase travel safety, minimize environmental impact, improve traffic management and, more generally, optimize travel. Vehicle&#x2010;to&#x2010;Vehicle or Vehicle&#x2010;to&#x2010;Infrastructure are appropriate solutions to manage safety elements in the vehicle domain. Light is another means of communication that is very useful in vehicular networks: between two cars following each other, there is no obstacle that would stop the light. The chapter looks at the characteristics of these networks, which are called VLCs, and one of the major products is Li&#x2010;Fi.},
  keywords={Safety;5G mobile communication;Standards;Wireless fidelity;Servers;Radar;Vehicular ad hoc networks},
  doi={10.1002/9781394257461.ch11},
  ISSN={},
  publisher={Wiley},
  isbn={9781394257447},
  url={https://ieeexplore.ieee.org/document/10364613},}@INBOOK{10364618,
  author={},
  booktitle={Cloud and Edge Networking}, 
  title={The Cloud Continuum and Industry 4.0}, 
  year={2023},
  volume={},
  number={},
  pages={199-209},
  abstract={Transformations in the industrial world happen in spurts when a new revolutionary solution comes along. The revolution brought about by Industry 4.0 comes from the mutations due to digital technology. Industry 4.0 relies on intelligent controls capable of reacting in millisecond timeframes. To meet the challenges imposed by the demands of Industry 4.0 applications, technology innovations are needed in many aspects of network design, from the physical layer and protocols to resource management. While some Industry 4.0 applications such as cloud&#x2010;associated robotics or machine tool control simultaneously require low latency and high reliability, other Industry 4.0 applications rely primarily on low&#x2010;latency communication where security may be of a lower order. Embedded Edge solutions are also capable of addressing the challenges posed by Industry 4.0 through the presence of embedded data centers in machines located on the endpoint of the Edge located in the machine tools themselves.},
  keywords={Fourth Industrial Revolution;5G mobile communication;Real-time systems;Cloud computing;Reliability;Quality of service;Time factors},
  doi={10.1002/9781394257461.ch12},
  ISSN={},
  publisher={Wiley},
  isbn={9781394257447},
  url={https://ieeexplore.ieee.org/document/10364618},}@INBOOK{10364607,
  author={},
  booktitle={Cloud and Edge Networking}, 
  title={Edge and Cloud Networking in the IoT}, 
  year={2023},
  volume={},
  number={},
  pages={155-180},
  abstract={Telecommunications operators are particularly interested in the Internet of Things (IoT). This chapter examines the different categories of networks for the IoT. LPWANs (Low Power Wide Area Networks) are a generation of networks for the IoT that started in the early 2010s and aim to connect objects over long distances with very low energy consumption. One could classify operator networks as LPWANs, but they are quite different because they are specified completely by 3GPP and are integrated directly into operator technologies. This chapter deals with the Bluetooth network, which almost became the standard for Personal Area Networks after an initial specification by the IEEE 802.15 working group that deals with the standardization of this category of networks. The data streams coming from the objects are processed in the Cloud Continuum on the data center that is best able to handle the constraints of the application.},
  keywords={Cloud computing;Data centers;Throughput;Telecommunications;Streams;Sensors;Low-power wide area networks},
  doi={10.1002/9781394257461.ch10},
  ISSN={},
  publisher={Wiley},
  isbn={9781394257447},
  url={https://ieeexplore.ieee.org/document/10364607},}@INBOOK{10364611,
  author={},
  booktitle={Cloud and Edge Networking}, 
  title={The Future of Edge and Cloud Networking}, 
  year={2023},
  volume={},
  number={},
  pages={267-281},
  abstract={The future of Edge and Cloud Networking can be imagined through the research done for 6G. The years 2020&#x2010;2024 will be mainly devoted to the different possible ways to achieve a new generation. The networks that enable Cloud Continuum belong to the different categories of 5G or 6G and Wi&#x2010;Fi. The private 6G associated with Wi&#x2010;Fi could become preponderant with the slices of the telecom operators. The 5G revolution is represented by the appearance of data centers on the Edge: Multi&#x2010;access Edge Computing (MEC) data centers. 5G&#x2010;Advanced offers strong virtualization as all functions will be virtualized in the MEC data center. Femto data centers can also be connected to each other by a vertical 5G or 6G, also called 5G or 6G infrastructure. The services offered by the boxes depend on the virtual machines that are positioned there, such as distributed databases, geolocation, voice and video, push to talk, blockchain, etc.},
  keywords={5G mobile communication;Data centers;Antennas;6G mobile communication;Cloud computing;Wireless fidelity;Virtual machining},
  doi={10.1002/9781394257461.ch16},
  ISSN={},
  publisher={Wiley},
  isbn={9781394257447},
  url={https://ieeexplore.ieee.org/document/10364611},}@INPROCEEDINGS{10336191,
  author={Różańska, Marta and Horn, Geir},
  booktitle={2023 IEEE International Conference on Autonomic Computing and Self-Organizing Systems Companion (ACSOS-C)}, 
  title={Modelling Adaptive Autonomic Cloud Application Utility Using Template Functions}, 
  year={2023},
  volume={},
  number={},
  pages={134-139},
  abstract={Autonomic decisions are necessary for persistent Cloud application adaptation due to dynamic execution context and changing workload. However, it is often difficult to accurately model the utility to represent the application owner's preferences as a mathematical function linking the utility with the monitored information from the application. We propose a systematic approach for utility function modelling for adaptive applications in the Cloud continuum. This method exploits a set of utility function templates, automated quality checks, and the impact of measurements and performance indicators values on the utility value range. The method is evaluated with an illustrative example of a Cloud application that is compared to an existing manually modelled utility function.},
  keywords={Adaptation models;Systematics;Adaptive systems;Computational modeling;Stochastic processes;Data models;Mathematical models;utility function modelling;Cloud continuum optimization;autonomic Cloud application},
  doi={10.1109/ACSOS-C58168.2023.00053},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10336226,
  author={Nezami, Zeinab and Pournaras, Evangelos and Borzouie, Amir and Xu, Jie},
  booktitle={2023 IEEE International Conference on Autonomic Computing and Self-Organizing Systems Companion (ACSOS-C)}, 
  title={SMOTEC: An Edge Computing Testbed for Adaptive Smart Mobility Experimentation}, 
  year={2023},
  volume={},
  number={},
  pages={1-7},
  abstract={Smart mobility becomes paramount for meeting net-zero targets. However, autonomous, self-driving and electric vehicles require more than ever before an efficient, resilient and trustworthy computational offloading backbone that expands throughout the edge-to-cloud continuum. Utilizing on-demand heterogeneous computational resources for smart mobility is challenging and often cost-ineffective. This paper introduces SMOTEC, a novel open-source testbed for adaptive smart mobility experimentation with edge computing. SMOTEC provides for the first time a modular end-to-end instrumentation for prototyping and optimizing placement of intelligence services on edge devices such as augmented reality and real-time traffic monitoring. SMOTEC supports a plug-and-play Docker container integration of the SUMO simulator for urban mobility, Raspberry Pi edge devices communicating via ZeroMQ and EPOS for an AI-based decentralized load balancing across edge-to-cloud. All components are orchestrated by the K3s lightweight Kubernetes. A proof-of-concept of self-optimized service placements for traffic monitoring from Munich demonstrates in practice the applicability and cost-effectiveness of SMOTEC.},
  keywords={Instruments;Containers;Load management;Electric vehicles;Real-time systems;Computational efficiency;Distributed computing;Edge Computing;Smart Mobility Experimentation;Testbed;Dynamic Resource Allocation;Traffic Monitoring},
  doi={10.1109/ACSOS-C58168.2023.00021},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10336198,
  author={Baiardi, Martina and Ciatto, Giovanni and Pianini, Danilo},
  booktitle={2023 IEEE International Conference on Autonomic Computing and Self-Organizing Systems Companion (ACSOS-C)}, 
  title={Infrastructures for the Edge-Cloud Continuum on a Small Scale: A Practical Case Study}, 
  year={2023},
  volume={},
  number={},
  pages={128-133},
  abstract={The Edge-Cloud Continuum (ECC) is an emerging paradigm for the holistic exploitation of all sorts of hardware resources. Compared with traditional cloud computing, ECC is more flexible, as it can operate with heterogeneous devices. ECC is thus particularly well-suited for implementing a compute infrastructure in contexts where hardware provisioning is not continuous, and where the need for resource sharing is high. This is the case, for instance, of research groups willing to share their computational resources, differing in terms of capabilities, maintenance, and provisioning. However, designing a small-scale ECC infrastructure is not trivial, as there are many admissible architectures, design choices, and technological solutions. In this paper, we report the experience of building a flexible architecture, involving both virtual and bare metal nodes, where researches can smoothly and occasionally (un)plug their own machines, and where computational tasks are dynamically balanced considering the currently available resources.},
  keywords={Cloud computing;Architecture;Buildings;Metals;Computer architecture;Maintenance engineering;Hardware;Edge-cloud continuum;heterogeneous infrastructure;openness;scalability},
  doi={10.1109/ACSOS-C58168.2023.00052},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10336229,
  author={Van, Hoai My and da Silva, Alexandre Sawczuk and Knissel, Tim and Weiss, Gereon},
  booktitle={2023 IEEE International Conference on Autonomic Computing and Self-Organizing Systems Companion (ACSOS-C)}, 
  title={Self-Adaptive Service Deployment for Resilience of Smart Manufacturing Architectures}, 
  year={2023},
  volume={},
  number={},
  pages={146-151},
  abstract={Recent advances in the manufacturing sector - including edge-to-cloud continuum, machine learning, and digitalization - can enable smart manufacturing solutions, such as control optimization and predictive maintenance. One challenge in new system architectures is the efficient resource management under changing conditions while meeting process requirements, such as latency, when deploying software services. To address this, we propose an approach for self-adaptive service deployment that increases the resilience of smart manufacturing systems. We combine self-adaptation principles with run-time models - that describe the system in the form of the standardized Asset Administration Shell - to enable flexible software architectures for manufacturing. The proposed solution comprises the continuous adaptation of the service deployment in response to system changes, such as resource exhaustion or failure, to ensure an optimized operation. An evaluation of an example manufacturing use case shows that the proposed solution leads to lower execution latency and continuation of production in situations with low resources, e.g., through failures, compared to less flexible deployment approaches.},
  keywords={Production systems;Software architecture;Systems architecture;Computer architecture;Telecommunication traffic;Software;Resource management;Industrial Automation;Smart Manufacturing Architectures;Edge-to-Cloud Continuum;Self-Adaptation;Self-Description;MAPE-K;Asset Administration Shell},
  doi={10.1109/ACSOS-C58168.2023.00055},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10336202,
  author={Audrito, Giorgio and Martinelli, Alberto Riccardo and Torta, Gianluca},
  booktitle={2023 IEEE International Conference on Autonomic Computing and Self-Organizing Systems Companion (ACSOS-C)}, 
  title={Parallelising an Aggregate Programming Framework with Message-Passing Interface}, 
  year={2023},
  volume={},
  number={},
  pages={140-145},
  abstract={FCPP is an optimized C++ implementation of the Aggregate Programming (AP) paradigm for the implementation of distributed systems. Until now, it has been either deployed on networks of constrained far edge devices, or used for simulating AP systems on a single local computer. Recent work hints at a third possibility, namely adopting AP as a way to effectively program distributed algorithms, and execute them on a centralized high-performance hardware instead of a network of low-end computational nodes. This could also allow an integration of edge and cloud resources, where workload could be dynamically moved between the computational layers. In the present work, we describe the first extension of FCPP that supports the execution on a distributed network of high-end computational nodes (e.g., NUMA architectures, or small computer networks). The extension allows the mapping of a large simulation of a far edge system into such nodes basing on the MPI (Message-Passing Interface) standard, providing a first step towards an edge-cloud continuum for aggregate programs.},
  keywords={Aggregates;Computer architecture;C++ languages;Programming;Hardware;Computer networks;Distributed computing;distributed systems;programming languages;aggregate programming;high performance computing},
  doi={10.1109/ACSOS-C58168.2023.00054},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10329735,
  author={Basaras, Pavlos and Vasilopoulos, Emmanuel and Magklaris, Stratos and Katsaros, Konstantinos V. and Amditis, Angelos J.},
  booktitle={2023 IEEE Conference on Network Function Virtualization and Software Defined Networks (NFV-SDN)}, 
  title={Experimentally Assessing Deployment Tradeoffs for AI-enabled Video Analytics Services in the 5G Compute Continuum}, 
  year={2023},
  volume={},
  number={},
  pages={99-104},
  abstract={This article investigates the performance of video analytics services in a real industrial scenario, namely, a Port, using commercial grade cellular networks (5G, LTE-A, LTE) and a private cloud infrastructure. We create a virtual platform incorporating cloud and extreme/far-edge devices to host the work-load of AI services (e.g., object detection), and experimentally investigate deployment trade-offs in the 5G compute continuum, based on the criteria of service latency and bandwidth usage, inference accuracy, inference time and power consumption. Our experimental results demonstrate that private cloud computing benefits low-latency, high-performance apps, whereas far-edge processing (local offloading) can be used for bandwidth/power-efficiency.},
  keywords={Cellular networks;Performance evaluation;Cloud computing;Technological innovation;Power demand;5G mobile communication;Visual analytics;Cellular networks;video analytics;compute continuum},
  doi={10.1109/NFV-SDN59219.2023.10329735},
  ISSN={2832-2231},
  month={Nov},}@INPROCEEDINGS{10319957,
  author={Rosendo, Daniel and Mattoso, Marta and Costan, Alexandru and Souza, Renan and Pina, Débora and Valduriez, Patrick and Antoniu, Gabriel},
  booktitle={2023 IEEE International Conference on Cluster Computing (CLUSTER)}, 
  title={ProvLight: Efficient Workflow Provenance Capture on the Edge-to-Cloud Continuum}, 
  year={2023},
  volume={},
  number={},
  pages={221-233},
  abstract={Modern scientific workflows require hybrid infrastructures combining numerous decentralized resources on the IoT/Edge interconnected to Cloud/HPC systems (aka the Computing Continuum) to enable their optimized execution. Understanding and optimizing the performance of such complex Edge-to-Cloud workflows is challenging. Capturing the provenance of key performance indicators, with their related data and processes, may assist in understanding and optimizing workflow executions. However, the capture overhead can be prohibitive, particularly in resource-constrained devices, such as the ones on the IoT/Edge.To address this challenge, based on a performance analysis of existing systems, we propose ProvLight, a tool to enable efficient provenance capture on the IoT/Edge. We leverage simplified data models, data compression and grouping, and lightweight transmission protocols to reduce overheads. We further integrate ProvLight into the E2Clab framework to enable workflow provenance capture across the Edge-to-Cloud Continuum. This integration makes E2Clab a promising platform for the performance optimization of applications through reproducible experiments.We validate ProvLight at a large scale with synthetic workloads on 64 real-life IoT/Edge devices in the FIT IoT LAB testbed. Evaluations show that ProvLight outperforms state-of-the-art systems like ProvLake and DfAnalyzer in resource-constrained devices. ProvLight is 26—37x faster to capture and transmit provenance data; uses 5—7x less CPU; 2x less memory; transmits 2x less data; and consumes 2—2.5x less energy. ProvLight [1] and E2Clab [2] are available as open-source tools.},
  keywords={Protocols;Memory management;Key performance indicator;Data compression;Cluster computing;Data models;Performance analysis;Provenance;Lineage;Workflows;Edge;IoT;Computing Continuum},
  doi={10.1109/CLUSTER52292.2023.00026},
  ISSN={2168-9253},
  month={Oct},}@ARTICLE{10323487,
  author={Bachoumis, A. and Mylonas, C. and Plakas, K. and Birbas, M. and Birbas, A.},
  journal={IEEE Access}, 
  title={Data-Driven Analytics for Reliability in the Buildings-to-Grid Integrated System Framework: A Systematic Text-Mining-Assisted Literature Review and Trend Analysis}, 
  year={2023},
  volume={11},
  number={},
  pages={130763-130787},
  abstract={Data-driven machine learning-based methods have provided immense capabilities, revolutionizing sectors like the Buildings-to-grid (B2G) integrated system. Since the penetration rate of distributed energy resources increases towards a net-zero emissions power system, so does the need for advanced services that ensure B2G-integrated system reliability. The convergence of advancements in machine learning, computational resources at the entire cloud-edge continuum, and large datasets from sensing devices enable the development of these data-driven energy analytics services. This work conducts a systematic text-mining-based literature review to examine the diverse range and trends of machine learning methods used to enhance reliability in B2G-integrated systems. While traditional manual sampling and analysis approaches have limited the effectiveness of previous literature review papers in this field, this systematic literature review work aims to synthesize and summarize the existing body of research more efficiently and effectively. To achieve this, this study collected almost 10,500 papers from Scholar and Scopus databases. It employed text-mining-assisted BERTopic-based topic modelling and statistical trend analysis techniques to uncover semantic patterns and explore the temporal evolution of research themes. A two-dimensional taxonomy was derived to analyze the technical papers from a business and machine learning-related perspective. By quantifying the temporal trends within these topics, the study unveiled insights about the state-of-the-art analytics that ensure reliability in the B2G-integrated system domain while proposing future research directions.},
  keywords={Bibliographies;Reliability;Systematics;Market research;Machine learning;Analytical models;Taxonomy;Data models;Modeling;Building-to-grid;data-driven;machine learning;systematic review;topic modeling;trend analysis},
  doi={10.1109/ACCESS.2023.3335191},
  ISSN={2169-3536},
  month={},}@ARTICLE{10323468,
  author={Mafakheri, Babak and Schmidt, Lars and Prakash, Arun and Richter, Robert and Harasic, Marko and Heindlmaier, Michael and Hecker, Peter and Goratti, Leonardo},
  journal={IEEE Aerospace and Electronic Systems Magazine}, 
  title={AI-Powered Edge-Cloud Continuum for In-Flight Entertainment and Connectivity}, 
  year={2023},
  volume={38},
  number={12},
  pages={14-27},
  abstract={The aviation industry is moving toward a greener, more sustainable, integrated, and digital ecosystem, with Artificial Intelligence (AI) and machine learning showing potential key roles in the transformation process. Travelers, who are now increasingly used to ubiquitous data access, are restarting their air travels with higher expectations and demands for connectivity services. This trend highlights the importance of the in-flight entertainment and connectivity system, which should adapt to such changes and be designed to focus on network security and privacy. In this article, we provide experimental demonstration of an AI-based edge-computing platform developed within the cloud-enabled Aircraft Network and ARtificial Intelligence-based data Analysis (CANARIA) project, which targets to deliver proof-of-concept of an in-flight edge network. The CANARIA edge-computing platform offers a set of AI-based and containerized applications to not only improve the in-flight experience for cabin crew and passengers, but also to underpin the cabin digital transformation while increasing the safety and security of the connectivity system.},
  keywords={Cloud computing;Computer architecture;Servers;Logic gates;Entertainment industry;Backhaul networks;Media;AI;ML;Distributed Storage;Edge Computing;Edge Management;Federated Learning;IFEC},
  doi={10.1109/MAES.2023.3334686},
  ISSN={1557-959X},
  month={Dec},}@INPROCEEDINGS{10318524,
  author={Jo, Hyeon-Ki and Seo, Yuri and Hong, Choong Seon and Huh, Eui-Nam},
  booktitle={2023 International Conference on Advanced Technologies for Communications (ATC)}, 
  title={Multi-Still: A lightweight Multi-modal Cross Attention Knowledge Distillation method for the Real-Time Emotion Recognition Service in Edge-to-Cloud Continuum}, 
  year={2023},
  volume={},
  number={},
  pages={296-300},
  abstract={Recent advances in big data and artificial intelligence have led to active research in emotion recognition based on multimodal transformer models. Although these multimodal transformer models demonstrate high performance, their applications into real-time services are challenging due to their heavy computational requirements. Therefore, this study proposes a Multi-Still method, which transfers the multimodal knowledge of a teacher model to a student model using the knowledge distillation method supporting edge to cloud continuum environment. Multi-Still trained by text and voice data from Korean multimodal emotional datasets (KEMDy19, KEMDy20) both teacher and student. As a result, the student model transferred knowledge from the teacher model showed a 21% increase in number of inferences per second compared to the teacher model, 70.31% reduction in network size, and 65% reduction in the number of parameters. Nevertheless, it shows similar accuracy to the teacher model. We provide real-time emotion recognition services for the lightweight resources in edge continuum by efficiently learning multimodal data through knowledge distillation.},
  keywords={Knowledge engineering;Emotion recognition;Computational modeling;Big Data;Transformers;Real-time systems;Data models;multimodal;knowledge distillation;emotion recognition;lightweight model},
  doi={10.1109/ATC58710.2023.10318524},
  ISSN={2162-1039},
  month={Oct},}@INPROCEEDINGS{10317670,
  author={Barmpounakis, Sokratis and Karaolanis, Antonis and Demestichas, Panagiotis and Faucheux, Frédéric and Sayadi, Bessem},
  booktitle={2023 2nd International Conference on 6G Networking (6GNet)}, 
  title={Resilient Manufacturing Through 6G Mechanisms: Handling of Unexpected Situations in Industrial Environments}, 
  year={2023},
  volume={},
  number={},
  pages={1-3},
  abstract={Emerging demands across diverse industry sectors, notably in manufacturing, are ushering in a new era of unprecedented challenges. These challenges necessitate a resilient and robust infrastructure extending from the Far Edge to the Cloud. In the realm of future 6G wireless networks, we anticipate a transformative shift beyond the conventional devices and respective capabilities, as well as unparalleled flexibility, trustworthiness, and robustness in the orchestration of automated and resource efficient operations and workloads. This demo shows in an industrial use case, comprising collaborative robots (cobots) cooperating in conducting automated tasks, how advanced mechanisms, leveraging the far edge - cloud continuum resources, along with advanced monitoring-as-a-service capabilities (MaaS), Artificial Intelligence/Machine Learning (AI/ML), Digital Twinning and eXtended Reality (XR) technologies, can enable advanced observability, efficiency and robustness to the overall system, as well as immersive experience to the industrial worker/user.},
  keywords={6G mobile communication;Service robots;Wireless networks;Learning (artificial intelligence);Robustness;Manufacturing;X reality;6G;manufacturing;cobots;AIIML;Monitoring-as-a-Service;Digital Twins},
  doi={10.1109/6GNet58894.2023.10317670},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10317768,
  author={Pujolle, Guy},
  booktitle={2023 2nd International Conference on 6G Networking (6GNet)}, 
  title={Internet of Edges Architecture for 6G}, 
  year={2023},
  volume={},
  number={},
  pages={1-4},
  abstract={The objective of this paper is to propose a 6G architecture based on trust zones called Edges. An Edge is built with nodes integrating small data centers so that a very large part of the 6G requests can be processed locally. This local infrastructure brings distributed data centers in the nodes of the Edges and supports serverless functions. The Edge infrastructure represents a horizontal network where clients are able to go directly from one node to another node in a D2D mode. The vertical part of the network corresponds to the telecommunications operator infrastructure. This infrastructure allows horizontal networks to open secure channel between trust zones. Cloud Continuum is the sum of horizontal and vertical networks. This architecture has been developed, tested, and now commercialized by Green Communications company.},
  keywords={6G mobile communication;Data centers;Cloud computing;Companies;Telecommunications;Device-to-device communication;Commercialization;6G architecture;Edge;Direct mode;Trust zone},
  doi={10.1109/6GNet58894.2023.10317768},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10306090,
  author={Verginadis, Yiannis and Sarros, Christos-Alexandros and de Los Mozos, Mario Reyes and Veloudis, Simeon and Piliszek, Radosław and Kourtellis, Nicolas and Horn, Geir},
  booktitle={2023 Eighth International Conference on Fog and Mobile Edge Computing (FMEC)}, 
  title={NebulOuS: A Meta-Operating System with Cloud Continuum Brokerage Capabilities}, 
  year={2023},
  volume={},
  number={},
  pages={254-261},
  abstract={Cloud Continuum is the paradigm that unifies and exploits resources from far edge to public and private cloud offerings, as well as processing nodes with significant capacity in between. Nowadays, the combination of all these resources for augmenting modern hyper-distributed applications becomes a necessity, especially considering the vast volumes of data, their velocity, and their variety, which constitute well known challenges of Big Data processing. In this paper, we address the main research question on how a Cloud Continuum management platform should be structured to cope with the constantly increasing challenges and opportunities of the domain. We introduce the NebulOuS architecture vision towards accomplishing substantial research contributions in the realms of Cloud Continuum brokerage. We propose an advanced architecture that enables secure and optimal application provisioning, as well as reconfiguration over the Cloud Continuum. NebulOuS introduces a novel Meta-Operating System and platform, that is currently being developed, for enabling transient Cloud Continuum brokerage ecosystems that seamlessly exploit edge and fog nodes, in conjunction with multi-cloud resources, to cope with the requirements posed by low latency applications.},
  keywords={Cloud computing;Multi-access edge computing;Soft sensors;Ecosystems;Computer architecture;Maintenance engineering;Sensor systems;Cloud Continuum brokerage;cloud meta-OS},
  doi={10.1109/FMEC59375.2023.10306090},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10305820,
  author={Pusztai, Thomas and Nastic, Stefan and Raith, Philipp and Dustdar, Schahram and Vij, Deepak and Xiong, Ying},
  booktitle={2023 IEEE International Conference on Cloud Engineering (IC2E)}, 
  title={Vela: A 3-Phase Distributed Scheduler for the Edge-Cloud Continuum}, 
  year={2023},
  volume={},
  number={},
  pages={161-172},
  abstract={The amalgamation of multiple Edge and Cloud clusters into an Edge-Cloud continuum requires efficient scheduling techniques to cope with high numbers of infrastructure nodes and computing jobs. Since monolithic schedulers typically do not scale well beyond a certain cluster size, distributed scheduling approaches are usually employed to address such scalability issues. Distributed schedulers are often designed for Cloud environments and lack support for the Edge. Conversely, many Edge schedulers focus on single clusters and provide limited support to deal with the scale of the Edge-Cloud continuum. In this paper, we present the Vela Distributed Scheduler, a globally distributed scheduler, which is specifically tailored for the Edge-Cloud continuum. The main contributions of our work include: i) A novel, globally distributed and orchestrator-independent scheduler with a 3-phase scheduling workflow; ii) A two-level, informed sampling mechanism, which reduces latency for globally distributed sampling and leverages job requirements to produce high quality node samples; And iii) a MultiBind mechanism that significantly reduces job evictions and rescheduling due to scheduling conflicts. We implement Vela on top of Kubernetes and evaluate it in a realistic large-scale setup using multiple interconnected, globally distributed, and production-ready MicroK8s clusters with up to 20,000 total simulated nodes. Our results show that Vela’s performance scales linearly with infrastructure size and that it reduces scheduling conflicts by a factor of 10.},
  keywords={Sharding;Processor scheduling;Scalability;Pipelines;Throughput;distributed scheduling;edge computing;edge-cloud continuum},
  doi={10.1109/IC2E59103.2023.00026},
  ISSN={2694-0825},
  month={Sep.},}@INPROCEEDINGS{10305811,
  author={Rac, Samuel and Brorsson, Mats},
  booktitle={2023 IEEE International Conference on Cloud Engineering (IC2E)}, 
  title={Cost-Effective Scheduling for Kubernetes in the Edge-to-Cloud Continuum}, 
  year={2023},
  volume={},
  number={},
  pages={153-160},
  abstract={The edge to data center computing continuum is the aggregation of computing resources located anywhere between the network edge (e.g. close to 5G antennas), and servers in traditional data centers. Kubernetes is the de facto standard for container orchestration. It is very efficient in a data center environment, but it fails to give the same performance when adding edge resources. At the edge, resources are more limited, and networking conditions are changing over time.In this paper, we present a methodology that lowers the costs of running applications in the edge-to-cloud computing continuum. A cost-aware scheduler enables this optimization. We are also monitoring the Key Performance Indicators of the applications to ensure that cost optimizations do not impact negatively their Quality of Service. In addition, to ensure that performances are optimal even when users are moving, we introduce a background process that periodically checks if a better location is available for the application. To demonstrate the performance of our scheduling approach, we evaluate it on a vehicle cooperative perception use case, a representative 5G application.},
  keywords={Data centers;Energy consumption;Costs;5G mobile communication;Key performance indicator;Quality of service;Servers;Cloud computing;Edge computing;Scheduling;Container Orchestration;Resource allocation;5G;Kubernetes},
  doi={10.1109/IC2E59103.2023.00025},
  ISSN={2694-0825},
  month={Sep.},}@INPROCEEDINGS{10296241,
  author={Baneshi, Saeedeh and Varbanescu, Ana-Lucia and Pathania, Anuj and Akesson, Benny and Pimentel, Andy},
  booktitle={2023 IEEE 29th International Conference on Embedded and Real-Time Computing Systems and Applications (RTCSA)}, 
  title={Analyzing Digital Services Across the Compute Continuum Using iFogSim}, 
  year={2023},
  volume={},
  number={},
  pages={279-280},
  abstract={Digital services enable users to interact with a broad range of applications and, as such, have become an essential part of our daily lives. Although convenient, their ubiquity comes at a significant cost in energy, raising sustainability concerns. We access these services by triggering a computing continuum, spanning from the device to the edge, fog, and cloud. Scheduling decisions made at each layer impact the overall quality of service (QoS) and energy consumption of digital services.},
  keywords={Performance evaluation;Energy consumption;Processor scheduling;Computational modeling;Quality of service;Real-time systems;Energy efficiency},
  doi={10.1109/RTCSA58653.2023.00047},
  ISSN={2325-1301},
  month={Aug},}@INPROCEEDINGS{10295642,
  author={Bahy, Muhammad Bintang and Dwi Riyanto, Nur Rahmat and Fawwaz Nuruddin Siswantoro, Muhammad Zain and Santoso, Bagus Jati},
  booktitle={2023 10th International Conference on Electrical Engineering, Computer Science and Informatics (EECSI)}, 
  title={Resource Utilization Comparison of KubeEdge, K3s, and Nomad for Edge Computing}, 
  year={2023},
  volume={},
  number={},
  pages={321-327},
  abstract={Containers have become increasingly popular as a lightweight form of virtualization technology in the past few years. This surge in popularity aligns closely with the growing use of microservice architectures, primarily due to the scalability, ephemeral nature, and isolation provided by containers. In more recent times, advancements in edge devices have enabled them to support the execution of containerized microservices. These devices maintain a desirable balance between their size and power capabilities, to be implemented in a variety of locations. Research into various container placement strategies within edge networks has been prompted, resulting in the emergence of concepts like osmotic computing. Although these strategies for placing containers are efficient in terms of weight allocation, container orchestrators at present typically demand high resources requirement running on edge devices which have limitations of capabilities in terms of managing processes.This article presents a performance comparison of several container orchestrations consisting of KubeEdge, K3s and Nomad. The comparative aspects include resource utilization like CPU, memory and storage use before and after the deployment process. The experiment’s evaluation indicates that orchestrators favour Nomad because of its exceptional ability to efficiently utilize CPU and memory resources. On the other hand, K3s stands out for its higher efficiency in utilizing storage resources compared to other orchestrators.},
  keywords={Performance evaluation;Program processors;Scalability;Memory management;Microservice architectures;Containers;Resource management;cloud computing;edge computing;resource utilization;comparison;KubeEdge;K3s;Nomad;ICT infrastructure},
  doi={10.1109/EECSI59885.2023.10295642},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10293453,
  author={Gurgel, Leonandro and Souza, Arthur and Cacho, Nélio and Lopes, Frederico},
  booktitle={2023 IEEE International Smart Cities Conference (ISC2)}, 
  title={Deep Learning Distribution Model Using Osmotic Computing}, 
  year={2023},
  volume={},
  number={},
  pages={1-7},
  abstract={The utilization of edge computing has proven beneficial to Smart City applications due to its low latency processing on servers located in close proximity or even on the edge device. On the other hand, cloud computing leverages centralized computing power, resulting in significant advantages. Applications employing deep learning models commonly use both cloud computing and edge computing. While edge computing excels in providing rapid response times, devices typically possess limited computational resources. Conversely, cloud computing offers substantial computational power but suffers from longer access latencies. The challenge arises when deep learning applications must address one of these constraints, leading to poor scalability when focusing solely on edge or cloud computing or selecting a fixed distribution model. In this context, this paper aims to demonstrate the adaptive distribution of load leveraging osmotic computing. This approach directly impacts the scalability of deep learning solutions, mitigating the limitations imposed by either edge or cloud computing, improving throughput by up to 29% with low latency variation.},
  keywords={Deep learning;Cloud computing;Adaptation models;Smart cities;Scalability;Computational modeling;Artificial neural networks;Edge;Cloud;Distributed Deep Learning;Osmotic Computing},
  doi={10.1109/ISC257844.2023.10293453},
  ISSN={2687-8860},
  month={Sep.},}@INPROCEEDINGS{10283704,
  author={Carvalho, Gonçalo and Velasquez, Karima and Fernandes, João Paulo and Cabral, Bruno},
  booktitle={2023 IEEE International Conference on Communications Workshops (ICC Workshops)}, 
  title={On Computation Offloading and Energy Efficiency on Android Devices}, 
  year={2023},
  volume={},
  number={},
  pages={1836-1841},
  abstract={As resource-demanding mobile applications become increasingly popular, smartphones, which are resource- and battery-dependent by nature, can migrate their workload to other devices on the Cloud-to-Edge continuum. This is known as computation offloading and allows for the “heavy” processing to be carried out on another, typically more powerful equipment that prompts the result back to the smartphone. The goal is to improve overall performance, reduce energy consumption, and/or prolong the smartphone's battery life. However, the offloading process might have practical implications, such as performance degradation by increasing the latency of the response time or even increasing the energy consumption of the device if the application requires heavy data transfer. Also, one should consider that the chips in today's smartphones are extremely energy efficient and offer outstanding performance. 5G networks also increase the data transfer bandwidth between devices. We aim to shed light on the circumstances under which computation offloading is a robust architectural solution for mobile apps. We used the EdgeBench benchmark in our experimental evaluation, namely the audio, image, and scalar applications, over three smartphones. The results highlight different performance and energy consumption depending on the type of device and manufacturer, considering the same application, showing that the offloading decision is not linear, thus it is not always the best solution to minimize battery consumption.},
  keywords={Performance evaluation;Energy consumption;Conferences;Data transfer;Energy efficiency;Mobile applications;Computational efficiency;Computation Offloading;EdgeBench;Energy consumption},
  doi={10.1109/ICCWorkshops57953.2023.10283704},
  ISSN={2694-2941},
  month={May},}@INPROCEEDINGS{10283544,
  author={Rahman, Aisha B and Siraj, Md Sadman and Tsiropoulou, Eirini Eleni and Papavassiliou, Symeon},
  booktitle={2023 IEEE International Conference on Communications Workshops (ICC Workshops)}, 
  title={Mutualistic Compute Continuum: A Network Economics Analysis}, 
  year={2023},
  volume={},
  number={},
  pages={1565-1570},
  abstract={In the transformative data-driven era, Compute Continuum – consisting of the edge, fog and cloud - has been introduced as a viable long-term economic model. In this setting the problem of utilizing the appropriate compute resources at optimal processing points (edge, fog, cloud) in the system, becomes of paramount importance. In this paper, we address this issue by introducing the novel concept of mutualistic computing. Specifically, we do not simply account for the interactions among the involved actors, but we consider that the edge, fog, and the cloud computing providers establish an obligate symbiosis with the users in order to serve their computing demands. A network economics-based analysis is introduced in order to jointly enable the computing providers and the users to maximize their profit and utility, respectively. Two pricing models are studied to determine the computing providers' optimal prices in terms of maximizing their profit. The first one - free market pricing model - enables the full competition among the computing providers and is formulated as a non-cooperative game among the computing providers. The second one - oligopoly pricing - is introduced among the cloud computing provider (leader) and the edge, fog computing providers (followers), and is treated via a Stackelberg game. The performance evaluation of the proposed approach is achieved via modeling and simulation, and the tradeoffs of the two different pricing models within the mutualistic computing paradigm are highlighted.},
  keywords={Performance evaluation;Symbiosis;Cloud computing;Computational modeling;Conferences;Pricing;Games;Network Economics;Mutualistic Computing;Compute Continuum;Game Theory},
  doi={10.1109/ICCWorkshops57953.2023.10283544},
  ISSN={2694-2941},
  month={May},}@INPROCEEDINGS{10279214,
  author={Garbugli, Andrea and Rosa, Lorenzo and Bujari, Armir and Foschini, Luca},
  booktitle={ICC 2023 - IEEE International Conference on Communications}, 
  title={KuberneTSN: a Deterministic Overlay Network for Time-Sensitive Containerized Environments}, 
  year={2023},
  volume={},
  number={},
  pages={1494-1499},
  abstract={The emerging paradigm of resource disaggregation enables the deployment of cloud-like services across a pool of physical and virtualized resources, interconnected using a network fabric. This design embodies several benefits in terms of resource efficiency and cost-effectiveness, service elasticity and adaptability, etc. Application domains benefiting from such a trend include cyber-physical systems (CPS), tactile internet, 5G networks and beyond, or mixed reality applications, all generally embodying heterogeneous Quality of Service (QoS) requirements. In this context, a key enabling factor to fully support those mixed-criticality scenarios will be the network and the system-level support for time-sensitive communication. Although a lot of work has been conducted on devising efficient orchestration and CPU scheduling strategies, the networking aspects of performance-critical components remain largely unstudied. Bridging this gap, we propose KuberneTSN, an original solution built on the Kubernetes platform, providing support for time-sensitive traffic to unmodified application binaries. We define an architecture for an accelerated and deterministic overlay network, which includes kernel-bypassing networking features as well as a novel userspace packet scheduler compliant with the Time-Sensitive Networking (TSN) standard. The solution is implemented as tsn-cni, a Kubernetes network plugin that can coexist alongside popular alternatives. To assess the validity of the approach, we conduct an experimental analysis on a real distributed testbed, demonstrating that KuberneTSN enables applications to easily meet deterministic deadlines, provides the same guarantees of bare-metal deployments, and outperforms overlay networks built using the Flannel plugin.},
  keywords={Tactile Internet;Overlay networks;Scheduling algorithms;Mixed reality;Quality of service;Elasticity;Cyber-physical systems;time-sensitive networking;container;kubernetes;cloud continuum;network virtualization;bounded latency},
  doi={10.1109/ICC45041.2023.10279214},
  ISSN={1938-1883},
  month={May},}@INPROCEEDINGS{10287436,
  author={Vidal, Ivan and Gonzalez, Luis F. and Valera, Francisco and Nogales, Borja and Martin, Raul and Artalejo, Dulce and Lopez, Diego R. and Manjón, Jose M. and Pastor, Antonio},
  booktitle={2023 20th Annual IEEE International Conference on Sensing, Communication, and Networking (SECON)}, 
  title={A Multi-domain Testbed for Collaborative Research on the IoT-Edge-Cloud Continuum}, 
  year={2023},
  volume={},
  number={},
  pages={394-395},
  abstract={This poster showcases an industry-academia collaboration between Telefónica and Universidad Carlos III de Madrid, aiming to establish a testbed to support research and experimentation with novel IoT, edge, and cloud computing technologies. The testbed has been deployed at the 5G Telefonica Open Network Innovation Centre (5TONIC), and enables the seamless integration of IoT/Edge/Cloud infrastructure domains using virtual and hardware components that can be made available both within 5TONIC and external premises. The design of the testbed is based on key enabling technologies in 5G/6G networking, including Network Function Virtualization (NFV), Software Defined Networking (SDN), and cloud-native computing, as well as on a Secure Infrastructure Abstraction (SIA) that facilitates automation and secure network communications.},
  keywords={Cloud computing;Technological innovation;Federated learning;Supply chains;Collaboration;Hardware;Network function virtualization},
  doi={10.1109/SECON58729.2023.10287436},
  ISSN={2155-5494},
  month={Sep.},}@INPROCEEDINGS{10275470,
  author={Chehida, Salim and Fellah, Karim and Rutten, Eric and Giraud, Guillaume and Mocanu, Stéphane},
  booktitle={2023 IEEE 28th International Conference on Emerging Technologies and Factory Automation (ETFA)}, 
  title={Model-based Self-adaptive Management in a Smart Grid Substation}, 
  year={2023},
  volume={},
  number={},
  pages={1-8},
  abstract={The design of Cyber Physical Systems (CPS) is becoming increasingly complex due to the dynamic changes in their environments and infrastructures, requiring them to be self-adaptive. An important class of CPS is Industrial Control Systems (ICS), where a major trend is to upgrade from historically specific hardware and technologies towards more software-defined, virtual approaches involving the Could-Fog-Edge continuum. In this work, we propose a model-based approach for the design of the self-adaptation in ICS, inspired by, and applied to an industrial case study in Smart Grids, more particularly an electrical substation from RTE (the French Energy Transmission company). The problem is to allocate and reallocate dynamically a set of control functions upon a distributed computing infrastructure, with self-adaptation to variations and perturbations. We define and implement the model-based autonomic management feedback loop using constraint programming, to describe the space of possible configurations, as well as the constraints and objectives formalizing the operators strategies. This model is used in simulation, calling the constraints solver at each cycle of the loop.},
  keywords={Integrated circuits;Constraint handling;Analytical models;Substations;Computational modeling;Industrial control;Aerospace electronics;Self-adaptive Systems;CPS;Electrical Substation;Constraint Programming;Autonomic Manager;Energy;Smart Grid},
  doi={10.1109/ETFA54631.2023.10275470},
  ISSN={1946-0759},
  month={Sep.},}@INPROCEEDINGS{10275664,
  author={Johansson, Bjarne and Rågberger, Mats and Papadopoulos, Alessandro V. and Nolte, Thomas},
  booktitle={2023 IEEE 28th International Conference on Emerging Technologies and Factory Automation (ETFA)}, 
  title={Consistency Before Availability: Network Reference Point based Failure Detection for Controller Redundancy}, 
  year={2023},
  volume={},
  number={},
  pages={1-8},
  abstract={Distributed control systems constitute the automation solution backbone in domains where downtime is costly. Redundancy reduces the risk of faults leading to unplanned downtime. The Industry 4.0 appetite to utilize the device-to-cloud continuum increases the interest in network-based hardware-agnostic controller software. Functionality, such as controller redundancy, must adhere to the new ground rules of pure network dependency. In a standby controller redundancy, only one controller is the active primary. When the primary fails, the backup takes over. A typical network-based failure detection uses a cyclic message with a known interval, a.k.a. a heartbeat. Such a failure detection interprets heartbeat absences as a failure of the supervisee; consequently, a network partitioning could be indistinguishable from a node failure. Hence, in a network partitioning situation, a conventional heartbeat-based failure detection causes more than one active controller in the redundancy set, resulting in inconsistent outputs. We present a failure detection algorithm that uses network reference points to prevent network partitioning from leading to dual primary controllers. In other words, a failure detection that prioritizes consistency before availability.},
  keywords={Heart beat;Redundancy;Decentralized control;Software;Fourth Industrial Revolution;Detection algorithms;Manufacturing automation},
  doi={10.1109/ETFA54631.2023.10275664},
  ISSN={1946-0759},
  month={Sep.},}@INPROCEEDINGS{10271640,
  author={Cohen, Itamar and Giaccone, Paolo and Chiasserini, Carla Fabiana},
  booktitle={2023 International Conference on Software, Telecommunications and Computer Networks (SoftCOM)}, 
  title={Distributed Asynchronous Protocol for Service Provisioning in the Edge-Cloud Continuum}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={In the edge-cloud continuum, datacenters provide microservices (MSs) to mobile users, with each MS having specific latency constraints and computational requirements. Deploying such a variety of MSs matching their requirements with the available computing resources is challenging. In addition, time-critical MSs may have to be migrated as the users move, to keep meeting their latency constraints. Unlike previous work relying on a central orchestrator with an always-updated global view of the available resources and of the users’ locations, this work envisions a distributed solution to the above issues. In particular, we propose a distributed asynchronous protocol for MS deployment in the cloud-edge continuum that (i) dramatically reduces the system overhead compared to a centralized approach, and (ii) increases the system stability by avoiding having a single point of failure as in the case of a central orchestrator. Our solution ensures cost-efficient feasible placement of MSs, while using negligible bandwidth.},
  keywords={Protocols;Costs;Microservice architectures;Mobile communication;Software;Computer networks;Telecommunications;Edge computing;5G mobile communication.},
  doi={10.23919/SoftCOM58365.2023.10271640},
  ISSN={1847-358X},
  month={Sep.},}@ARTICLE{10273774,
  author={Anisetti, Marco and Ardagna, Claudio A. and Bena, Nicola and Damiani, Ernesto},
  journal={IEEE Internet Computing}, 
  title={Rethinking Certification for Trustworthy Machine-Learning-Based Applications}, 
  year={2023},
  volume={27},
  number={6},
  pages={22-28},
  abstract={Machine learning (ML) is increasingly used to implement advanced applications with nondeterministic behavior, which operate on the cloud–edge continuum. The pervasive adoption of ML is urgently calling for assurance solutions to assess applications’ nonfunctional properties (e.g., fairness, robustness, and privacy) with the aim of improving their trustworthiness. Certification has been clearly identified by policy makers, regulators, and industrial stakeholders as the preferred assurance technique to address this pressing need. Unfortunately, existing certification schemes are not immediately applicable to nondeterministic applications built on ML models. This article analyzes the challenges and deficiencies of current certification schemes, discusses open research issues, and proposes a first certification scheme for ML-based applications.},
  keywords={Certification;Robustness;Data models;Behavioral sciences;Malware;Security;Detectors},
  doi={10.1109/MIC.2023.3322327},
  ISSN={1941-0131},
  month={Nov},}@INPROCEEDINGS{10271920,
  author={Bartelucci, Nicolò and Bellavista, Paolo},
  booktitle={2023 IEEE International Conference on Metaverse Computing, Networking and Applications (MetaCom)}, 
  title={A Practical Guide to Autoscaling Solutions for Next Generation Internet Applications}, 
  year={2023},
  volume={},
  number={},
  pages={627-631},
  abstract={With the increasing opportunities offered by the cloud continuum (with the availability of distributed edge cloud nodes in addition to traditional datacenter nodes) and the associated growing complexity of distributed virtualized deployment environments, it is often not trivial to statically select the best autoscaling solution to optimally manage resource elasticity for a specific application and for its requirements. In addition, for example because the traffic to a next generation Internet application in the cloud continuum may be highly variable, there is the need of a high degree of adaptability to dynamically determine the best tradeoff between the usage of virtualized resources and its cost. The paper aims at providing a practical guide to the state-of-the-art of autoscaling technologies by describing, comparing, and evaluating them. In particular, we propose an original taxonomy to classify and label the most promising and emerging autoscaling technologies. This taxonomy allows us also to define criteria and practical guidelines on which autoscaling solution to select and integrate in next generation cloud continuum applications, and sheds some light on the most promising directions expected for future research work to fill the current technology gaps.},
  keywords={Cloud computing;Costs;Metaverse;Taxonomy;Elasticity;Complexity theory;Next generation networking;Edge Computing;Cloud Continuum;Autoscaling;Polaris;Kubernetes;Pod Autoscaler;Elasticity},
  doi={10.1109/MetaCom57706.2023.00110},
  ISSN={},
  month={June},}@INPROCEEDINGS{10271910,
  author={Bassbouss, Louay and Neparidze, Andy and Kieslich, Kolja and Steglich, Stephan and Arbanowski, Stefan and Pogrzeba, Peter},
  booktitle={2023 IEEE International Conference on Metaverse Computing, Networking and Applications (MetaCom)}, 
  title={Metaverse Remote Rendering Testbed}, 
  year={2023},
  volume={},
  number={},
  pages={578-584},
  abstract={This paper introduces a comprehensive testbed for evaluating the performance of remote rendering in the Metaverse, a virtual world that is rapidly evolving with advances in VR, AR, AI, and spatial computing technologies. As rendering complex 3D experiences on end-user devices is often limited by computational resources, the testbed focuses on evaluating the remote rendering performance of multi-user Metaverse experiences in popular game engines, such as Unity and Unreal Engine, under various network conditions, communication protocols, video encoding, deployment scenarios, and number of connected users. The experiences are rendered on servers with varying computational resources and hardware acceleration and packaged as Docker containers, enabling easy deployment on any compute and storage system, including on-premise, edge, and cloud. The testbed results will provide valuable insights into the performance and scalability of remote rendering for the Metaverse and help address the main challenges and research focus of the Metaverse computing track, which aims to support the provisioning of computing services for pervasive applications in the Metaverse, with a special emphasis on computation offloading for extremely low latency in the cloud continuum.},
  keywords={Performance evaluation;Cloud computing;Three-dimensional displays;Protocols;Metaverse;Scalability;Rendering (computer graphics);Metaverse Computing;Testbed;Edge Cloud Continuum;Remote Rendering;Extremely Low Latency Streaming;5G;WebRTC;Gaming Engines},
  doi={10.1109/MetaCom57706.2023.00102},
  ISSN={},
  month={June},}
