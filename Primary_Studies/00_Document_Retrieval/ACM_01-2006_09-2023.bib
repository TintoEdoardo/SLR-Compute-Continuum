@article{10.1145/3488247,
author = {Neha, Benazir and Panda, Sanjaya Kumar and Sahu, Pradip Kumar and Sahoo, Kshira Sagar and Gandomi, Amir H.},
title = {A Systematic Review on Osmotic Computing},
year = {2022},
issue_date = {May 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
number = {2},
url = {https://doi.org/10.1145/3488247},
doi = {10.1145/3488247},
abstract = {Osmotic computing in association with related computing paradigms (cloud, fog, and edge) emerges as a promising solution for handling bulk of security-critical as well as latency-sensitive data generated by the digital devices. It is a growing research domain that studies deployment, migration, and optimization of applications in the form of microservices across cloud/edge infrastructure. It presents dynamically tailored microservices in technology-centric environments by exploiting edge and cloud platforms. Osmotic computing promotes digital transformation and furnishes benefits to transportation, smart cities, education, and healthcare. In this article, we present a comprehensive analysis of osmotic computing through a systematic literature review approach. To ensure high-quality review, we conduct an advanced search on numerous digital libraries to extracting related studies. The advanced search strategy identifies 99 studies, from which 29 relevant studies are selected for a thorough review. We present a summary of applications in osmotic computing build on their key features. On the basis of the observations, we outline the research challenges for the applications in this research field. Finally, we discuss the security issues resolved and unresolved in osmotic computing.},
journal = {ACM Trans. Internet Things},
month = {feb},
articleno = {9},
numpages = {30},
keywords = {edge computing, fog computing, Osmotic computing}
}

@inproceedings{10.1145/3578245.3584936,
author = {Jansen, Matthijs and Wagner, Linus and Trivedi, Animesh and Iosup, Alexandru},
title = {Continuum: Automate Infrastructure Deployment and Benchmarking in the Compute Continuum},
year = {2023},
isbn = {9798400700729},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3578245.3584936},
doi = {10.1145/3578245.3584936},
abstract = {As the next generation of diverse workloads like autonomous driving and augmented/virtual reality evolves, computation is shifting from cloud-based services to the edge, leading to the emergence of a cloud-edge compute continuum. This continuum promises a wide spectrum of deployment opportunities for workloads that can leverage the strengths of cloud (scalable infrastructure, high reliability), edge (energy efficient, low latencies), and endpoints (sensing, user-owned). Designing and deploying software in the continuum is complex because of the variety of available hardware, each with unique properties and trade-offs. In practice, developers have limited access to these resources, limiting their ability to create software deployments. To simplify research and development in the compute continuum, in this paper, we propose Continuum, a framework for automated infrastructure deployment and benchmarking that helps researchers and engineers to deploy and test their use cases in a few lines of code. Continuum can automatically deploy a wide variety of emulated infrastructures and networks locally and in the cloud, install software for operating services and resource managers, and deploy and benchmark applications for users with diverse configuration options. In our evaluation, we show how our design covers these requirements, allowing Continuum to be (i) highly flexible, supporting any computing model, (ii) highly configurable, allowing users to alter framework components using an intuitive API, and (iii) highly extendable, allowing users to add support for more infrastructure, applications, and more. Continuum is available at https://github.com/atlarge-research/continuum.},
booktitle = {Companion of the 2023 ACM/SPEC International Conference on Performance Engineering},
pages = {181–188},
numpages = {8},
keywords = {task offloading, software development, resource management, infrastructure deployment, compute continuum, benchmark},
location = {Coimbra, Portugal},
series = {ICPE '23 Companion}
}

@inproceedings{10.1145/3589010.3594893,
author = {Matricardi, Alessio and Bocci, Alessandro and Forti, Stefano and Brogi, Antonio},
title = {Simulating FaaS Orchestrations In The Cloud-Edge Continuum},
year = {2023},
isbn = {9798400701641},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589010.3594893},
doi = {10.1145/3589010.3594893},
abstract = {Deploying Function-as-a-Service (FaaS) applications to resources in the Cloud-Edge continuum calls for suitable simulation environments to assess new proposals for managing those applications while accounting for their specificity, i.e. ephemeral deployment and orchestrated execution. Indeed, exploiting real infrastructures for extensive experiments, while considering heterogeneous nodes and different applications, is costly and time-consuming.In this article, we propose a novel open-source discrete-time simulator for the management (i.e. deployment and migration) of orchestrated FaaS in the Cloud-Edge continuum. It enables assessing customised management policies against varying infrastructure conditions. It collects data about execution time, energy consumption, and successes/failures of management operations. We illustrate the prototype at work over a lifelike case study.},
booktitle = {Proceedings of the 3rd Workshop on Flexible Resource and Application Management on the Edge},
pages = {19–26},
numpages = {8},
keywords = {simulation, function-as-a-service, cloud-edge continuum},
location = {Orlando, FL, USA},
series = {FRAME '23}
}

@inproceedings{10.1145/3437378.3444366,
author = {Buzachis, Alina and Boruta, Daiana and Villari, Massimo and Spillner, Josef},
title = {Modeling and Emulation of an Osmotic Computing Ecosystem using OsmoticToolkit},
year = {2021},
isbn = {9781450389563},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3437378.3444366},
doi = {10.1145/3437378.3444366},
abstract = {Digital services are increasingly becoming cyber-physical and osmotic, combining Cloud resources with Fog, Edge, and IoT devices. This trend can be observed in the e-health domain or in smart city applications where the location of software deployments and data processing matters. Before such applications go live, careful planning with real system emulation is necessary. We claim that the OsmoticToolkit, although in the early stages, is the first emulation environment designed to address this challenge. In this paper, we introduce the emulator’s functionalities and validate experimentally with an e-health scenario, using a reference deployment of a microservice-based hospital application. The experimental results carried out show its effectiveness providing valuable support for understanding the impact on resources, workloads, and Quality of Service requirements within Cloud-Edge/Fog-IoT scenarios while preserving the users’ Service Level Agreements (SLAs).},
booktitle = {Proceedings of the 2021 Australasian Computer Science Week Multiconference},
articleno = {9},
numpages = {9},
keywords = {SDN, Osmotic Computing, Orchestration, Microservices, Emulation, Deployment, Cloud Computing},
location = {Dunedin, New Zealand},
series = {ACSW '21}
}

@article{10.1145/3591335.3591352,
author = {Sousa, Rita and Sabate, Eudald and Gonzalez-Hierro, Marco and Barros, Ant\'{o}nio and Zubia, Cristina and Miguel Pinho, Luis and Kartsakli, Elli},
title = {Managing Non-functional Requirements in an ELASTIC Edge-Cloud Continuum},
year = {2023},
issue_date = {December 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {42},
number = {2},
issn = {1094-3641},
url = {https://doi.org/10.1145/3591335.3591352},
doi = {10.1145/3591335.3591352},
abstract = {The ELASTIC European project addresses the emergence of extreme-scale analytics, providing a software architecture with a new elasticity concept, intended to support smart cyberphysical systems with performance requirements from extreme-scale analytics workloads. One of the main challenges being tackled by ELASTIC is the necessity to simultaneously fulfil the non-functional properties inherited from smart systems, such as real-time, energy efficiency, communication quality or security. This paper presents how the ELASTIC architecture monitors and manages such nonfunctional requirements, working in close collaboration with the component responsible for the orchestration of elasticity.},
journal = {Ada Lett.},
month = {apr},
pages = {114–118},
numpages = {5},
keywords = {non-functional requirements, elasticity, compute continuum}
}

@inproceedings{10.1145/3526059.3533618,
author = {M\'{e}n\'{e}trey, J\"{a}mes and Pasin, Marcelo and Felber, Pascal and Schiavoni, Valerio},
title = {WebAssembly as a Common Layer for the Cloud-edge Continuum},
year = {2022},
isbn = {9781450393102},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3526059.3533618},
doi = {10.1145/3526059.3533618},
abstract = {Over the last decade, the cloud computing landscape has transformed from centralised architecture made of large data centres to a distributed and heterogeneous architecture embracing edge and IoT processing units. This shift has created the so-called cloud-edge continuum, which closes the gap between the large datacentres and the end-user devices. Existing solutions are, however, dominated by proprietary silos and incompatible technologies, built around dedicated devices and run-time stacks. In this position paper, we motivate the need for interoperable solutions that would run seamlessly across hardware devices and software environments, while achieving good performance and a high level of security-a critical requirement for code and data processed off-premises. We argue that the technology provided by WebAssembly running on modern virtual machines and shielded within trusted execution environments, combined with a core set of services and support libraries, allows us to meet both goals. We also present preliminary results from a prototype built with these technologies and deployed on the cloud-edge continuum.},
booktitle = {Proceedings of the 2nd Workshop on Flexible Resource and Application Management on the Edge},
pages = {3–8},
numpages = {6},
keywords = {webassembly, wasi, trusted execution environments, intel sgx, cloud-edge continuum, arm trustzone},
location = {Minneapolis, MN, USA},
series = {FRAME '22}
}

@inproceedings{10.1145/3415088.3415097,
author = {Mlotshwa, Likhwa Lothar and Makura, Sheunesu M. and Karie, Nickson M. and Kebande, Victor R.},
title = {Opportunistic security architecture for osmotic computing paradigm in dynamic IoT-Edge's resource diffusion},
year = {2020},
isbn = {9781450375580},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3415088.3415097},
doi = {10.1145/3415088.3415097},
abstract = {Increased heterogeneity of physical resources has had positive and negative effects in Internet of Things (IoT) through the existence of edge computing. As a result, there has been a need for effective dynamic management of IoT, cloud and edge resources, in order to address the existence of low-level constraints during resource migration. Nevertheless, the explosion of IoT devices and data has allowed orchestration of microservices to adopt an opportunistic approach to how applications and services are deployed in the edge in IoT platform. A notable approach has been osmotic computing that allows resources from a federated cloud to be able to diffuse from an ecosystem of higher solute (network properties and entities) concentration to solvent (applications, layered interfaces and services). We posit that, while computing resources and applications are able to move from the federated environment, to the cloud deployable models, to the edge, then to IoT ecosystem, there is a higher chance of susceptibility of threats and attacks that may be directed to the emerging edge applications/data due to dynamic emergent configurations. This paper proposes a 5-layer opportunistic architecture that adds security metrics across different levels of osmotic computing paradigm. The proposed 5-layer security architecture addresses the need for autonomously securing resources-edge computation, edge storage and emerging edge configurations as the computing resources move to a higher solute in heterogenous edge and cloud datacenters across IoT devices. This has been achieved by proposing security metrics that address the prevailing challenge with a degree of certainty.},
booktitle = {Proceedings of the 2nd International Conference on Intelligent and Innovative Computing Applications},
articleno = {9},
numpages = {7},
keywords = {security architecture, osmotic, opportunistic, edge, IoT},
location = {Plaine Magnien, Mauritius},
series = {ICONIC '20}
}

@article{10.1109/TNET.2022.3222640,
author = {Malandrino, Francesco and Chiasserini, Carla Fabiana and di Giacomo, Giuseppe},
title = {Efficient Distributed DNNs in the Mobile-Edge-Cloud Continuum},
year = {2022},
issue_date = {Aug. 2023},
publisher = {IEEE Press},
volume = {31},
number = {4},
issn = {1063-6692},
url = {https://doi.org/10.1109/TNET.2022.3222640},
doi = {10.1109/TNET.2022.3222640},
abstract = {In the mobile-edge-cloud continuum, a plethora of heterogeneous data sources and computation-capable nodes are available. Such nodes can cooperate to perform a distributed learning task, aided by a learning controller (often located at the network edge). The controller is required to make decisions concerning (i) data selection, i.e., which data sources to use; (ii) model selection, i.e., which machine learning model to adopt, and (iii) matching between the layers of the model and the available physical nodes. All these decisions influence each other, to a significant extent and often in counter-intuitive ways. In this paper, we formulate a problem addressing all of the above aspects and present a solution concept called RightTrain, aiming at making the aforementioned decisions in a joint manner, minimizing energy consumption subject to learning quality and latency constraints. RightTrain leverages an expanded-graph representation of the system and a delay-aware Steiner tree to obtain a provably near-optimal solution while keeping the time complexity low. Specifically, it runs in polynomial time and its decisions exhibit a competitive ratio of &lt;inline-formula&gt; &lt;tex-math notation="LaTeX"&gt;$2(1+epsilon)$ &lt;/tex-math&gt;&lt;/inline-formula&gt;, outperforming state-of-the-art solutions by over 50%. Our approach is also validated through a real-world implementation.},
journal = {IEEE/ACM Trans. Netw.},
month = {nov},
pages = {1702–1716},
numpages = {15}
}

@inproceedings{10.1145/3494322.3494357,
author = {Spillner, Josef and Liu, Mengwei and Zhan, Peng},
title = {Demo:Smart Waste Disposal with Edge-Cloud Continuum Architecture},
year = {2022},
isbn = {9781450385664},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3494322.3494357},
doi = {10.1145/3494322.3494357},
abstract = {The creation of circular economies calls for automated processes of handling goods and natural resources, including waste. Accurate knowledge about disposed waste types facilitates their smart processing and maximises the reuse potential. This requires components such as precise sensing, an appropriate architecture to gather sensed data and gain insights with low latency, and brokering tools to connect waste collectors with processors and collection points. This paper describes a smart waste detection prototype that has been designed and assembled to investigate the automated processes with those components. Its design is centered around a continuum computing architecture to align energy-efficient edge sensing with the shared aim of circular economies to reduce the ecological footprint.},
booktitle = {Proceedings of the 11th International Conference on the Internet of Things},
pages = {192–195},
numpages = {4},
keywords = {object detection, cyber-physical applications, circular economy},
location = {St.Gallen, Switzerland},
series = {IoT '21}
}

@article{10.1145/3226644,
author = {Baresi, L. and Mendon\c{c}a, D. F. and Garriga, M. and Guinea, S. and Quattrocchi, G.},
title = {A Unified Model for the Mobile-Edge-Cloud Continuum},
year = {2019},
issue_date = {May 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {19},
number = {2},
issn = {1533-5399},
url = {https://doi.org/10.1145/3226644},
doi = {10.1145/3226644},
abstract = {Technologies such as mobile, edge, and cloud computing have the potential to form a computing continuum for new, disruptive applications. At runtime, applications can choose to execute parts of their logic on different infrastructures that constitute the continuum, with the goal of minimizing latency and battery consumption and maximizing availability. In this article, we propose A3-E, a unified model for managing the life cycle of continuum applications. In particular, A3-E exploits the Functions-as-a-Service model to bring computation to the continuum in the form of microservices. Furthermore, A3-E selects where to execute a certain function based on the specific context and user requirements. The article also presents a prototype framework that implements the concepts behind A3-E. Results show that A3-E is capable of dynamically deploying microservices and routing the application’s requests, reducing latency by up to 90% when using edge instead of cloud resources, and battery consumption by 74% when computation has been offloaded.},
journal = {ACM Trans. Internet Technol.},
month = {apr},
articleno = {29},
numpages = {21},
keywords = {real-time systems, ops automation, mobile computing, fog computing, edge computing, Functions-as-a-Service, Computing continuum}
}

@inproceedings{10.1145/3477314.3507212,
author = {Costa, Daniel and Pereira, Jos\'{e} and Vila\c{c}a, Ricardo and Faria, Nuno},
title = {Adaptive database synchronization for an online analytical cioud-to-edge continuum},
year = {2022},
isbn = {9781450387132},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3477314.3507212},
doi = {10.1145/3477314.3507212},
abstract = {Wide availability of edge computing platforms, as expected in emerging 5G networks, enables a computing continuum between centralized cloud services and the edge of the network, close to end-user devices. This is particularly appealing for online analytics as data collected by devices is made available for decision-making. However, cloud-based parallel-distributed data processing platforms are not able to directly access data on the edge. This can be circumvented, at the expense of freshness, with data synchronization that periodically uploads data to the cloud for processing.In this work, we propose an adaptive database synchronization system that makes distributed data in edge nodes available dynamically to the cloud by balancing between reducing the amount of data that needs to be transmitted and the computational effort needed to do so at the edge. This adapts to the availability of CPU and network resources as well as to the application workload.},
booktitle = {Proceedings of the 37th ACM/SIGAPP Symposium on Applied Computing},
pages = {264–266},
numpages = {3},
keywords = {synchronization, replication, data federation, cloud-edge environment, analytical},
location = {Virtual Event},
series = {SAC '22}
}

@article{10.1109/TNET.2023.3271674,
author = {Cohen, Itamar and Chiasserini, Carla Fabiana and Giaccone, Paolo and Scalosub, Gabriel},
title = {Dynamic Service Provisioning in the Edge-Cloud Continuum With Bounded Resources},
year = {2023},
issue_date = {Dec. 2023},
publisher = {IEEE Press},
volume = {31},
number = {6},
issn = {1063-6692},
url = {https://doi.org/10.1109/TNET.2023.3271674},
doi = {10.1109/TNET.2023.3271674},
abstract = {We consider a hierarchical edge-cloud architecture in which services are provided to mobile users as chains of virtual network functions. Each service has specific computation requirements and target delay performance, which require placing the corresponding chain properly and allocating a suitable amount of computing resources. Furthermore, chain migration may be necessary to meet the services’ target delay. We model and formalize the problem of finding a feasible chain placement and resource allocation, while minimizing the migration, bandwidth, and computation costs. We tackle this problem by partitioning it into a (i) CPU allocation problem, and a (ii) placement problem. For the CPU allocation problem, we find an optimal solution. For the placement problem, we show that even finding a feasible solution is NP-hard, and envision an algorithm that is guaranteed to find a feasible solution while leveraging a bounded amount of resource augmentation. Our algorithms are incorporated into a solution framework that aims to minimize both the cost and the required resource augmentation. The results, obtained through trace-driven, large-scale simulations, show that our framework can provide a close-to-optimal solution while running several orders of magnitude faster than an ILP solver.},
journal = {IEEE/ACM Trans. Netw.},
month = {may},
pages = {3096–3111},
numpages = {16}
}

@proceedings{10.1145/3417310,
title = {CCIoT '20: Proceedings of the Workshop on Cloud Continuum Services for Smart IoT Systems},
year = {2020},
isbn = {9781450381314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Internet of Things (IoT) is one of the hottest topic in the field of communications and computing. Many cloud providers offers cloud/edge services for IoT, to handle big data, to apply AI technologies, to support massive IoT devices, and to provide low-latency control. At the same time 5G cellular networks have massive IoT as reference scenario, for which a huge number of smart sensors/actuators must be connected with low latency. Cloud and edge computing on the one and 5G on the other hand push for an IoT cloud continuum aimed at simplifying the integration, development and delivery processes of future, cloud-native, IoT applications, also considering related security and privacy issues. There are many alternatives for cloud and networking services and technologies in forming cloud continuum for IoT.The workshop focuses on application of cloud/edge computing to IoT systems, and networking of IoT devices, computing facilities, and individual IoT systems. The workshop provides the venue for the researchers and practitioners involved in the above mentioned IoT-system field to get together and discuss their issues.},
location = {Virtual Event, Japan}
}

@inproceedings{10.1145/3599733.3600253,
author = {Br\"{a}nnvall, Rickard and Stark, Tina and Gustafsson, Jonas and Eriksson, Mats and Summers, Jon},
title = {Cost Optimization for the Edge-Cloud Continuum by Energy-Aware Workload Placement},
year = {2023},
isbn = {9798400702273},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3599733.3600253},
doi = {10.1145/3599733.3600253},
abstract = {This article investigates the problem of where to place the computation workload in an edge-cloud network topology considering the trade-off between the location-specific cost of computation and data communication. For this purpose, a Monte Carlo simulation model is defined that accounts for different workload types, their distribution across time and location, as well as correlation structure. Results confirm and quantify the intuition that optimization can be achieved by distributing a part of cloud computation to make efficient use of resources in an edge data center network, with operational energy savings of 4–6% and up to 50% reduction in its claim for cloud capacity.},
booktitle = {Companion Proceedings of the 14th ACM International Conference on Future Energy Systems},
pages = {79–84},
numpages = {6},
keywords = {sustainability, energy efficiency, edge, data center, cost optimization},
location = {Orlando, FL, USA},
series = {e-Energy '23 Companion}
}

@inproceedings{10.1145/3331052.3332473,
author = {Kaur, Kuljeet and Garg, Sahil and Kaddoum, Georges and Ahmed, Syed Hassan and Jayakody, Dushantha Nalin K.},
title = {En-OsCo: Energy-aware Osmotic Computing Framework using Hyper-heuristics},
year = {2019},
isbn = {9781450368056},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3331052.3332473},
doi = {10.1145/3331052.3332473},
abstract = {The proliferation of the Internet of Things (IoT) has paved the way for many cloud based applications such as smart grid, healthcare, traffic management, finance, etc. In this vein, the need of transferring large data-streams to remote data centers is a key concern for modern Cloud-based IoT paradigms. This disrupts the remote Cloud Computing model, moving applications, data and computing resources to the logical extremes of the network. Thus, to handle streaming data in IoT environments, an efficient IoT-based computing model that can dynamically handle the interplay between Cloud and Edge data centers is required. In this direction, a recent paradigm, popularly known as Osmotic Computing, has emerged to ensure the acceptable performance of widely dispersed services. However, the burden of data-offloading across multiple data centers usually leads to a consequent increase in their energy consumption which in-turn will affect the overall Quality of Service (QoS) of the IoT-based applications. Keeping focus on all these issues, a consolidated decision making framework for Osmotic Computing, i.e., En-OsCo, is designed to ensure the energy-aware dynamic management of resources. The proposed framework incorporates four significant contributions: i) Resource monitoring of Edge data centers using Extended Kalman Filter, ii) Optimal dispatch of incoming services to the Edge/Cloud setup using Hyper-heuristics, iii) Minimizing the energy consumption of underlying data centers and reducing the service latency, and iv) Reducing the search space of Hyper-heuristics by keeping track of previously made decisions using Universal Streaming Monitoring. Further, in order to validate the efficacy of the proposed En-OsCo framework, ContainerCloudSim has been used in combination of HyFlex on PlanetLab datasets. The obtained results validate the purpose of the proposed scheme in minimizing the overall energy consumption of the computing setup while considerably reducing the latency.},
booktitle = {Proceedings of the ACM MobiHoc Workshop on Pervasive Systems in the IoT Era},
pages = {19–24},
numpages = {6},
keywords = {and Osmotic Computing, Latency Minimization, Hyper-heuristics, Extended Kalman Filter, Energy Minimization, Edge Computing, Cloud Computing},
location = {Catania, Italy},
series = {PERSIST-IoT '19}
}

@inproceedings{10.1145/3474085.3475182,
author = {Zhuang, Weiming and Wen, Yonggang and Zhang, Shuai},
title = {Joint Optimization in Edge-Cloud Continuum for Federated Unsupervised Person Re-identification},
year = {2021},
isbn = {9781450386517},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3474085.3475182},
doi = {10.1145/3474085.3475182},
abstract = {Person re-identification (ReID) aims to re-identify a person from non-overlapping camera views. Since person ReID data contains sensitive personal information, researchers have adopted federated learning, an emerging distributed training method, to mitigate the privacy leakage risks. However, existing studies rely on data labels that are laborious and time-consuming to obtain. We present FedUReID, a federated unsupervised person ReID system to learn person ReID models without any labels while preserving privacy. FedUReID enables in-situ model training on edges with unlabeled data. A cloud server aggregates models from edges instead of centralizing raw data to preserve data privacy. Moreover, to tackle the problem that edges vary in data volumes and distributions, we personalize training in edges with joint optimization of cloud and edge. Specifically, we propose personalized epoch to reassign computation throughout training, personalized clustering to iteratively predict suitable labels for unlabeled data, and personalized update to adapt the server aggregated model to each edge. Extensive experiments on eight person ReID datasets demonstrate that FedUReID not only achieves higher accuracy but also reduces computation cost by 29%. Our FedUReID system with the joint optimization will shed light on implementing federated learning to more multimedia tasks without data labels.},
booktitle = {Proceedings of the 29th ACM International Conference on Multimedia},
pages = {433–441},
numpages = {9},
keywords = {unsupervised person re-identification, unsupervised learning, person re-identification, federated learning},
location = {Virtual Event, China},
series = {MM '21}
}

@proceedings{10.1145/3609389,
title = {IIoT-NETs '23: Proceedings of the 1st Workshop on Enhanced Network Techniques and Technologies for the Industrial IoT to Cloud Continuum},
year = {2023},
isbn = {9798400703027},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {New York, NY, USA}
}

@inproceedings{10.1145/3381991.3395617,
author = {Ahmad, Tahir and Morelli, Umberto and Ranise, Silvio},
title = {Deploying Access Control Enforcement for IoT in the Cloud-Edge Continuum with the help of the CAP Theorem},
year = {2020},
isbn = {9781450375689},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3381991.3395617},
doi = {10.1145/3381991.3395617},
abstract = {The CAP Theorem is used by distributed system practitioners to investigate the necessary trade-offs in the design and development of distributed systems, mainly databases and web applications. In this paper, we use it to reason about access control systems designed for the Internet of Things (IoT). We validate our approach by experimentally investigating alternative architectural designs to enforce access control in a smart lock system using the cloud-edge IoT platform offered by Amazon Web Services. We discuss the trade-off between security and performance that may help IoT designers choose the most suitable architecture supporting their requirements.},
booktitle = {Proceedings of the 25th ACM Symposium on Access Control Models and Technologies},
pages = {213–220},
numpages = {8},
keywords = {internet of things, cap theorem, access control},
location = {Barcelona, Spain},
series = {SACMAT '20}
}

@inproceedings{10.1145/3492323.3495590,
author = {Balouek-Thomert, Daniel and Silva, Pedro and Fauvel, Kevin and Costan, Alexandru and Antoniu, Gabriel and Parashar, Manish},
title = {MDSC: modelling distributed stream processing across the edge-to-cloud continuum},
year = {2022},
isbn = {9781450391634},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3492323.3495590},
doi = {10.1145/3492323.3495590},
abstract = {The growth of the Internet of Things is resulting in an explosion of data volumes at the Edge of the Internet. To reduce costs incurred due to data movement and centralized cloud-based processing, it is becoming increasingly important to process and analyze such data closer to the data sources. Exploiting Edge computing capabilities for stream-based processing is however challenging. It requires addressing the complex characteristics and constraints imposed by all the resources along the data path, as well as the large set of heterogeneous data processing and management frameworks. Consequently, the community needs tools that can facilitate the modeling of this complexity and can integrate the various components involved. In this work, we introduce MDSC, a hierarchical approach for modeling distributed stream-based applications on Edge-to-Cloud continuum infrastructures. We demonstrate how MDSC can be applied to a concrete real-life ML-based application - early earthquake warning - to help answer questions such as: when is it worth decentralizing the classification load from the Cloud to the Edge and how?},
booktitle = {Proceedings of the 14th IEEE/ACM International Conference on Utility and Cloud Computing Companion},
articleno = {25},
numpages = {6},
keywords = {stream processing, modelling, computing continuum},
location = {Leicester, United Kingdom},
series = {UCC '21}
}

@inproceedings{10.1145/3468737.3494103,
author = {Smirnov, Fedor and Engelhardt, Chris and Mittelberger, Jakob and Pourmohseni, Behnaz and Fahringer, Thomas},
title = {Apollo: towards an efficient distributed orchestration of serverless function compositions in the cloud-edge continuum},
year = {2021},
isbn = {9781450385640},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3468737.3494103},
doi = {10.1145/3468737.3494103},
abstract = {This paper provides a first presentation of Apollo, an orchestration framework for serverless function compositions distributed across the cloud-edge continuum. Apollo has a modular design that enables a fine-grained decomposition of the runtime orchestration (scheduling, data transmission, etc.) of applications, so that each of the numerous orchestration decisions can be optimized separately, fully exploiting the potential for the optimization of performance and costs. Apollo features (a) a flexible model of the application and the available resources and (b) a decentralized orchestration scheme carried out by independent agents. This flexible structure enables distributing not only the processing but also the orchestration process itself across a large number of resources, each running an independent Apollo instance. In combination with the ability to execute parts of the application directly on the host of each Apollo instance, this unleashes a significant potential for cost and performance optimization by leveraging data locality. Apollo's efficiency and its potential for application performance improvement are demonstrated in a series of experiments---for both synthetic and real function compositions---where Apollo's capability for flexible distribution of tasks between local containers and serverless functions enables a significant application speedup (up to 20X).},
booktitle = {Proceedings of the 14th IEEE/ACM International Conference on Utility and Cloud Computing},
articleno = {10},
numpages = {10},
keywords = {workflows, serverless, orchestration, event-based, IoT},
location = {Leicester, United Kingdom},
series = {UCC '21}
}

@inproceedings{10.1145/3213299.3213307,
author = {Masip-Bruin, Xavi and Mar\'{\i}n-Tordera, Eva and Juan-Ferrer, Ana and Queralt, Anna and Jukan, Admela and Garcia, Jordi and Lezzi, Daniele and Jensen, Jens and Cordeiro, Cristovao and Leckey, Alexander and Salis, Antonio and Guilhot, Denis and Cankar, Matic},
title = {mF2C: towards a coordinated management of the IoT-fog-cloud continuum},
year = {2018},
isbn = {9781450358576},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3213299.3213307},
doi = {10.1145/3213299.3213307},
abstract = {Fog computing enables location dependent resource allocation and low latency services, while fostering novel market and business opportunities in the cloud sector. Aligned to this trend, we refer to Fog-to-cloud (F2C) computing system as a new pool of resources, set into a layered and hierarchical model, intended to ease the entire fog and cloud resources management and coordination. The H2020 project mF2C aims at designing, developing and testing a first attempt for a real F2C architecture. This document outlines the architecture and main functionalities of the management framework designed in the mF2C project to coordinate the execution of services in the envisioned set of heterogeneous and distributed resources.},
booktitle = {Proceedings of the 4th ACM MobiHoc Workshop on Experiences with the Design and Implementation of Smart Objects},
articleno = {8},
numpages = {8},
keywords = {resources management, fog computing, cloud computing, IoT},
location = {Los Angeles, California},
series = {SMARTOBJECTS '18}
}

@inproceedings{10.1145/1878961.1878963,
author = {Ilderem, Vida},
title = {Embedded market: challenges and opportunities},
year = {2010},
isbn = {9781605589053},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1878961.1878963},
doi = {10.1145/1878961.1878963},
abstract = {There is a convergence trend in the computing, communication and consumer markets and with a forecast of an additional 1 billion connected computing users by 2015, it is of high value to provide a common experience between the devices. Intel's vision of Compute Continuum will enable the users to realize the potential of a seamless cross-device experience with more consistency and accessibility to their information.The convergence trend and the Compute Continuum make System-on-Chip [SoC] a key ingredient for the embedded markets. At Intel Labs, we are focusing on delivering differentiating technology solutions to enable our business partners to successfully capture their targeted market segments. We are working on a variety of research that will enable modular system architecture and silicon technology breakthroughs for rapid customization and integration facilitating faster time-to-market. Intel's vision along with some technology challenges and possible solutions will be highlighted},
booktitle = {Proceedings of the Eighth IEEE/ACM/IFIP International Conference on Hardware/Software Codesign and System Synthesis},
pages = {1–2},
numpages = {2},
keywords = {system-on-a-chip, compute continuum},
location = {Scottsdale, Arizona, USA},
series = {CODES/ISSS '10}
}

@article{10.1145/3592598,
author = {Pallewatta, Samodha and Kostakos, Vassilis and Buyya, Rajkumar},
title = {Placement of Microservices-based IoT Applications in Fog Computing: A Taxonomy and Future Directions},
year = {2023},
issue_date = {December 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {55},
number = {14s},
issn = {0360-0300},
url = {https://doi.org/10.1145/3592598},
doi = {10.1145/3592598},
abstract = {The Fog computing paradigm utilises distributed, heterogeneous and resource-constrained devices at the edge of the network for efficient deployment of latency-critical and bandwidth-hungry IoT application services. Moreover, MicroService Architecture (MSA) is increasingly adopted to keep up with the rapid development and deployment needs of fast-evolving IoT applications. Due to the fine-grained modularity of the microservices and their independently deployable and scalable nature, MSA exhibits great potential in harnessing Fog and Cloud resources, thus giving rise to novel paradigms like Osmotic computing. The loosely coupled nature of the microservices, aided by the container orchestrators and service mesh technologies, enables the dynamic composition of distributed and scalable microservices to achieve diverse performance requirements of the IoT applications using distributed Fog resources. To this end, efficient placement of microservice plays a vital role, and scalable placement algorithms are required to utilise the said characteristics of the MSA while overcoming novel challenges introduced by the architecture. Thus, we present a comprehensive taxonomy of recent literature on microservices-based IoT applications placement within Fog computing environments. Furthermore, we organise multiple taxonomies to capture the main aspects of the placement problem, analyse and classify related works, identify research gaps within each category, and discuss future research directions.},
journal = {ACM Comput. Surv.},
month = {jul},
articleno = {321},
numpages = {43},
keywords = {application placement, Osmotic computing, Internet of Things, microservice architecture, Fog computing}
}

@inproceedings{10.1145/3589010.3594891,
author = {Dazzi, Patrizio},
title = {An Intelligent Continuum for Intelligent Applications},
year = {2023},
isbn = {9798400701641},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589010.3594891},
doi = {10.1145/3589010.3594891},
abstract = {The compute continuum is considered to be just an aggregation of computational entities encompassing a diverse array of resources, ranging from public clouds to edge devices. To facilitate the development of next-generation intelligent applications, we must transcend this restrictive perspective. In this keynote, we present the notion of an "intelligent meta-continuum" - a purpose-driven, adaptable continuum capable of effortlessly amalgamating distributed resources to execute applications in an optimized and scalable manner. The meta-continuum integrates pivotal technological and architectural advances, such as software-defined infrastructure, workload orchestration, microservices, virtualization, and edge computing. Harnessing these enablers, the intelligent meta-continuum offers a flexible foundation for contemporary distributed applications, allowing them to dynamically adapt to highly variable conditions by optimizing their placement and resource utilization based on factors such as bandwidth, latency, cost, and availability. Innovative programming and organizational models, such as the actor model, play a crucial role in actualizing this vision. These models enable the decomposition of applications into discrete, stateful components that intelligently interact across the meta-continuum. The implementation of such models through technologies like containers and serverless computing allows applications to glide effortlessly across infrastructures. The meta-continuum holds the promise of substantial benefits for next-generation applications in domains such as smart cities, industrial automation, healthcare, and autonomous systems. By seamlessly amalgamating resources from cloud to edge, applications can achieve low latency, extensive distribution, mobility, scalability, and cost-efficiency. To fully unlock its potential, however, we must confront prevailing challenges related to interoperability, security, skill development, and organizational transformation.},
booktitle = {Proceedings of the 3rd Workshop on Flexible Resource and Application Management on the Edge},
pages = {1–2},
numpages = {2},
keywords = {programming models, distributed systems, compute continuum, AI},
location = {Orlando, FL, USA},
series = {FRAME '23}
}

@inproceedings{10.1145/3526059.3533620,
author = {Mordacchini, Matteo and Carlini, Emanuele and Dazzi, Patrizio},
title = {A Mathematical Model for Latency Constrained Self-Organizing Application Placement in the Edge},
year = {2022},
isbn = {9781450393102},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3526059.3533620},
doi = {10.1145/3526059.3533620},
abstract = {The highly dynamic and heterogeneous environment that characterizes the edge of the Cloud/Edge Continuum calls for new intelligent methods for tackling the needs of such a complex scenario. In particular, adaptive and self-organizing decentralized solutions have been advanced for optimizing the placement of applications at the Edge. In this paper, we propose a probabilistic mathematical model that allows to describe one of such solutions. The goal of the model is twofold: i) to make it possible to demonstrate the convergence of the proposed solution; ii) to study the impact of the self-organizing solution without the need of an actual implementation or simulation of the system, allowing to evaluate the suitability of the solution in specific contexts. The paper presents the mathematical formulation of the proposed solution as well as the validation of the proposed model against a simulation of the system.},
booktitle = {Proceedings of the 2nd Workshop on Flexible Resource and Application Management on the Edge},
pages = {29–32},
numpages = {4},
keywords = {self-organizing, mathematical model, edge intelligence, cloud/edge continuum, application placement, adaptive},
location = {Minneapolis, MN, USA},
series = {FRAME '22}
}

@inproceedings{10.1145/3502181.3535103,
author = {Ferrucci, Luca and Coppola, Massimo and Kavalionak, Hanna and Kontopoulos, Ioannis},
title = {FRAME 2022: The 2nd Workshop on Flexible Resource and Application Management on the Edge},
year = {2022},
isbn = {9781450391993},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3502181.3535103},
doi = {10.1145/3502181.3535103},
abstract = {The 2nd International Workshop on Flexible Resource and Application Management on the Edge (FRAME 2022) is dedicated to the so-called Cloud/Edge Continuum, where Cloud and Edge infrastructures can work together to fulfill requirements from a variety of NextGen applications. Clouds provide appropriate levels of performance to large groups of different users, whereas Edge resources act as a first layer of computing capacity that is closer to the user, to reduce the service latency. With respect to Clouds, Edge infrastructures typically are composed of heterogeneous and constrained resources and introduce new challenges from the viewpoint of security, orchestration and resource management. Tackling these new issues calls for innovative combinations of tools and abstractions, where AI and machine learning techniques complement algorithmic orchestration and optimization, bringing about new levels of distributed adaptivity and self-management. As real-time data-driven decisions can be promptly taken on the spot, without the need to wait for data to travel to the Cloud and back, also interactive and time-sensitive services like the immersive data processing of Extended Reality (XR) applications can be partially extended toward the edge, thus exploiting a better computation to communication tradeoff and smoother connections to improve their QoE and remote collaboration. The FRAME'22 workshop proceedings are available at: https://dl.acm.org/citation.cfm?id=3526059.},
booktitle = {Proceedings of the 31st International Symposium on High-Performance Parallel and Distributed Computing},
pages = {288–289},
numpages = {2},
keywords = {virtualization, resource management, network mobility, machine learning, federated learning, edge storage, edge orchestration, edge continuum, edge computing, cloud federation, cloud computing, autonomic management, artificial intelligence, 3d point cloud},
location = {Minneapolis, MN, USA},
series = {HPDC '22}
}

@inproceedings{10.1145/3589010.3594887,
author = {Carlini, Emanuele and Dazzi, Patrizio and Tserpes, Konstantinos and Blasi, Lorenzo and Di Girolamo, Marco and Dober, Dariusz},
title = {Innovation Potential of the ACCORDION Platform},
year = {2023},
isbn = {9798400701641},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589010.3594887},
doi = {10.1145/3589010.3594887},
abstract = {The seamless utilization of resources in the cloud-edge spectrum is a key driver for innovation in the ICT sector, as it supports economic growth and strengthens the industry's competitiveness while making next-application services possible with minimal investments and disruption. In this context, the EU project ACCORDION provides an innovative three-layered architecture designed as a comprehensive solution dedicated to latency-aware applications. This paper summarizes the key technological innovations of ACCORDION, highlighting their alignment with the European agenda of the ICT sector.},
booktitle = {Proceedings of the 3rd Workshop on Flexible Resource and Application Management on the Edge},
pages = {33–35},
numpages = {3},
keywords = {resource orchestration, kubernetes, edge federation, edge continuum, application deployment},
location = {Orlando, FL, USA},
series = {FRAME '23}
}

@inproceedings{10.1145/3578245.3584938,
author = {Diaz-de-Arcaya, Josu and Osaba, Eneko and Benguria, Gorka and Etxaniz, I\~{n}aki and L. Lobo, Jesus and Alonso, Juncal and Torre-Bastida, Ana I. and Almeida, Aitor},
title = {IEM: A Unified Lifecycle Orchestrator for Multilingual IaC Deployments},
year = {2023},
isbn = {9798400700729},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3578245.3584938},
doi = {10.1145/3578245.3584938},
abstract = {Over the last few years, DevOps methodologies have promoted a more streamlined operationalization of software components in production environments. Infrastructure as Code (IaC) technologies play a key role in the lifecycle management of applications, as they promote the delivery of the infrastructural elements alongside the application components. This way, IaC technologies aspire to minimize the problems associated with the environment by providing a repeatable and traceable process. However, there are a large variety of IaC frameworks, each of them focusing on a different phase of the operationalization lifecycle, hence the necessity to master numerous technologies. In this research, we present the IaC Execution Manager (IEM), a tool devoted to providing a unified framework for the operationalization of software components that encompasses the various stages and technologies involved in the application lifecycle. We analyze an industrial use case to improve the current approach and conclude the IEM is a suitable tool for solving the problem as it promotes automation, while reducing the learning curve associated with the required IaC technologies.},
booktitle = {Companion of the 2023 ACM/SPEC International Conference on Performance Engineering},
pages = {195–199},
numpages = {5},
keywords = {infrastructure as code, edge, cloud continuum, cloud, IAC, DevsecOps, DevOps},
location = {Coimbra, Portugal},
series = {ICPE '23 Companion}
}

@inproceedings{10.1145/2591888.2591903,
author = {Cellary, Wojciech},
title = {Smart governance for smart industries},
year = {2013},
isbn = {9781450324564},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2591888.2591903},
doi = {10.1145/2591888.2591903},
abstract = {In this paper, we present a vision of smartness as an environment in which humans and devices, visible and unseen, provide a wide range of e-services trying to make a person's life easier, more comfortable and more efficient. Economic and privacy issues are discussed as the most challenging. We argue that only direct income from consumers of e-services may guarantee sustainable development of smart industries. We present threats coming from smart industries and smart governance which may abuse trust of people who are served. We indicate the triple role of smart governance: first, to become smart and avoid a smartness gap between the public and private sectors; second, to boost smart industries, while third, and simultaneously, enforcing the codes of protecting privacy.},
booktitle = {Proceedings of the 7th International Conference on Theory and Practice of Electronic Governance},
pages = {91–93},
numpages = {3},
keywords = {trust, smartness, smart industry, smart government, smart governance, privacy, internet of things, economy, e-services, discrimination, customization, compute continuum},
location = {Seoul, Republic of Korea},
series = {ICEGOV '13}
}

@inproceedings{10.1145/3526059.3533621,
author = {Bano, Saira and Carlini, Emanuele and Cassara', Pietro and Coppola, Massimo and Dazzi, Patrizio and Gotta, Alberto},
title = {A Novel Approach to Distributed Model Aggregation using Apache Kafka},
year = {2022},
isbn = {9781450393102},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3526059.3533621},
doi = {10.1145/3526059.3533621},
abstract = {Multi-Access Edge Computing (MEC) is attracting a lot of interest because it complements cloud-based approaches. Indeed, MEC is opening up in the direction of reducing both interaction delays and data sharing, called Cyber-Physical Systems (CPSs). In the near fu- ture, edge technologies will be a fundamental tool to better support time-dependent and data-intensive applications. In this context, this work explores existing and emerging platforms for MEC and human-centric applications, and proposes a suitable architecture that can be used in the context of autonomous vehicle systems.The proposed architecture will support scalable communication among sensing devices and edge/cloud computing platforms, as well as orchestrate services for computing, storage, and learning with the use of an Information-centric paradigm such as Apache Kafka},
booktitle = {Proceedings of the 2nd Workshop on Flexible Resource and Application Management on the Edge},
pages = {33–36},
numpages = {4},
keywords = {edge intelligence, cloud/edge continuum},
location = {Minneapolis, MN, USA},
series = {FRAME '22}
}

@inproceedings{10.1145/3609389.3610564,
author = {Reisacher, Marco and Frank, Reinhard and Blenk, Andreas},
title = {FactoryDC: Network and Resource Planning for Emerging Applications in Future Factories},
year = {2023},
isbn = {9798400703027},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3609389.3610564},
doi = {10.1145/3609389.3610564},
abstract = {Today's industrial factory networks have neither been designed for traffic demands of new applications that use machine learning (ML) nor have they considered a deep connection with the cloud. Accordingly, there is a lack of knowledge w.r.t how to plan new factory networks given the new demands of applications using ML and network technology opportunities. We argue that within widely-spanned factory networks, there is indeed a high potential to bring the context of ML applications into consideration. It is important to plan and evaluate different topologies to accommodate said demands. In this paper, we propose a method of analyzing ML models, a network planning concept, and a tool bringing data center networks and factory layouts with ML in mind together. We illustrate and evaluate the proposed method with a concrete use case. The results demonstrate the need for new planning procedures in factories. In particular, they show the impact of flexible network architectures on factory traffic.},
booktitle = {Proceedings of the 1st Workshop on Enhanced Network Techniques and Technologies for the Industrial IoT to Cloud Continuum},
pages = {1–7},
numpages = {7},
keywords = {optimization, network planning, machine learning network traffic, data center topology, factory network, industrial networks},
location = {New York, NY, USA},
series = {IIoT-NETs '23}
}

@inproceedings{10.1145/3452369.3463816,
author = {Korontanis, Ioannis and Tserpes, Konstantinos and Pateraki, Maria and Blasi, Lorenzo and Violos, John and Diego, Ferran and Marin, Eduard and Kourtellis, Nicolas and Coppola, Massimo and Carlini, Emanuele and Ledwo\'{n}, Zbyszek and Tarkowski, Przemys\l{}aw and Loven, Thomas and Rozas, Yago Gonz\'{a}lez and Kentros, Mike and Dodis, Michael and Dazzi, Patrizio},
title = {Inter-operability and Orchestration in Heterogeneous Cloud/Edge Resources: The ACCORDION Vision},
year = {2021},
isbn = {9781450383844},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3452369.3463816},
doi = {10.1145/3452369.3463816},
abstract = {This paper introduces the ACCORDION framework, a novel framework for the management of the cloud-edge continuum, targeting the support of NextGen applications with strong QoE requirements. The framework addresses the need for an ever expanding and heterogeneous pool of edge resources in order to deliver the promise of ubiquitous computing to the NextGen application clients. This endeavor entails two main technical challenges. First, to assure interoperability when incorporating heterogeneous infrastructures in the pool. Second, the management of the largely dynamic pool of edge nodes. The optimization of the delivered QoE stands as the core driver to this work, therefore its monitoring and modelling comprises a core part of the conducted work. The paper discusses the main pillars that support the ACCORDION vision, and provide a description of the three planned use case that are planned to demonstrate ACCORDION capabilities.},
booktitle = {Proceedings of the 1st Workshop on Flexible Resource and Application Management on the Edge},
pages = {9–14},
numpages = {6},
keywords = {federation, edge, cloud, architecture},
location = {Virtual Event, Sweden},
series = {FRAME '21}
}

@inproceedings{10.1145/3590837.3590921,
author = {Legierski, Jaroslaw and Rachwal, Kajetan and Sowinski, Piotr and Niewolski, Wojciech and Ratuszek, Przemyslaw and Kopertowski, Zbigniew and Paprzycki, Marcin and Ganzha, Maria},
title = {Towards Edge-Cloud Architectures for Personal Protective Equipment Detection},
year = {2023},
isbn = {9781450399937},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3590837.3590921},
doi = {10.1145/3590837.3590921},
abstract = {Detecting Personal Protective Equipment in images and video streams is a relevant problem in ensuring the safety of construction workers. In this contribution, an architecture enabling live image recognition of such equipment is proposed. The solution is deployable in two settings – edge-cloud and edge-only. The system was tested on an active construction site, as a part of a larger scenario, within the scope of the ASSIST-IoT H2020 project. To determine the feasibility of the edge-only variant, a model for counting people wearing safety helmets was developed using the YOLOX method. It was found that an edge-only deployment is possible for this use case, given the hardware infrastructure available on site. In the preliminary evaluation, several important observations were made, that are crucial to the further development and deployment of the system. Future work will include an in-depth investigation of performance aspects of the two architecture variants.},
booktitle = {Proceedings of the 4th International Conference on Information Management &amp; Machine Intelligence},
articleno = {84},
numpages = {6},
keywords = {worker safety, image recognition, edge-cloud continuum architectures, PPE detection},
location = {Jaipur, India},
series = {ICIMMI '22}
}

@inproceedings{10.1145/3609389.3610567,
author = {Makhijani, Kiran and Li, Richard and Tahiliani, Mohit and Westphal, Cedric and Dong, Lijun},
title = {Operations and Control Networks (OCN) Model: A Systematic Approach to Operational and Information Technology Convergence},
year = {2023},
isbn = {9798400703027},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3609389.3610567},
doi = {10.1145/3609389.3610567},
abstract = {Convergence between Operational Technology (OT) and Information Technology (IT) remains an aspirational goal due to the lack of a systematic integrated approach. The next-generation Industry 4.0 will automate operations even more, involving different degrees of coordination, multiple locations, applications, and organizations. Eventually, the network's capabilities and technologies will integrate OT and IT. This paper presents a reference model called Operations and Control Networks (OCN), whose components are abstract exchange points between which automation takes place. Such network model for process control can be used as a tool for system integrators and operators to design and analyze their OT networks. It enables OT applications to be developed independently of the underlying network infrastructure. We discuss principles, interfaces, and examples of this model.},
booktitle = {Proceedings of the 1st Workshop on Enhanced Network Techniques and Technologies for the Industrial IoT to Cloud Continuum},
pages = {22–28},
numpages = {7},
location = {New York, NY, USA},
series = {IIoT-NETs '23}
}

@inproceedings{10.1145/3609389.3610568,
author = {Eppler, Manuel and Schenk, Jochen and Gruner, Tobias and Zirkler, Andreas and Mueller, Harald and Blenk, Andreas},
title = {FabOS: Hooking up Container Platforms with Time-Sensitive Networks},
year = {2023},
isbn = {9798400703027},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3609389.3610568},
doi = {10.1145/3609389.3610568},
abstract = {There is no holistic approach that provides a full implementation and integration of flexible container platforms with time-sensitive networks in industrial factories yet. This hinders innovation and also withhelds the advantages of flexible infrastructure from industrial network operators --- a clear miss of optimization opportunities. To fill this gap, this paper proposes the FabOS architecture: a Kubernetes and Time-Sensitive-Networking-based architecture. Hence, FabOS provides flexible processing and deterministic networking for future industrial factories. With FabOS, use case developers can for the first time specify and implement applications that are deployed on Kubernetes connected via a time-sensitive network. Measurements taken from a proof-of-concept implementation demonstrate that future factories can benefit from bringing together container platforms and real-time networking.},
booktitle = {Proceedings of the 1st Workshop on Enhanced Network Techniques and Technologies for the Industrial IoT to Cloud Continuum},
pages = {29–34},
numpages = {6},
keywords = {network controller, kubernetes, time-sensitive networking, architecture, industrial networking},
location = {New York, NY, USA},
series = {IIoT-NETs '23}
}

@inproceedings{10.1145/3609389.3610565,
author = {Hayes, John and Aneiba, Adel and Gaber, Mohamed},
title = {SymbIoT: Towards An Extensible Blockchain Integration Testbed for IIoT},
year = {2023},
isbn = {9798400703027},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3609389.3610565},
doi = {10.1145/3609389.3610565},
abstract = {This paper presents SymbIoT, an extensible hybrid simulation-emulation testbed to investigate the integration of blockchain and distributed ledger technology (DLT) within the Industrial Internet of Things (IIoT) continuum. By adopting a joint software and hardware-based approach, we amalgamate the flexibility of software solutions and the real-world applicability offered by integrating comparable IoT hardware. The versatility of SymbIoT lies in its extensibility, offering flexibility in parameters including consensus algorithms, block size, node count and topology, throughput limitation, and use-case application deployment. SymbIoT facilitates comprehensive empirical studies of blockchain implementations within IIoT, focusing on performance, scalability, and security considerations. The testbed provides a platform for innovative and pragmatic experimentation in blockchain and IIoT integration, holding promise for shaping future applications and solutions in this cross-disciplinary field. We also present results from preliminary experimentation, indicating the applicability of the testbed for IIoT and broader IoT-to-cloud scenarios.},
booktitle = {Proceedings of the 1st Workshop on Enhanced Network Techniques and Technologies for the Industrial IoT to Cloud Continuum},
pages = {8–14},
numpages = {7},
keywords = {IIoT, testbed, IoT, blockchain},
location = {New York, NY, USA},
series = {IIoT-NETs '23}
}

@inproceedings{10.1145/3609389.3610566,
author = {Rosa, Lorenzo and Garbugli, Andrea and Patera, Lorenzo and Foschini, Luca},
title = {Supporting vPLC Networking over TSN with Kubernetes in Industry 4.0},
year = {2023},
isbn = {9798400703027},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3609389.3610566},
doi = {10.1145/3609389.3610566},
abstract = {The shift in the industrial ecosystem from closed and specialized technologies to the open and general-purpose vision of Industry 4.0 faces numerous challenges. The absence of viable solutions to replace Programmable Logic Controllers (PLCs), vital components in control infrastructures, with their virtual equivalent (vPLCs) embodies those difficulties. In this paper, we introduce a framework that aims at truly materializing the integration between Operational (OT) and Information Technologies (IT) by defining an open, general ecosystem around vPLCs. Previous work either could not meet the performance and determinism requirements of the OT or did so by sacrificing the generality of IT. Building on these experiences, our framework provides both flexibility and efficiency by clearly separating the data path for OT and IT communications. To do that, we integrate tools from both domains: techniques to ensure low network performance and variability (TSN), to ease portability (OPC-UA), and to enhance management and deployment (Kubernetes). Experiments on a real testbed show that vPLCs within our framework can meet strict performance requirements and yet provide the same flexibility as cloud-based applications.},
booktitle = {Proceedings of the 1st Workshop on Enhanced Network Techniques and Technologies for the Industrial IoT to Cloud Continuum},
pages = {15–21},
numpages = {7},
keywords = {DPDK, OPC-UA, kubernetes, TSN, industry 4.0, vPLC},
location = {New York, NY, USA},
series = {IIoT-NETs '23}
}

@inproceedings{10.1145/3555776.3577840,
author = {Heeb, Zeno and Kalinagac, Onur and Soussi, Wissem and G\"{u}r, G\"{u}rkan},
title = {IoMiRCA: Root cause analysis in IoT-extended 5G microservice environments},
year = {2023},
isbn = {9781450395175},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3555776.3577840},
doi = {10.1145/3555776.3577840},
abstract = {Softwarized services in converged networks are evolving from monolithic applications to distributed architectures, often comprising numerous microservices. At the same time, with the massive proliferation of IoT devices, much more complexity and diversity are added to such critical infrastructures. In that regard, Root Cause Analysis (RCA) is an important part of a running distributed service ecosystem to keep the applications available and manageable by finding the root causes of errors and malfunctions. This paper provides a topology graph based anomaly detection and RCA solution for the microservice architecture in edge-to-cloud environments entailing microservices in combination with IoT.},
booktitle = {Proceedings of the 38th ACM/SIGAPP Symposium on Applied Computing},
pages = {106–108},
numpages = {3},
keywords = {edge-to-cloud continuum, 5G and beyond, microservices, critical infrastructure management, root cause analysis},
location = {Tallinn, Estonia},
series = {SAC '23}
}

@inproceedings{10.1145/3609389.3610570,
author = {Barahouei Pasandi, Hannaneh and Moradbeikie, Azin and Barros, Daniel and Verde, David and Paiva, Sara and Lopes, Sergio Ivan},
title = {Improving BLE Fingerprint Radio Maps: A Method based on Fuzzy Clustering and Weighted Interpolation},
year = {2023},
isbn = {9798400703027},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3609389.3610570},
doi = {10.1145/3609389.3610570},
abstract = {Conventional localization methods like GNSS face limitations in accuracy, power consumption, and cost within indoor environments. Bluetooth Low Energy (BLE) technology and the fingerprint method have emerged as popular options for short-range networks. Although fingerprint-based localization offers accurate position estimation, it suffers from drawbacks such as the requirement for a complete map and frequent map updates. To address the issue of incomplete signal maps, this study proposes a novel approach that incorporates fuzzy clustering to generate candidate locations and weighted interpolation to estimate the final location by considering the impact of walls on the environment's signal. A Neural Network (NN) is employed to approximate the object's location relative to walls, providing precise weights for candidate positions and enhancing estimation accuracy. Evaluation results obtained from an office environment demonstrate a remarkable 15% improvement in positioning accuracy, affirming the potential of our approach for real-world industry-driven applications.},
booktitle = {Proceedings of the 1st Workshop on Enhanced Network Techniques and Technologies for the Industrial IoT to Cloud Continuum},
pages = {41–47},
numpages = {7},
location = {New York, NY, USA},
series = {IIoT-NETs '23}
}

@inproceedings{10.1145/3609389.3610569,
author = {ROUTRAY, KASTURI and Bera, Padmalochan},
title = {Context-Aware Attribute Based Access Control for Cloud-based SCADA Systems},
year = {2023},
isbn = {9798400703027},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3609389.3610569},
doi = {10.1145/3609389.3610569},
abstract = {Cloud-based SCADA (Supervisory Control and Data Acquisition) systems enable seamless access to internet of things (IoT) operational data for employees at control facilities and operators working on the field for automated control and monitoring of industrial infrastructure. In this work, we introduced a novel approach based on ciphertext policy attribute-based encryption (CP-ABE) to ensure secure and fine-grained access control over data stored in the cloud. Our proposed scheme considers static and dynamic attributes of the users to devise an access policy. Contextual locks are introduced for defining constraints on dynamic attributes. These locks are independent of the user's attribute sets; thus, they don't require decryption keys to be associated with dynamic attributes. This avoids system overhead with frequent changes in contextual parameters. To protect the confidentiality of the access policy, we obfuscate its attributes during the data-sharing process. Moreover, our proposed scheme prevents key escrow attacks on cloud-stored data. Additionally, fog servers are employed to verify the user's contextual attributes and reduce the computational overhead of decryption for end users. Our scheme enhances the security and integrity of remote process control and monitoring in industrial systems while leveraging the benefits of real-time data analysis and decision-making.},
booktitle = {Proceedings of the 1st Workshop on Enhanced Network Techniques and Technologies for the Industrial IoT to Cloud Continuum},
pages = {35–40},
numpages = {6},
keywords = {policy obfuscation, context-aware, attribute-based encryption, access control},
location = {New York, NY, USA},
series = {IIoT-NETs '23}
}

@inproceedings{10.1145/3412841.3444962,
author = {Lan, Dapeng and Liu, Yu and Taherkordi, Amir and Eliassen, Frank and Delbruel, St\'{e}phane and Lei, Liu},
title = {A federated fog-cloud framework for data processing and orchestration: a case study in smart cities},
year = {2021},
isbn = {9781450381048},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3412841.3444962},
doi = {10.1145/3412841.3444962},
abstract = {The fog computing paradigm has been proposed to alleviate the pressures on cloud platforms for data processing and enable computation-intensive and delay-sensitive applications in smart cities. However, state-of-the-art approaches mainly advocate either cloud-or fog-based data processing solutions, and they also lack a common framework for programming over the fog-cloud continuum. In this paper, we propose a distributed, fog-cloud data processing and orchestration framework, which is capable of exploiting the semantics of both fog platforms and the Cloud. Our framework can create on-demand process engine data flow (PEDF) spanning multiple device layers with various resource constraints. This will considerably help the developers rapidly develop and deploy data processing applications over the fog-cloud continuum. Our proposed framework is validated in a real-world scenario---IoT data streaming analytics for the smart green wall in a smart city---which demonstrates efficient resource usage and latency reduction.},
booktitle = {Proceedings of the 36th Annual ACM Symposium on Applied Computing},
pages = {729–736},
numpages = {8},
keywords = {smart city, orchestration, fog computing, data processing, cloud computing},
location = {Virtual Event, Republic of Korea},
series = {SAC '21}
}

@inproceedings{10.1145/3469263.3470828,
author = {Hetzel, Raphael and K\"{a}rkk\"{a}inen, Teemu and Ott, J\"{o}rg},
title = {μActor: Stateful Serverless at the Edge},
year = {2021},
isbn = {9781450386036},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3469263.3470828},
doi = {10.1145/3469263.3470828},
abstract = {Serverless computing has the potential to produce a universal service platform by integrating an execution environment into networked devices. However, current serverless solutions are often limited to the cloud, Linux-based devices, and stateless functions. In this paper, we propose to integrate the actor model of computation with content-based networking to produce a serverless computing platform that can run on all devices from microcontrollers to cloud servers. We present the model of computation, a platform to realize it, a proof-of-concept implementation, and its evaluation. The resulting system is capable of placing interconnected serverless computations over the entire leaf-edge-cloud continuum.},
booktitle = {Proceedings of the 1st Workshop on Serverless Mobile Networking for 6G Communications},
pages = {1–6},
numpages = {6},
keywords = {uActor, serverless, content-based networking, actor model, μActor},
location = {Virtual, WI, USA},
series = {MobileServerless'21}
}

@inproceedings{10.1145/3526059.3533619,
author = {Blasi, Lorenzo and Toro, Andrea and Di Girolamo, Marco and Tserpes, Konstantinos},
title = {A Minicloud Specification Enabling the Federation of Heterogeneous Edge Resources for Latency Sensitive Applications' Requirements},
year = {2022},
isbn = {9781450393102},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3526059.3533619},
doi = {10.1145/3526059.3533619},
abstract = {We assume a computing infrastructure that implements a cloud-to-edge continuum by federating heterogeneous resources. This infrastructure enables next generation (nextgen) QoE-intensive applications, by facilitating one of their critical requirements: latency. As such each node is identified primarily in terms of latency and secondarily in terms of, more traditional, computational capacity and availability characteristics. Since this infrastructure is dependent on the existing, local, and potentially third-party owned resources, we must address the pertinent problem of resource heterogeneity. This paper delineates the technical specifications of the solution that was designed to tackle the problem, creating a software stack that comprises a complete environment for the orchestration of containerized and VM-based workflows. The solution, dubbed "Minicloud", allows the underlying resource to be federated from a higher-level continuum management layer and be used for the deployment of nextgen apps based on latency requirements. Based on lightweight Kubernetes-oriented technologies and tools, it maintains minimum dependencies allowing a wide range of underlying OSs and system architectures to be supported.},
booktitle = {Proceedings of the 2nd Workshop on Flexible Resource and Application Management on the Edge},
pages = {15–18},
numpages = {4},
keywords = {vim, kubernetes, federation, edge},
location = {Minneapolis, MN, USA},
series = {FRAME '22}
}

@inproceedings{10.1145/3589806.3600032,
author = {Rosendo, Daniel and Keahey, Kate and Costan, Alexandru and Simonin, Matthieu and Valduriez, Patrick and Antoniu, Gabriel},
title = {KheOps: Cost-effective Repeatability, Reproducibility, and Replicability of Edge-to-Cloud Experiments},
year = {2023},
isbn = {9798400701764},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589806.3600032},
doi = {10.1145/3589806.3600032},
abstract = {Distributed infrastructures for computation and analytics are now evolving towards an interconnected ecosystem allowing complex scientific workflows to be executed across hybrid systems spanning from IoT Edge devices to Clouds, and sometimes to supercomputers (the Computing Continuum). Understanding the performance trade-offs of large-scale workflows deployed on such complex Edge-to-Cloud Continuum is challenging. To achieve this, one needs to systematically perform experiments, to enable their reproducibility and allow other researchers to replicate the study and the obtained conclusions on different infrastructures. This breaks down to the tedious process of reconciling the numerous experimental requirements and constraints with low-level infrastructure design choices. To address the limitations of the main state-of-the-art approaches for distributed, collaborative experimentation, such as Google Colab, Kaggle, and Code Ocean, we propose KheOps, a collaborative environment specifically designed to enable cost-effective reproducibility and replicability of Edge-to-Cloud experiments. KheOps is composed of three core elements: (1) an experiment repository; (2) a notebook environment; and (3) a multi-platform experiment methodology. We illustrate KheOps with a real-life Edge-to-Cloud application. The evaluations explore the point of view of the authors of an experiment described in an article (who aim to make their experiments reproducible) and the perspective of their readers (who aim to replicate the experiment). The results show how KheOps helps authors to systematically perform repeatable and reproducible experiments on the Grid5000 + FIT IoT LAB testbeds. Furthermore, KheOps helps readers to cost-effectively replicate authors experiments in different infrastructures such as Chameleon Cloud + CHI@Edge testbeds, and obtain the same conclusions with high accuracies (&gt; 88% for all performance metrics).},
booktitle = {Proceedings of the 2023 ACM Conference on Reproducibility and Replicability},
pages = {62–73},
numpages = {12},
keywords = {Workflows, Reproducibility, Replicability, Repeatability, Edge Computing, Computing Continuum, Cloud Computing},
location = {Santa Cruz, CA, USA},
series = {ACM REP '23}
}

@inproceedings{10.1145/3368235.3368884,
author = {Bittencourt, Luiz Fernando and Schulze, Bruno Richard and Tolosana-Calasanz, Rafael},
title = {12th IEEE/ACM International UCC/BDCAT'19 CloudAM'19 Workshop Chairs' Welcome Message &amp; Organization},
year = {2019},
isbn = {9781450370448},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3368235.3368884},
doi = {10.1145/3368235.3368884},
abstract = {Welcome to the 8th International Workshop on Cloud and Edge Computing, and Applications Management - CloudAM2019, which will be held in conjunction with the 12th IEEE/ACM Utility and Cloud Computing Conference (UCC) in Auckland, New Zealand, from 2-5 December 2019. CloudAM is a successful series of workshops that bring together practitioners and researchers on current research advances on cloud computing, virtualization technologies and real applications. As it is anticipated that this interest will keep expanding with the emergence of edge computing infrastructures, this 8th edition of CloudAM will also cover the topics of edge and fog computing. Cloud and edge infrastructures can work together to fulfill requirements from a variety of applications, composing the so-called Cloud Continuum to the edge. Furthermore, clouds must provide appropriate levels of performance to large groups of diverse users, and those clouds are accessed through virtualized wide area networks, where edge/fog devices can act as a first layer of computing capacity closer to the user. Management systems are essential for that and thereby for the future success of the fog-cloud hierarchy. New systems, methods, and approaches for cloud and edge computing, virtualization, and applications management are to be discussed at this workshop. In this edition of CloudAM, we received six submissions and we could only accept three of them. On the other hand, another the CloudAM program also includes nine high-quality papers that were submitted to the UCC main track and directed for presentation in the workshop. All papers were reviewed and evaluated based on relevance, quality, and novelty. Overall, a number of 12 contributions, covering a broad number of topics, will be presented and discussed during a one-day workshop.},
booktitle = {Proceedings of the 12th IEEE/ACM International Conference on Utility and Cloud Computing Companion},
pages = {1–2},
numpages = {2},
keywords = {welcome message, cloudam},
location = {Auckland, New Zealand},
series = {UCC '19 Companion}
}

@inproceedings{10.1145/3589013.3596676,
author = {Phalak, Chetan and Chahal, Dheeraj and Ramesh, Manju and Singhal, Rekha},
title = {mSIRM: Cost-Efficient and SLO-aware ML Load Balancing on Fog and Multi-Cloud Network},
year = {2023},
isbn = {9798400701665},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589013.3596676},
doi = {10.1145/3589013.3596676},
abstract = {The use of intelligent sensors and edge devices has grown exponentially for automation in the industry to hyper-personalize applications, minimize cost, improve efficiency, and optimize operations. In a typical Internet-of-Thing (IoT) workflow, pre-trained machine-learning (ML) models are placed on edge devices. These devices have limited resources to serve the incoming load and hence judicious capacity planning is required to address future workloads. This generally results in the over-provisioning or under-provisioning of the resources.Cloud offers a flexible infrastructure for unpredictable workloads faced by on-premise instances but at the cost of increased latency. Fog devices and spatially closer-to-edge devices act as intermediaries to cloud resources with lower latency, however, suffer from capacity planning challenges. These challenges can be mitigated by the use of appropriate cloud services and resource configuration. In this work, we present a Multi-cloud System for Inference Request Management (mSIRM) for the edge-fog-cloud continuum. mSIRM has capabilities for serving dynamically varying machine learning inference workloads using flexible infrastructure across different cloud vendors. Furthermore, we show that the use of multiple clouds with different services in conjunction with the fog computing resources results in a significant drop in Service Level Objective (SLO) violations. Specifically, we compare the edge-cloud frameworks developed using machine learning and serverless platforms from popular cloud service providers.},
booktitle = {Proceedings of the 13th Workshop on AI and Scientific Computing at Scale Using Flexible Computing},
pages = {19–26},
numpages = {8},
keywords = {inference serving, cost minimization, SLO awareness, MLaaS},
location = {Orlando, FL, USA},
series = {FlexScience '23}
}

@article{10.1145/3502771.3502781,
author = {Nguyen, Phu H. and Sen, Sagar and Jourdan, Nicolas and Cassoli, Beatriz and Myrseth, Per and Armendia, Mikel and Myklebust, Odd},
title = {Software Engineering and AI for Data Quality in Cyber- Physical Systems - SEA4DQ'21 Workshop Report},
year = {2022},
issue_date = {January 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {47},
number = {1},
issn = {0163-5948},
url = {https://doi.org/10.1145/3502771.3502781},
doi = {10.1145/3502771.3502781},
abstract = {Cyber-physical systems (CPS) have been developed in many industrial sectors and application domains in which the quality requirements of data acquired are a common factor. Data quality in CPS can deteriorate because of several factors such as sensor faults and failures due to operating in harsh and uncertain environments. How can software engineering and artificial intelligence (AI) help manage and tame data quality issues in CPS? This is the question we aimed to investigate in the SEA4DQ workshop. Emerging trends in software engineering need to take data quality management seriously as CPS are increasingly datacentric in their approach to acquiring and processing data along the edge-fog-cloud continuum. This workshop provided researchers and practitioners a forum for exchanging ideas, experiences, understanding of the problems, visions for the future, and promising solutions to the problems in data quality in CPS. Examples of topics include software/hardware architectures and frameworks for data quality management in CPS; software engineering and AI to detect anomalies in CPS data or to repair erroneous CPS data. SEA4DQ 2021, which took place on August 24th, 2021 was a satellite event of the ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering (ESEC / FSE) 2021. The workshop attracted 35 international participants and was exciting with a great keynote, six excellent presentations, and concluded on a high note with a panel discussion. SEA4DQ was motivated by the common research interests from the EU projects for Zero-Defects Manufacturing such as InterQ and Dat4.Zero.},
journal = {SIGSOFT Softw. Eng. Notes},
month = {jan},
pages = {26–29},
numpages = {4}
}

@article{10.1145/3191758,
author = {Mosenia, Arsalan and Bechara, Jad F. and Zhang, Tao and Mittal, Prateek and Chiang, Mung},
title = {ProCMotive: Bringing Programmability and Connectivity into Isolated Vehicles},
year = {2018},
issue_date = {March 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {1},
url = {https://doi.org/10.1145/3191758},
doi = {10.1145/3191758},
abstract = {In recent years, numerous vehicular technologies, e.g., cruise control and steering assistant, have been proposed and deployed to improve the driving experience, passenger safety, and vehicle performance. Despite the existence of several novel vehicular applications in the literature, there still exists a significant gap between resources needed for a variety of vehicular (in particular, data-dominant, latency-sensitive, and computationally-heavy) applications and the capabilities of already-in-market vehicles. To address this gap, different smartphone-/Cloud-based approaches have been proposed that utilize the external computational/storage resources to enable new applications. However, their acceptance and application domain are still very limited due to programmability, wireless connectivity, and performance limitations, along with several security/privacy concerns.In this paper, we present a novel reference architecture that can potentially enable rapid development of various vehicular applications while addressing shortcomings of smartphone-/Cloud-based approaches. The architecture is formed around a core component, called SmartCore, a privacy/security-friendly programmable dongle that brings general-purpose computational and storage resources to the vehicle and hosts in-vehicle applications. Based on the proposed architecture, we develop an application development framework for vehicles, that we call ProCMotive. ProCMotive enables developers to build customized vehicular applications along the Cloud-to-edge continuum, i.e., different functions of an application can be distributed across SmartCore, the user's personal devices, and the Cloud.In order to highlight potential benefits that the framework provides, we design and develop two different vehicular applications based on ProCMotive, namely, Amber Response and Insurance Monitor. We evaluate these applications using real-world data and compare them with state-of-the-art technologies.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = {mar},
articleno = {26},
numpages = {31},
keywords = {Smartphone, Smart vehicles, Security, Programmability, Privacy, Performance, Internet connectivity, Cloud, Architecture, Application development}
}

@inproceedings{10.5555/3578948.3578967,
author = {Schu\ss{}, Markus and Boano, Carlo Alberto and Baddeley, Michael and Prakash, Monika and Romer, Kay},
title = {Poster: Towards a Federated Testbed Infrastructure for Geographically-Distributed Low-Power Wireless Systems},
year = {2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Several IoT testbeds have been designed to test and push the performance of low-power wireless networking protocols to the limit. However, they mostly target low-power wireless systems operating in isolation, and are unable to precisely characterize the performance of solutions operating across multiple sites or interacting with cloud resources. As advances in backbone communication networks allow to move towards decentralized IoT deployments, there is a growing need to understand the impact of the Internet on the timeliness and reliability of end-to-end communications. In this poster, we outline the necessary steps to evolve D-Cube, a full-fledged benchmarking infrastructure, into a federated testbed capable of measuring the performance of low-power wireless systems operating across multiple sites through the Internet, thereby enabling research on the next-generation IoT systems operating on a mesh-cloud continuum.},
booktitle = {Proceedings of the 2022 International Conference on Embedded Wireless Systems and Networks},
pages = {192–193},
numpages = {2},
location = {<conf-loc>, <city>Linz</city>, <country>Austria</country>, </conf-loc>},
series = {EWSN '22}
}

@article{10.1145/3594539,
author = {Lumpp, Francesco and Panato, Marco and Bombieri, Nicola and Fummi, Franco},
title = {A Design Flow based on Docker and Kubernetes for ROS-based Robotic Software Applications},
year = {2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1539-9087},
url = {https://doi.org/10.1145/3594539},
doi = {10.1145/3594539},
abstract = {Human-centered robotic applications are becoming pervasive in the context of robotics and smart manufacturing and such a pervasiveness is even more expected with the shift to Industry 5.0. The always increasing level of autonomy of modern robotic platforms requires the integration of software applications from different domains to implement artificial intelligence, cognition, and human-robot/robot-robot interaction. Developing and (re)configuring such a multi-domain software to meet functional constraints is a challenging task. Even more challenging is customizing the software to satisfy non-functional requirements such as real-time, reliability, and energy efficiency. In this context, the concept of Edge-Cloud continuum is gaining consensus as a solution to address functional and non-functional constraints in a seamless way. Containerization and orchestration are becoming a standard practice as they allow for better information flow among different network levels as well as increased modularity in the use of multi-domain software components. Nevertheless, the adoption of such a practice along the design flow, from simulation to the deployment of complex robotic applications by addressing the de-facto development standards (e.g., ROS - Robotic Operating System) is still an open problem. We present a design methodology based on Docker and Kubernetes that enables containerization and orchestration of ROS-based robotic SW applications for heterogeneous and hierarchical HW architectures. The methodology aims at (i) integrating and verifying multi-domain components since early in the design flow, (ii) mapping software tasks to containers to minimize the performance and memory footprint overhead, (iii) clustering containers to efficiently distribute load across the edge-cloud architecture by minimizing resource utilization, and (iv) enabling multi-domain verification of functional and non-functional constraints before deployment. The article presents the results obtained with a real case of study, in which the design methodology has been applied to program the mission of a Robotnik RB-Kairos mobile robot in an industrial agile production chain. We have obtained reduced load on the robot’s HW with minimal performance and network overhead thanks to the optimized distributed system.},
note = {Just Accepted},
journal = {ACM Trans. Embed. Comput. Syst.},
month = {apr},
keywords = {Edge-Cloud computing, Robotic applications, K3S, Kubernetes, Docker, ROS}
}

@inproceedings{10.1145/3502181.3535102,
author = {Costan, Alexandru and Nicolae, Bogdan and Sato, Kento},
title = {FlexScience'22: 12th Workshop on AI and Scientific Computing at Scale using Flexible Computing Infrastructures},
year = {2022},
isbn = {9781450391993},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3502181.3535102},
doi = {10.1145/3502181.3535102},
abstract = {Scientific computing applications generate enormous datasets that are continuously increasing exponentially in both complexity and volume, making their analysis, archival, and sharing one of the grand challenges of modern big data analytics. Supported by the rise of artificial intelligence and deep learning, such enormous datasets are becoming valuable resources even beyond their original scope, opening new opportunities to learn patterns and extract new knowledge at large scale, potentially without human intervention. However, this leads to an increasing complexity of the workflows that combine traditional HPC simulations with big data analytics and AI applications. An initial wave that opened this direction was the shift from compute-intensive to data-intensive, which saw several ideas from big data analytics (in-situ processing, shipping computations close to data, complex and dynamic workflows) fused with the tightly coupled patterns addressed by the AI and the high performance computing ecosystems. In a quest to keep up with the complexity of the workflows, the design and operation of the infrastructures capable of running them efficiently at scale has evolved accordingly. Extreme heterogeneity at all levels (combinations of CPUs and accelerators, various types of memories and local storage and network links, parallel file systems and object stores, etc.) is now the norm. ideas pioneered by cloud and edge computing (aspects related to elasticity, multi-tenancy, geo-distributed processing, stream computing) are also beginning to be adopted in the HPC ecosystem (containerized workflows, on-demand jobs to complement batch jobs, streaming of experimental data from instruments directly to supercomputers, etc.). Thus, modern scientific applications need to be integrated into an entire Compute Continuum from the edge all the way to supercomputers and large data-centers using flexible infrastructures and middlewares. The 12th workshop on AI and Scientific Computing at Scale using Flexible Computing Infrastructures (FlexScience) will provide the scientific community a dedicated forum for discussing new research, development, and deployment efforts in running scientific computing workloads in such flexible ecosystems, across the Computing Continuum, focusing on emerging technologies and new convergence challenges that are not sufficiently addressed by the current generation of supercomputers and dedicated data centers. The workshop aims to address questions such as: what architectural changes to existing frameworks (hardware, operating systems, networking and/or programming models) are needed to support flexible computing? Dynamic information derived from remote instruments, coupled simulations, and sensor ensembles that stream data for real-time analysis and machine learning are important emerging trends. How can we leverage and adapt to these patterns? What scientific workloads are suitable candidates to take advantage of heterogeneity, elasticity and/or on-demand resources? What factors are limiting the adoption of a flexible design?The workshop encourages interaction and cross-pollination between participants that are developing applications, algorithms, middleware and infrastructure and that are facing new challenges and opportunities to take advantage of flexible computing. The workshop will be an excellent place to help the community define the current state, determine future goals, and discuss promising technologies and techniques.},
booktitle = {Proceedings of the 31st International Symposium on High-Performance Parallel and Distributed Computing},
pages = {287},
numpages = {1},
keywords = {scientific computing, edge processing, computing continuum, cloud computing, artificial intelligence},
location = {Minneapolis, MN, USA},
series = {HPDC '22}
}

@inproceedings{10.1145/3492323.3495589,
author = {Spillner, Josef},
title = {Self-balancing architectures based on liquid functions across computing continuums},
year = {2022},
isbn = {9781450391634},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3492323.3495589},
doi = {10.1145/3492323.3495589},
abstract = {Scalable application development is highly influenced by two major trends - serverless computing and continuum computing. These trends have had little intersection, as most application architectures, even when following a microservices or function-based approach, are built around rather monolithic Function-as-a-Service engines that do not span continuums. Functions are thus separated code-wise but not infrastructure-wise, as they continue to run on the same single platform they have been deployed to. Moreover, developing and deploying distributed applications remains non-trivial and is a hurdle for enhancing the capabilities of mobile and sensing domains. To overcome this limitation, the concept of self-balancing architectures is introduced in which liquid functions traverse cloud and edge/fog platforms in a continuum as needed, represented by the abstract notion of pressure relief valves based on resource capacities, function execution durations and optimisation preferences. With CoRFu, a reference implementation of a continuum-wide distributed Function-as-a-Service engine is introduced and combined with a dynamic function offloading framework. The implementation is validated with a sensor data inference and regression application.},
booktitle = {Proceedings of the 14th IEEE/ACM International Conference on Utility and Cloud Computing Companion},
articleno = {24},
numpages = {6},
keywords = {serverless computing, liquid software, continuum computing},
location = {Leicester, United Kingdom},
series = {UCC '21}
}

@proceedings{10.1145/3452369,
title = {FRAME '21: Proceedings of the 1st Workshop on Flexible Resource and Application Management on the Edge},
year = {2021},
isbn = {9781450383844},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is our great pleasure to welcome you to the 1st Workshop on Flexible Resource and Application Management on the Edge - FRAME 2021, held in conjunction with the HPDC 2021 conference as an online event on June 25th, 2021.The mission of the FRAME workshop is to bring together cloud and edge computing experts from academia and industry in order to identify new challenges for the management of resources in cloudedge infrastructures, as well as to promote the vision of a Continuum of resources including Edge and Cloud platforms among academia and industry stakeholders.By merging into the so-called Cloud/Edge Continuum, Cloud and Edge infrastructures can work together to fulfill requirements from a variety of Next-generation applications. Edge resources can act as a first layer of computing capacity that is close to the user, exploiting proximity to reduce latency and increase the exploitable portion of network bandwidth. Conventional Cloud infrastructures provide higher levels of reliability and performance than Edge resources to large groups of different users, also acting as a computing-power capacitor for the Edge of the network.From a technological perspective, by improving the features of scalability, interoperability, and efficient allocation of resources at the edge we can enable a whole new set of scenarios. Interactive and time-sensitive services can close the proximity gap with (potential) users by extending their services toward them. Real-time, data-driven decisions can promptly be made without waiting for data to travel to the Cloud and back.},
location = {Virtual Event, Sweden}
}

@inproceedings{10.1145/3587135.3592179,
author = {Kunkel, Julian Martin and Boehme, Christian and Decker, Jonathan and Magugliani, Fabrizio and Pleiter, Dirk and Koller, Bastian and Sivalingam, Karthee and Pllana, Sabri and Nikolov, Alexander and Soyturk, Mujdat and Racca, Christian and Bartolini, Andrea and Tate, Adrian and Yaman, Berkay},
title = {DECICE: Device-Edge-Cloud Intelligent Collaboration Framework},
year = {2023},
isbn = {9798400701405},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3587135.3592179},
doi = {10.1145/3587135.3592179},
abstract = {DECICE is a Horizon Europe project that is developing an AI-enabled open and portable management framework for automatic and adaptive optimization and deployment of applications in computing continuum encompassing from IoT sensors on the Edge to large-scale Cloud / HPC computing infrastructures. In this paper, we describe the DECICE framework and architecture. Furthermore, we highlight use-cases for framework evaluation: intelligent traffic intersection, magnetic resonance imaging, and emergency response.},
booktitle = {Proceedings of the 20th ACM International Conference on Computing Frontiers},
pages = {266–271},
numpages = {6},
keywords = {KubeEdge, Digital Twin, Cognitive Cloud, Cloud-Edge Orchestration, AI-enabled Computing Continuum},
location = {Bologna, Italy},
series = {CF '23}
}

@inproceedings{10.1145/3452369.3463822,
author = {Carlini, Emanuele and Carnevale, Lorenzo and Coppola, Massimo and Dazzi, Patrizio and Mencagli, Gabriele and Talia, Domenico and Villari, Massimo},
title = {An Osmotic Ecosystem for Data Streaming Applications in Smart Cities},
year = {2021},
isbn = {9781450383844},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3452369.3463822},
doi = {10.1145/3452369.3463822},
abstract = {Modern multi-tier Cloud-Edge-IoT computational platforms seamlessly map with the distributed and hierarchical nature of smart cities infrastructure. However, classical tools and methodologies to organise data as well as computational and network resources are poorly equipped to tackle the dynamic and heterogeneous environments of smart cities. In this paper we propose a reference architecture that aims to establish a unified approach for the orchestration of modern Cloud-Edge-IoT infrastructures and resources specifically tailored for data streaming applications in smart-cities. Stemming from the proposed reference architecture, we also discuss a series of open challenges, which we believe represent relevant research directions in the nearest future.},
booktitle = {Proceedings of the 1st Workshop on Flexible Resource and Application Management on the Edge},
pages = {27–31},
numpages = {5},
keywords = {smart cities, internet of things, edge computing, data streaming, cloud computing},
location = {Virtual Event, Sweden},
series = {FRAME '21}
}

@inproceedings{10.1145/3576914.3588019,
author = {Kourtis, Michail Alexandros and Xilouris, George and Batistatos, Michael and Kourtis, Anastasios and Markakis, Albertos},
title = {Emergency communications leveraging decentralized swarm computing},
year = {2023},
isbn = {9798400700491},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3576914.3588019},
doi = {10.1145/3576914.3588019},
abstract = {Abstract—Reliable and ubiquitous communications, offering high data rates, low latency and supporting large numbers of connected devices, are critical requirements for modern emergency rescue missions. Multiple teams of First Responders, operating at remote areas, on rough terrain or under harsh conditions (e.g. wildfires, earthquakes, flooding etc.) need seamless connectivity to send/receive mission data and organize their operations. Decentralized swarm computing architectures offer a wide range of capabilities to enhance and accelerate edge processing for critical use case scenarios. This paper presents a converged approach on swarm computing and intelligence using Decentralized Autonomous Organizations for emergency communications, and how a swarm of drones can leverage different edge accelerators for different applications.},
booktitle = {Proceedings of Cyber-Physical Systems and Internet of Things Week 2023},
pages = {302–306},
numpages = {5},
keywords = {swarm intelligence, drones, decentralized computing, blockchain, Keywords— Emergency communications, DAO},
location = {San Antonio, TX, USA},
series = {CPS-IoT Week '23}
}

@inproceedings{10.1145/3600160.3605055,
author = {Rios, Erkuden and Iturbe, Eider and Rego, Angel and Ferry, Nicolas and Tigli, Jean-Yves and Lavirotte, St\'{e}phane and Rocher, Gerald and Nguyen, Phu and Song, Hui and Dautov, Rustem and Mallouli, Wissam and Cavalli, Ana Rosa},
title = {The DYNABIC approach to resilience of critical infrastructures},
year = {2023},
isbn = {9798400707728},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3600160.3605055},
doi = {10.1145/3600160.3605055},
abstract = {With increasing interdependencies and evolving threats, maintaining operational continuity in critical systems has become a significant challenge. This paper presents the DYNABIC (Dynamic business continuity of critical infrastructures on top of adaptive multi-level cybersecurity) approach as a comprehensive framework to enhance the resilience of critical infrastructures. The DYNABIC approach provides the resilience enhancement through dynamic adaptation, automated response, collaboration, risk assessment, and continuous improvement. By fostering a proactive and collaborative approach to resilience, the DYNABIC framework empowers critical infrastructure sectors to effectively mitigate disruptions and recover from incidents. The paper explores the key components and architecture of the DYNABIC approach and highlights its potential to strengthen the resilience of critical infrastructures using the concept of Digital Twins in the face of evolving threats and complex operating environments involving cascading effects.},
booktitle = {Proceedings of the 18th International Conference on Availability, Reliability and Security},
articleno = {136},
numpages = {8},
keywords = {SecDevOps, Digital Twin, Cybersecurity, Critical Infrastructure Protection},
location = {<conf-loc>, <city>Benevento</city>, <country>Italy</country>, </conf-loc>},
series = {ARES '23}
}

@inproceedings{10.1145/3528226.3528371,
author = {Santos, Rayane and Soares, Pamella and Rodrigues, Evandro and Maia, Paulo Henrique M. and Silveira, Amanda},
title = {How blockchain and microservices are being used together: a systematic mapping study},
year = {2023},
isbn = {9781450393317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3528226.3528371},
doi = {10.1145/3528226.3528371},
abstract = {Microservices and blockchain are recent technologies that are attracting attention not only individually, but also when used together to achieve a certain goal. This study aims to map how both technologies have been integrated with applications, presenting the state of the art in the subject. To do that we conducted a systematic mapping study that searched five significant research bases and selected 40 papers to extract information. The results indicate that healthcare has been the most addressed domain using the combination of blockchain and microservices. On the other hand, the majority of studies have not been evaluated or presented only a proof of concept as an empirical validation, which shows that the proposals are not mature yet and there are still open research opportunities.},
booktitle = {Proceedings of the 5th International Workshop on Emerging Trends in Software Engineering for Blockchain},
pages = {39–46},
numpages = {8},
keywords = {systematic mapping study, software engineering, microservice, blockchain},
location = {Pittsburgh, Pennsylvania},
series = {WETSEB '22}
}

@article{10.1145/3478680,
author = {Siqueira, Frank and Davis, Joseph G.},
title = {Service Computing for Industry 4.0: State of the Art, Challenges, and Research Opportunities},
year = {2021},
issue_date = {December 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {9},
issn = {0360-0300},
url = {https://doi.org/10.1145/3478680},
doi = {10.1145/3478680},
abstract = {Recent advances in the large-scale adoption of information and communication technologies in manufacturing processes, known as Industry 4.0 or Smart Manufacturing, provide us a window into how the manufacturing sector will evolve in the coming decades. As a result of these initiatives, manufacturing firms have started to integrate a series of emerging technologies into their processes that will change the way products are designed, manufactured, and consumed. This article provides a comprehensive review of how service-oriented computing is being employed to develop the required software infrastructure for Industry 4.0 and identifies the major challenges and research opportunities that ensue. Particular attention is paid to the microservices architecture, which is increasingly recognized as offering a promising approach for developing innovative industrial applications. This literature review is based on the current state of the art on service computing for Industry 4.0 as described in a large corpus of recently published research papers, which helped us to identify and explore a series of challenges and opportunities for the development of this emerging technology frontier, with the goal of facilitating its widespread adoption.},
journal = {ACM Comput. Surv.},
month = {oct},
articleno = {188},
numpages = {38},
keywords = {digital twins, industrial IoT, industry 4.0, microservices, Service-oriented architecture}
}

@inproceedings{10.1145/3587135.3592190,
author = {Mastroianni, Carlo and Scarcello, Luigi and Vinci, Andrea},
title = {Quantum Computing Management of a Cloud/Edge Architecture},
year = {2023},
isbn = {9798400701405},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3587135.3592190},
doi = {10.1145/3587135.3592190},
abstract = {Modern Cloud/Edge architectures are composed of computing nodes belonging to multiple layers, including Cloud facilities, Edge/Fog nodes and sensors/actuators. In this paper, we present an architecture that includes also quantum computing devices, in two ways:(i) quantum devices can become, in the next future, a viable alternative for executing computation that is intractable classically and (ii) they can be exploited to assist resource management and scheduling within the architecture itself. Furthermore, we describe the procedure through which a typical resource assignment problem, which has NP-hard complexity, can be transformed into a formulation that can be tackled by QAOA, a renowned hybrid quantum algorithm, and we present some preliminary results obtained for a simple instance, a knapsack problem where an Edge node needs to select and retrieve a set of processes from the Cloud.},
booktitle = {Proceedings of the 20th ACM International Conference on Computing Frontiers},
pages = {193–196},
numpages = {4},
keywords = {resource assignment, quantum computing, cloud/edge computing},
location = {Bologna, Italy},
series = {CF '23}
}

@inproceedings{10.1145/3452369.3463815,
author = {Ferrucci, Luca and Mordacchini, Matteo and Coppola, Massimo and Carlini, Emanuele and Kavalionak, Hanna and Dazzi, Patrizio},
title = {Latency Preserving Self-optimizing Placement at the Edge},
year = {2021},
isbn = {9781450383844},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3452369.3463815},
doi = {10.1145/3452369.3463815},
abstract = {The Internet is experiencing a fast expansion at its edges. The wide availability of heterogeneous resources at the Edge is pivotal in the definition and extension of traditional Cloud solutions toward supporting the development of new applications. However, the dynamic and distributed nature of these resources poses new challenges for the optimization of the behaviour of the system. New decentralized and self-organizing methods are needed to face the needs of the Edge/Cloud scenario and to optimize the exploitation of Edge resources. In this paper we propose a distributed and adaptive solution that reduces the number of replicas of application services that are executed throughout the system, all the while ensuring that the latency constraints of applications are met, thus allowing to also meet the end users' QoS requirements. Experimental evaluations through simulation show the effectiveness of the proposed approach.},
booktitle = {Proceedings of the 1st Workshop on Flexible Resource and Application Management on the Edge},
pages = {3–8},
numpages = {6},
keywords = {self-optimizing application placement, opti-mization techniques for resource management, edge computing, application model},
location = {Virtual Event, Sweden},
series = {FRAME '21}
}

@inproceedings{10.1145/3452369.3463818,
author = {Gebrealif, Yodit and Mubarkoot, Mohammed and Altmann, J\"{o}rn and Egger, Bernhard},
title = {AI-Based Container Orchestration for Federated Cloud Environments},
year = {2021},
isbn = {9781450383844},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3452369.3463818},
doi = {10.1145/3452369.3463818},
abstract = {This paper proposes an architecture for artificial-intelligence-based container orchestration in cloud federation environments. The paper adapts the architecture proposed by Kurze et al. [1] and enhances it with two subcomponents in the federation layer to enable resource identification and container orchestration across cloud federation members. These two subcomponents are the AI Resource Identifier and the Container Orchestrator. The AI Resource Identifier is responsible for identifying the available resource in the federated environment whenever needed. It optimizes resource allocation of federation members by using Artificial Intelligence (AI) techniques for learning from the past. The Container Orchestrator sub-component is responsible for organizing jobs to be allocated along with all the necessary files and dependencies in a containerized way. This, in turn, enhances scalability and portability in a federated environment.},
booktitle = {Proceedings of the 1st Workshop on Flexible Resource and Application Management on the Edge},
pages = {15–16},
numpages = {2},
keywords = {resource identification, distributed cloud federation, container orchestration, artificial intelligence (ai)},
location = {Virtual Event, Sweden},
series = {FRAME '21}
}

@inproceedings{10.1145/3452369.3463817,
author = {Mazzei, Daniele},
title = {Filling the Gap between Scientific Research on Artificial Intelligence and Industry 4.0 Need},
year = {2021},
isbn = {9781450383844},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3452369.3463817},
doi = {10.1145/3452369.3463817},
abstract = {AI improves the data acquisition and analysis typical of the 4.0 paradigm, leading to the optimization of the industrial processes through fast, lightweight and well-performing algorithms. The academic research efforts on AI have followed a trend of development of complex and resource-intensive algorithms that require cloud-centric architectures while the industrial architectures for data acquisition are in most cases distributed, fragmented and resource-constrained. Recent researches have demonstrated the need of moving toward a decentralized use of AI where data analysis algorithms are executed directly on the machine side ("on the edge"). As this is the future, it becomes evident that a new generation of AI and ML experts, able to adapt these technologies to the industrial needs and to foster their role as the key players of the 4th industrial revolution, is needed. The talk will present the activities of the PLANET4 project that aims at filling the gap between scientific research on AI and its industrial application by designing an innovative blended course.},
booktitle = {Proceedings of the 1st Workshop on Flexible Resource and Application Management on the Edge},
pages = {1–2},
numpages = {2},
keywords = {teaching, industry 4.0, edge computing, artificial intelligence},
location = {Virtual Event, Sweden},
series = {FRAME '21}
}

@inproceedings{10.1145/3313150.3313218,
author = {Desai, Nitin and Punnekkat, Sasikumar},
title = {Safety of fog-based industrial automation systems},
year = {2019},
isbn = {9781450366984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313150.3313218},
doi = {10.1145/3313150.3313218},
abstract = {The Fog computing paradigm employing multiple technologies is expected to play a key role in a multitude of industrial applications by fulfilling futuristic requirements such as flexible and enhanced computing, storage, and networking capability closer to the field devices. While performance aspects of the Fog paradigm has been the central focus of researchers, safety aspects have not received enough attention so far. In this paper, we identify various safety challenges related to the Fog paradigm and provide specific safety design aspects as a step towards enhancing safety in industrial automation scenarios. We contextualize these ideas by invoking a distributed mobile robots use-case that can benefit from the use of the Fog paradigm.},
booktitle = {Proceedings of the Workshop on Fog Computing and the IoT},
pages = {6–10},
numpages = {5},
keywords = {safety, mobile robots, industrial automation, fog computing},
location = {Montreal, Quebec, Canada},
series = {IoT-Fog '19}
}

@inproceedings{10.1145/3589010.3594890,
author = {Cicconetti, Claudio and Carlini, Emanuele and Paradell, Antonio},
title = {EDGELESS Project: On the Road to Serverless Edge AI},
year = {2023},
isbn = {9798400701641},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589010.3594890},
doi = {10.1145/3589010.3594890},
abstract = {The EDGELESS project is set to efficiently operate serverless computing in extremely diverse computing environments, from resource-constrained edge devices to highly-virtualized cloud platforms. Automatic deployment and reconfiguration will leverage AI/ML techniques, resulting in a flexible horizontally-scalable computation solution able to fully use heterogeneous edge resources while preserving vertical integration with the cloud and the benefits of serverless and its companion programming model, i.e., Function-as-a-Service (FaaS). The system under design will be environmentally sustainable, as it will dynamically concentrate resources physically (e.g., by temporarily switching off far-edge devices) or logically (e.g., by dispatching tasks towards a specific set of nodes) at the expense of performance-tolerant applications.},
booktitle = {Proceedings of the 3rd Workshop on Flexible Resource and Application Management on the Edge},
pages = {41–43},
numpages = {3},
keywords = {serverless computing, resource-constrained devices, internet of things, edge computing},
location = {Orlando, FL, USA},
series = {FRAME '23}
}

@inproceedings{10.1145/3528229.3529385,
author = {Das, Sankar N. and Ahuja, Manish and Singi, Kapil and Dey, Kuntal and Kaulgud, Vikrant and Raman, Mahesh V. and Tung, Teresa},
title = {Digital twin based fault analysis in hybrid-cloud applications},
year = {2022},
isbn = {9781450393348},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3528229.3529385},
doi = {10.1145/3528229.3529385},
abstract = {Hybrid clouds bring together the advantages of the on-premises, private, and public cloud services. Agility, privacy, and regulatory compliance are some of the advantages of hybrid clouds. However, the key characteristics of complex hybrid cloud application such as heterogeneity, reliability, interoperability, scalability, and dynamic nature also makes old static approaches brittle. A digital twin can capture real-time (meta) data of a hybrid cloud application and supply valuable insights for efficient management of the cloud services and analyzing faults. In this paper, we propose a digital twin assisted approach to analyze the faults, interoperability, and reliability issues of a hybrid cloud-based application. We also present some metamorphic relations to analyze the reliability of our twin. Insights from the digital twin can assist developers to take proactive measures before a fault occur. The digital twin can also help detect faults and identify the cause and remediation steps through data insights. The key advantage of using digital twin is that it helps detect issues in complex hybrid cloud applications in a holistic way.},
booktitle = {Proceedings of the 10th IEEE/ACM International Workshop on Software Engineering for Systems-of-Systems and Software Ecosystems},
pages = {29–32},
numpages = {4},
keywords = {precision rehabilitation, metamorphic testing, hybrid cloud, edge computing, digital twin},
location = {Pittsburgh, Pennsylvania},
series = {SESoS '22}
}

@inproceedings{10.1145/3220228.3220238,
author = {Galletta, Antonino and Allam, Salma and Carnevale, Lorenzo and Bekri, Moulay Ali and Ouahbi, Rachid El and Villari, Massimo},
title = {An innovative methodology for big data visualization in oceanographic domain},
year = {2018},
isbn = {9781450364454},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3220228.3220238},
doi = {10.1145/3220228.3220238},
abstract = {Nowadays, thanks to new technologies, we are observing an explosion of data in different fields such as clinical, environmental and so on. In this context, a typical example of the well-known Big Data problem is represented by visualization. In this work, we propose an innovative platform for managing the oceanographic acquisitions. More specifically, we present two innovative visualization techniques: general overview and site specific observation. Experiments prove the goodness of the proposed system in terms both of performance and user experience.},
booktitle = {Proceedings of the International Conference on Geoinformatics and Data Analysis},
pages = {103–107},
numpages = {5},
keywords = {oceanography, microservices, geolocation, big data visualization, big data, acidification, IoT},
location = {Prague, Czech Republic},
series = {ICGDA '18}
}

@inproceedings{10.1145/3524458.3547125,
author = {Sabbioni, Andrea and Mazzocca, Carlo and Bujari, Armir and Montanari, Rebecca and Corradi, Antonio},
title = {A Decentralized Architecture for Dynamic and Federated Access Control Facilitating Smart Tourism Services},
year = {2022},
isbn = {9781450392846},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3524458.3547125},
doi = {10.1145/3524458.3547125},
abstract = {Edge computing and the Internet of Things (IoT) are inextricably linked, and much work has been devoted to strengthening their symbiotic relationship, providing better coverage and quality of service. These solutions are typically vertically tailored, provider-specific and bound to work within one administrative domain, as they presume direct deployment and ownership of the resources controlled in a centralised fashion. This model has effectively created a myriad of physically interconnected elements, logically broken down into separate domain-specific islands, each possibly applying different security/privacy policies, device and process control mechanisms, service access and provisioning schemes etc. To address this data and service balkanization phenomena, complex and time-consuming interactions between multiple providers are required to set up and operate federation of resources across domains and/or providers. Without loss of generality, we envision a scenario where stakeholders in a Smart Tourism ecosystem participate in resource federations to enrich their services and exploit complementarities. In this context, we present a decentralized architecture, relying on Distributed Ledger Technology (DLT), providing a flexible and effective federated access control mechanism to data and services.},
booktitle = {Proceedings of the 2022 ACM Conference on Information Technology for Social Good},
pages = {403–408},
numpages = {6},
keywords = {Resource Federation, Distributed Ledger, Access Control},
location = {Limassol, Cyprus},
series = {GoodIT '22}
}

@inproceedings{10.1145/3401025.3401764,
author = {Wiener, Patrick and Zehnder, Philipp and Riemer, Dominik},
title = {Managing geo-distributed stream processing pipelines for the IIoT with StreamPipes edge extensions},
year = {2020},
isbn = {9781450380287},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3401025.3401764},
doi = {10.1145/3401025.3401764},
abstract = {The industrial IoT and its promise to realize data-driven decision-making by analyzing industrial event streams is an important innovation driver in the industrial sector. Due to an enormous increase of generated data and the development of specialized hardware, new decentralized paradigms such as fog computing arised to overcome shortcomings of centralized cloud-only approaches. However, current undertakings are focused on static deployments of standalone services, which is insufficient for geo-distributed applications that are composed of multiple event-driven functions. In this paper, we present StreamPipes Edge Extensions (SEE), a novel contribution to the open source IIoT toolbox Apache StreamPipes. With SEE, domain experts are able to create stream processing pipelines in a graphical editor and to assign individual pipeline elements to available edge nodes, while underlying provisioning and deployment details are abstracted by the framework. The main contributions are (i) a fog cluster management model to represent computing node characteristics, (ii) a node controller for pipeline element life cycle management and (iii) a management framework to deploy event-driven functions to registered nodes. Our approach was validated in a real industrial setup showing low overall overhead of SEE as part of a robot-assisted product quality inspection use case.},
booktitle = {Proceedings of the 14th ACM International Conference on Distributed and Event-Based Systems},
pages = {165–176},
numpages = {12},
keywords = {stream processing, industrial internet of things, fog computing},
location = {Montreal, Quebec, Canada},
series = {DEBS '20}
}

@inproceedings{10.1145/3549206.3549236,
author = {Kinger, Kushagra and Singh, Ajeet and Panda, Sanjaya Kumar},
title = {Priority-Aware Resource Allocation Algorithm for Cloud Computing},
year = {2022},
isbn = {9781450396752},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3549206.3549236},
doi = {10.1145/3549206.3549236},
abstract = {Cloud is an innovative model of the computing paradigm, where servers, networks, storage, development tools, and applications are enabled to the users through the Internet in the form of services. These services are provided by the cloud service providers (CSPs) by deploying virtual machines (VMs) as per the resource request received from the users. These VM requests are of various types and priorities, and therefore have varying impacts in terms of importance, criticality, accountability, and domains of applications. On the other hand, the resources/hosts are of varying sizes and assigned to the requests based on their capability, availability, and feasibility. Therefore, it is an exigent issue to map the VM requests with the hosts to maximize the allocation rate with respect to their priority. One of the recent solutions is to assign the high-priority VM requests in close proximity, and other requests can be assigned using first fit decreasing (FFD). However, this solution does not partition the hosts to discriminate the type of requests. This paper introduces a priority-aware resource allocation (PARA) algorithm to consider three types of VM requests: highly critical, critical, and normal, and partition the hosts into three levels. PARA enables the high-priority VM requests to a relatively large pool of hosts compared to low-priority requests. The proposed algorithm is simulated by considering 10000 to 100000 VM requests and 20 to 30 hosts and compared with a non-partitioned pool of hosts with FFD to show effectiveness in allocation rate and weighted score concerning the serving requests.},
booktitle = {Proceedings of the 2022 Fourteenth International Conference on Contemporary Computing},
pages = {168–174},
numpages = {7},
keywords = {Virtual Machine, Resource Partitioning, Resource Allocation, First Fit Decreasing, Cloud Service Provider, Cloud Computing},
location = {Noida, India},
series = {IC3-2022}
}

@inproceedings{10.1145/3578354.3592869,
author = {Wang, Minghe and Schirmer, Trever and Pfandzelter, Tobias and Bermbach, David},
title = {Lotus: Serverless In-Transit Data Processing for Edge-based Pub/Sub},
year = {2023},
isbn = {9798400700828},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3578354.3592869},
doi = {10.1145/3578354.3592869},
abstract = {Publish-subscribe systems are a popular approach for edge-based IoT use cases: Heterogeneous, constrained edge devices can be integrated easily, with message routing logic offloaded to edge message brokers. Message processing, however, is still done on constrained edge devices. Complex content-based filtering, the transformation between data representations, or message extraction place a considerable load on these systems, and resulting superfluous message transfers strain the network.In this paper, we propose Lotus, adding in-transit data processing to an edge publish-subscribe middleware in order to offload basic message processing from edge devices to brokers. Specifically, we leverage the Function-as-a-Service paradigm, which offers support for efficient multi-tenancy, scale-to-zero, and real-time processing. With a proof-of-concept prototype of Lotus, we validate its feasibility and demonstrate how it can be used to offload sensor data transformation to the publish-subscribe messaging middleware.},
booktitle = {Proceedings of the 6th International Workshop on Edge Systems, Analytics and Networking},
pages = {31–35},
numpages = {5},
keywords = {edge communication, function-as-a-service (FaaS), publish/subscribe},
location = {Rome, Italy},
series = {EdgeSys '23}
}

@inproceedings{10.1145/3469263.3469858,
author = {Baldoni, Gabriele and Loudet, Julien and Cominardi, Luca and Corsaro, Angelo and He, Yong},
title = {Facilitating distributed data-flow programming with Eclipse Zenoh: the ERDOS case},
year = {2021},
isbn = {9781450386036},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3469263.3469858},
doi = {10.1145/3469263.3469858},
abstract = {Data-flow programming is the computational model of choice for a large class of application domains, such as, real-time data processing, robotics platforms, and big-data analytics. Traditionally, dataflows are deployed and executed within well-defined system boundaries, such as robots, radars, or data-centers. These boundaries however are expected to blur with the advent of Edge Computing, which provides a multi-tier infrastructure spanning from the cloud to the things and enables for the distribution of applications across this continuum. In this paper we make a step towards the design of an Edge-native data-flow by mixing technologies coming from both worlds: ERDOS, a novel data-flow framework, and Eclipse Zenoh, a Named-Data-Networking built for the Edge Computing. More specifically, we (i) investigate how ERDOS can be expanded to cover Edge deployments by leveraging Zenoh, (ii) analyze the advantages provided by this integration, and (iii) evaluate the performance of a Zenoh-powered ERDOS. Our results show that ERDOS experiences a higher throughput and bounded latency when operating over Zenoh. Moreover, Zenoh enhances ERDOS with full location transparency, allowing developers and system designers to focus on the logic of their application as opposed to the topology deployment. Finally, our integration of Zenoh and ERDOS is available as open source at https://github.com/atolab/erdos-on-zenoh.},
booktitle = {Proceedings of the 1st Workshop on Serverless Mobile Networking for 6G Communications},
pages = {13–18},
numpages = {6},
keywords = {zenoh, serverless, data-flow, NDN, FaaS, ERDOS},
location = {Virtual, WI, USA},
series = {MobileServerless'21}
}

@article{10.1145/3431235.3431243,
author = {Nogueira, Luis and Barros, Ant\'{o}nio and Zubia, Cristina and Faura, David and Gracia P\'{e}rez, Daniel and Miguel Pinho, Luis},
title = {Non-functional requirements in the ELASTIC architecture},
year = {2020},
issue_date = {June 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {40},
number = {1},
issn = {1094-3641},
url = {https://doi.org/10.1145/3431235.3431243},
doi = {10.1145/3431235.3431243},
abstract = {The new generation of smart systems require processing a vast amount of information from distributed data sources, while fulfilling non-functional properties related to real-time, energy-efficiency, communication quality and security. The ELASTIC software architecture is being developed to tackle this challenge, considering the complete continuum from the edge to the cloud. This paper provides a brief analysis of the smart application considered in the project, and the requirements emanating from their non-functional properties. The paper then identifies some of the technical constrains imposed to the ELASTIC software architecture to allow guaranteeing the non-functional requirements of the systems.},
journal = {Ada Lett.},
month = {oct},
pages = {85–90},
numpages = {6},
keywords = {non-functional requirements, elasticity, computing continuum.}
}

@inproceedings{10.1145/3517206.3526275,
author = {Habenicht, Daniel and Kreutz, Kevin and Becker, Soeren and Bader, Jonathan and Thamsen, Lauritz and Kao, Odej},
title = {SyncMesh: improving data locality for function-as-a-service in meshed edge networks},
year = {2022},
isbn = {9781450392532},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3517206.3526275},
doi = {10.1145/3517206.3526275},
abstract = {The increasing use of Internet of Things devices coincides with more communication and data movement in networks, which can exceed existing network capabilities. These devices often process sensor or user information, where data privacy and latency are a major concern. Therefore, traditional approaches like cloud computing do not fit well, yet new architectures such as edge computing address this gap. In addition, the Function-as-a-Service (FaaS) paradigm gains in prevalence as a workload execution platform, however the decoupling of storage results in further challenges for highly distributed edge environments.To address this, we propose SyncMesh, a system to manage, query, and transform data in a scalable and stateless manner by leveraging the capabilities of Function-as-a-Service and at the same time enabling data locality. Furthermore, we provide a prototypical implementation and evaluate it against established centralized and decentralized systems in regard to traffic usage and request times.The preliminary results indicate that SyncMesh is able to exonerate the network layer and accelerate the transmission of data to clients, while simultaneously improving local data processing.},
booktitle = {Proceedings of the 5th International Workshop on Edge Systems, Analytics and Networking},
pages = {55–60},
numpages = {6},
keywords = {mesh network, function-as-a-service, fog computing, edge computing, data management, data locality},
location = {Rennes, France},
series = {EdgeSys '22}
}

@inproceedings{10.1145/3517206.3526269,
author = {B\"{a}urle, Simon and Mohan, Nitinder},
title = {ComB: a flexible, application-oriented benchmark for edge computing},
year = {2022},
isbn = {9781450392532},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3517206.3526269},
doi = {10.1145/3517206.3526269},
abstract = {Edge computing is an attractive platform where applications, previously hosted in the cloud, shift parts of their workload on resources closer to the users. The field is still in its nascent stages with significant ongoing innovation in small form-factor hardware designed to operate at the edge. However, the increased hardware heterogeneity at the edge makes it difficult for application developers to determine if their workloads will operate as desired. Simultaneously, edge providers have to make expensive deployment choices for the "correct" hardware that will remain suitable for the near future. We present ComB, an application-oriented benchmarking suite for edge that assists early adopters in evaluating the suitability of an edge deployment. ComB is flexible, extensible, and incorporates a microservice-based video analytics pipeline as default workload to measure underlying hardware's compute and networking capabilities accurately. Our evaluation on a heterogeneous testbed shows that ComB enables both providers and developers to understand better the runtime capabilities of different hardware configurations for supporting operations of applications designed for the edge.},
booktitle = {Proceedings of the 5th International Workshop on Edge Systems, Analytics and Networking},
pages = {19–24},
numpages = {6},
keywords = {next-generation applications, edge computing, benchmarking},
location = {Rennes, France},
series = {EdgeSys '22}
}

@inproceedings{10.1145/3485730.3493375,
author = {Ranathunga, Tharindu and McGibney, Alan and Rea, Susan},
title = {The convergence of Blockchain and Machine Learning for Decentralized Trust Management in IoT Ecosystems},
year = {2021},
isbn = {9781450390972},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3485730.3493375},
doi = {10.1145/3485730.3493375},
abstract = {The EU data strategy postulates that by 2025 there will be a paradigm shift towards more decentralized intelligence and data processing at the edge. The convergence of a large number of nodes at the IoT edge along with multiple service providers and network operators exposes data owners and resource providers to potential threats. To address cloud-edge risks, trust-based decentralized management is needed. Blockchain technology has created an opportunity to decentralize IoT ecosystems, through its intrinsic properties and together with machine learning (ML) it can be used to provide a trusted backbone for managing IoT ecosystems to support automated and adaptive trust management. This paper presents a novel approach for crosslayer intelligent trust computation modelling leveraging ML and Blockchain for decentralized trust management in IoT ecosystems. The effectiveness of the proposed approach for flow-based trust assessment is demonstrated using the Hyperledger Framework and the Cooja-based simulation environment. Finally, an initial evaluation is presented to understand the performance in terms of scalability and trust convergence of the proposed model.},
booktitle = {Proceedings of the 19th ACM Conference on Embedded Networked Sensor Systems},
pages = {499–504},
numpages = {6},
keywords = {Trust, Machine Learning, IoT Ecosystems, Internet of things, Hyperledger, Blockchain},
location = {Coimbra, Portugal},
series = {SenSys '21}
}

@proceedings{10.1145/2046642,
title = {DIM '11: Proceedings of the 7th ACM workshop on Digital identity management},
year = {2011},
isbn = {9781450310062},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is our great pleasure to welcome you to the 7th ACM Digital Identity Management Workshop -- DIM 2011.Identity is on the move -- With an ever-rising number of mobile devices, the popularity of tablet PCs, the continuum of computing and communication devices as well as the continuous connectivity paradigm of mobile devices and cloud-based services, identity management is used - and needed - everywhere. Whether at home, at work, or on the move, services may be accessed and come with requirements for authentication, authorization and proof of attribute claims. As mobile computing is woven into our lives, identity management is confronted with a plethora of scenarios: online and offline usage of identity services, user-centricity, federation, ad-hoc setup, discovery and negotiation.Identity is on the move -- With an unimpeded growth of social networks, the flood of apps growing by the minute, and the emerging mash-up, location-based, and peer-2-peer user-centric services, we find an ever-changing, lively environment for identity. In this multi-faceted environment, identity management needs to be on the move, as well. Paradigms that have been solid foundations of identity management in recent years change and are re-prioritized. Whereas authentication and certified claims from a trusted identity provider were predominant in traditional identity federation, we find factors such as reputation, social network structure, location and vicinity to be of growing importance.A key question is regarding what makes an electronic identity? Is it a UUID or user attributes or claims? This would impact how identity transactions would look like and fit seamlessly in the new technologies. We need to question how electronic identity interacts with a user's life. We are certain of one thought: identity research needs to be versatile, light-footed and constantly on the move.Keeping this theme in mind, we are very grateful that two exceptional key note speakers joined our workshop. Having just completed the European Research project Privacy and Identity Management for Life (Primelife), they have been investigating identity on the move in their own way. Last year's ACM award winner Dr. Jan Camenisch (IBM Research, Switzerland) will introduce us to new cryptographic building blocks and their applications to open new paths for identity and privacy. Prof. Ronald Leenes (Tilburg University, The Netherlands) will trace the (mis-)steps of social networks and their dangers for identity and privacy as well as propose new directions for this area. Thus, our keynotes reflect recent developments in identity, in terms of risks and new possibilities.For our sessions we also keep this diversity. We will have a session on policies and frameworks and one on cryptographic primitives. Also, we pursue authentication and biometrics as well as social networks and usability. We hope that you will find this program interesting and thought-provoking and that the symposium will provide you with a valuable opportunity to share ideas with other researchers and practitioners from institutions around the world.We hope that you will find this program interesting as well as inspiring. At the Digital Identity Management Workshop, we have a tradition of nurturing lively discussions for the benefit of researchers and practitioners. Thus, we are looking forward to the opportunity for sharing ideas and dynamic discourse. Welcome to DIM'2011!},
location = {Chicago, Illinois, USA}
}

@inproceedings{10.1145/3520304.3533938,
author = {Osaba, Eneko and Diaz-de-Arcaya, Josu and Orue-Echevarria, Leire and Alonso, Juncal and Lobo, Jesus L. and Benguria, Gorka and Etxaniz, I\~{n}aki},
title = {PIACERE project: description and prototype for optimizing infrastructure as code deployment configurations},
year = {2022},
isbn = {9781450392686},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3520304.3533938},
doi = {10.1145/3520304.3533938},
abstract = {PIACERE is an European project supported by the Union's Horizon 2020 research and innovation programme, whose objective is to enhance the productivity of DevOps teams in the operation of Infrastructure as Code (IaC) by offering an integrated DevSec-Ops framework. Thus, DevOps practitioners can develop IaC as if they were programming a common software application. In order to achieve this challenging task, one of the core technologies considered within PIACERE will be the design and development of optimization metaheuristics, in a module coined as IaC Optimizer Platform (IOP). The main objective of the IOP is to provide DevSecOps teams with the most appropriate deployment configurations that best fit a set of defined constraints. The goal of this technical paper is to describe the preliminary approach followed in PIACERE for carrying out this optimization, and how the IOP fits into the whole PIACERE ecosystem. Additionally, results obtained in a preliminary experimentation are detailed in this study.},
booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference Companion},
pages = {71–72},
numpages = {2},
keywords = {NSGA-II, PIACERE, combinatorial optimization, infrastructure as code, multiobjective optimization},
location = {<conf-loc>, <city>Boston</city>, <state>Massachusetts</state>, </conf-loc>},
series = {GECCO '22}
}

@inproceedings{10.1145/3368235.3368847,
author = {Abdul Majeed, Ayesha and Kilpatrick, Peter and Spence, Ivor and Varghese, Blesson},
title = {Performance Estimation of Container-Based Cloud-to-Fog Offloading},
year = {2019},
isbn = {9781450370448},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3368235.3368847},
doi = {10.1145/3368235.3368847},
abstract = {Fog computing offloads latency critical services of a Cloud application onto resources located at the edge of the network that are in close proximity to end-user devices. The research in this paper is motivated towards characterising and estimating the time taken to offload a service using containers, which is investigated in the context of the 'Save and Load' container migration technique. To this end, the research addresses questions such as whether fog offloading can be accurately modelled and which system and network related parameters influence offloading. These are addressed by exploring a catalogue of 21 different metrics both at the system and process levels that is used as input to four estimation techniques using a collective model and individual models to predict the time taken for offloading. The study is pursued by collecting over 1.1 million data points and the preliminary results indicate that offloading can be modelled accurately.},
booktitle = {Proceedings of the 12th IEEE/ACM International Conference on Utility and Cloud Computing Companion},
pages = {151–156},
numpages = {6},
keywords = {offloading, fog computing, edge computing, containers},
location = {Auckland, New Zealand},
series = {UCC '19 Companion}
}

@inproceedings{10.1145/3583120.3589571,
author = {Feraudo, Angelo},
title = {PhD Forum Abstract: Vehicular-based Support to Cooperative Edge Computing based Applications in Next-gen Networks},
year = {2023},
isbn = {9798400701184},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3583120.3589571},
doi = {10.1145/3583120.3589571},
abstract = {Today’s advancements in IoT devices and edge computing platforms have given rise to new scenarios enabling context-aware applications in extremely interconnected environments. To promote the standardization of these platforms the European Telecommunications Standards Institute (ETSI) proposed the Multi-access Edge Computing (MEC) standard, enabling the execution of cloud-like services at the network edge. In this work, we propose the design of a novel MEC-compliant architecture that leverages underutilized far-edge resources to enlarge MEC edge node computational capacity and enhance service availability in highly mobile networks. Our approach allows far-edge devices to participate in a negotiation process embodying a rewarding system while addressing resource volatility as these devices join and leave the edge node resource infrastructure. Furthermore, we developed an original simulation framework to replicate the proposed architecture by using vehicle resources as far-edge devices. Its primary purpose is to demonstrate the viability and flexibility of our proposal, as well as to investigate novel application scenarios using real-world datasets. Our preliminary results show the feasibility and effectiveness of our proposal when using vehicular-based virtual resources in realistically simulated 5G networks.},
booktitle = {Proceedings of the 22nd International Conference on Information Processing in Sensor Networks},
pages = {352–353},
numpages = {2},
keywords = {Vehicular Computing, Multi-access Edge Computing, IoV, 5G},
location = {San Antonio, TX, USA},
series = {IPSN '23}
}

@article{10.1109/TNET.2023.3305922,
author = {Si Salem, Tareq and Castellano, Gabriele and Neglia, Giovanni and Pianese, Fabio and Araldo, Andrea},
title = {Toward Inference Delivery Networks: Distributing Machine Learning With Optimality Guarantees},
year = {2023},
issue_date = {Feb. 2024},
publisher = {IEEE Press},
volume = {32},
number = {1},
issn = {1063-6692},
url = {https://doi.org/10.1109/TNET.2023.3305922},
doi = {10.1109/TNET.2023.3305922},
abstract = {An increasing number of applications rely on complex inference tasks that are based on machine learning (ML). Currently, there are two options to run such tasks: either they are served directly by the end device (e.g., smartphones, IoT equipment, smart vehicles), or offloaded to a remote cloud. Both options may be unsatisfactory for many applications: local models may have inadequate accuracy, while the cloud may fail to meet delay constraints. In this paper, we present the novel idea of inference delivery networks (IDNs), networks of computing nodes that coordinate to satisfy ML inference requests achieving the best trade-off between latency and accuracy. IDNs bridge the dichotomy between device and cloud execution by integrating inference delivery at the various tiers of the infrastructure continuum (access, edge, regional data center, cloud). We propose a distributed dynamic policy for ML model allocation in an IDN by which each node dynamically updates its local set of inference models based on requests observed during the recent past plus limited information exchange with its neighboring nodes. Our policy offers strong performance guarantees in an adversarial setting and shows improvements over greedy heuristics with similar complexity in realistic scenarios.},
journal = {IEEE/ACM Trans. Netw.},
month = {aug},
pages = {859–873},
numpages = {15}
}

@article{10.1145/3593043,
author = {Goknil, Arda and Nguyen, Phu and Sen, Sagar and Politaki, Dimitra and Niavis, Harris and Pedersen, Karl John and Suyuthi, Abdillah and Anand, Abhilash and Ziegenbein, Amina},
title = {A Systematic Review of Data Quality in CPS and IoT for Industry 4.0},
year = {2023},
issue_date = {December 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {55},
number = {14s},
issn = {0360-0300},
url = {https://doi.org/10.1145/3593043},
doi = {10.1145/3593043},
abstract = {The Internet of Things (IoT) and Cyber-Physical Systems (CPS) are the backbones of Industry 4.0, where data quality is crucial for decision support. Data quality in these systems can deteriorate due to sensor failures or uncertain operating environments. Our objective is to summarize and assess the research efforts that address data quality in data-centric CPS/IoT industrial applications. We systematically review the state-of-the-art data quality techniques for CPS and IoT in Industry 4.0 through a systematic literature review (SLR) study. We pose three research questions, define selection and exclusion criteria for primary studies, and extract and synthesize data from these studies to answer our research questions. Our most significant results are (i) the list of data quality issues, their sources, and application domains, (ii) the best practices and metrics for managing data quality, (iii) the software engineering solutions employed to manage data quality, and (iv) the state of the data quality techniques (data repair, cleaning, and monitoring) in the application domains. The results of our SLR can help researchers obtain an overview of existing data quality issues, techniques, metrics, and best practices. We suggest research directions that require attention from the research community for follow-up work.},
journal = {ACM Comput. Surv.},
month = {jul},
articleno = {327},
numpages = {38},
keywords = {systematic review, Industry 4.0, CPS, IoT, Data quality}
}

@article{10.1145/3591335.3591347,
author = {John, Wolfgang and Balador, Ali and Taghia, Jalil and Johnsson, Andreas and Sj\"{o}berg, Johan and Marsh, Ian and Gustafsson, Jonas and Tonini, Federico and Monti, Paolo and Sk\"{o}ldstr\"{o}m, Pontus and Dowling, Jim},
title = {ANIARA Project - Automation of Network Edge Infrastructure and Applications with Artificial Intelligence},
year = {2023},
issue_date = {December 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {42},
number = {2},
issn = {1094-3641},
url = {https://doi.org/10.1145/3591335.3591347},
doi = {10.1145/3591335.3591347},
abstract = {Emerging use-cases like smart manufacturing and smart cities pose challenges in terms of latency, which cannot be satisfied by traditional centralized infrastructure. Edge networks, which bring computational capacity closer to the users/clients, are a promising solution for supporting these critical low latency services. Different from traditional centralized networks, the edge is distributed by nature and is usually equipped with limited compute capacity. This creates a complex network to handle, subject to failures of different natures, that requires novel solutions to work in practice. To reduce complexity, edge application technology enablers, advanced infrastructure and application orchestration techniques need to be in place where AI and ML are key players.},
journal = {Ada Lett.},
month = {apr},
pages = {92–95},
numpages = {4}
}

@inproceedings{10.1145/3297280.3297402,
author = {de Santana, Cleber Jorge Lira and de Mello Alencar, Brenno and Prazeres, C\'{a}ssio V. Serafim},
title = {Reactive microservices for the internet of things: a case study in fog computing},
year = {2019},
isbn = {9781450359337},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3297280.3297402},
doi = {10.1145/3297280.3297402},
abstract = {The Future Internet will be able to connect most of the objects that are not yet connected on the current Internet. The Internet of Things (IoT) is an important part of the Future Internet and involves connectivity between several physical and virtual objects, allowing the emergence of new services and applications. These intelligent objects, along with their tasks, constitute domain-specific applications (vertical markets), while ubiquitous and analytic services form independent domain services (horizontal markets). The development of these applications and services in these markets brings challenges such as deployment, scalability, integration, interoperability, mobility and performance. Recent research indicates that Microservices has been successfully applied by companies such as Netflix and SoundCloud to address some of these issues in their cloud computing applications. However, in the field of IoT, the use of Microservices to deal with these challenges still presents unresolved issues. In this paper, we present a reactive Microservices architecture and apply it in a Fog Computing case study to investigate these challenges at the edge of the network. Finally, we evaluate our proposal from the perspective of performance of Microservices provided by intelligent objects (IoT gateways) at the edge of the network.},
booktitle = {Proceedings of the 34th ACM/SIGAPP Symposium on Applied Computing},
pages = {1243–1251},
numpages = {9},
keywords = {reactive microservices, internet of things, fog computing, architecture, IoT platform},
location = {Limassol, Cyprus},
series = {SAC '19}
}

@inproceedings{10.1145/3297280.3297295,
author = {Mendes, Seundefinedgio and Sim\~{a}o, Jos\'{e} and Veiga, Lu\'{\i}s},
title = {Oversubscribing micro-clouds with energy-aware containers scheduling},
year = {2019},
isbn = {9781450359337},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3297280.3297295},
doi = {10.1145/3297280.3297295},
abstract = {Cloud computation is being pushed to the edge of the network, towards Micro-clouds, to promote more energy efficiency and less latency when compared to heavy resourced centralized datacenters. This trend will enable new markets and providers to fill the current gap. There are however challenges in this design: (i) devices have less resources, leading to a frequent use of oversubscription (ii) lack of economic incentives to both provider and application owner to cope with less than full requests fulfilled. To support this trend, the virtualization layer of Micro-clouds is currently dominated by containers, which have a small memory footprint and strong isolation properties. We propose an extension to Docker Swarm, a widely used containers orchestrator, with an oversubscribing scheduling algorithm, based on improving resources utilization to levels where the energy efficiency is maximized. This solution improves CPU and memory utilization over Spread and Binpack (Docker Swarm strategies). Although we introduce a small overhead in scheduling times, our solution manages to allocate more requests, with a successful allocation rate of 83% against 57% of current solutions, measured on the scheduling of real CPU- and memory-intensive workloads (e.g. Video encoding, Key-value storages and a Deep-learning algorithm).},
booktitle = {Proceedings of the 34th ACM/SIGAPP Symposium on Applied Computing},
pages = {130–137},
numpages = {8},
keywords = {oversubscription, energy efficienct, containers orchestration},
location = {Limassol, Cyprus},
series = {SAC '19}
}

@inproceedings{10.1145/3339252.3341481,
author = {Leander, Bj\"{o}rn and \v{C}au\v{s}evi\'{c}, Aida and Hansson, Hans},
title = {Applicability of the IEC 62443 standard in Industry 4.0 / IIoT},
year = {2019},
isbn = {9781450371643},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3339252.3341481},
doi = {10.1145/3339252.3341481},
abstract = {Today's industrial automation systems are undergoing a digital transformation that implies a shift towards the Internet of Things (IoT), leading to the Industrial Internet of Things (IIoT) paradigm. Existing Industrial Automated Control Systems (IACS), enriched with a potentially large number of IoT devices are expected to make systems more efficient, flexible, provide intelligence, and ultimately enable autonomous control. In general, the majority of such systems come with high level of criticality that calls for well-established methods and approaches when achieving cybersecurity, preferably prescribed by a standard.IEC 62443 is an industrial standard that provides procedures to manage risks related to cybersecurity threats in IACS. Given the new IIoT paradigm, it is likely that existing standards are not sufficiently aligned with the challenges related to developing and maintaining cybersecurity in such systems. In this paper we review the applicability of the IEC 62443 standard in IIoT contexts and discuss potential challenges the process owners might encounter.Our analysis underlines that some areas within the standard could prove difficult to reach compliance with. In particular, handling of cross zone communication and software updates require additional guidance.},
booktitle = {Proceedings of the 14th International Conference on Availability, Reliability and Security},
articleno = {101},
numpages = {8},
location = {Canterbury, CA, United Kingdom},
series = {ARES '19}
}

@inproceedings{10.1145/3578245.3584934,
author = {Kousiouris, George and Ambroziak, Szymon and Zarzycki, Blazej and Costantino, Domenico and Tsarsitalidis, Stylianos and Katevas, Vasileios and Mamelli, Alessandro and Stamati, Teta},
title = {A Pattern-based Function and Workflow Visual Environment for FaaS Development across the Continuum},
year = {2023},
isbn = {9798400700729},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3578245.3584934},
doi = {10.1145/3578245.3584934},
abstract = {The ability to split applications across different locations in the continuum (edge/cloud) creates needs for application break down into smaller and more distributed chunks. In this realm the Function as a Service approach appears as a significant enabler in this process. The paper presents a visual function and workflow development environment for complex FaaS (Apache OpenwhisK) applications. The environment offers a library of pattern based and reusable nodes and flows while mitigating function orchestration limitations in the domain. Generation of the deployable artefacts, i.e. the functions, is performed through embedded DevOps pipelines. A range of annotations are available for dictating diverse options including QoS needs, function or data locality requirements, function affinity considerations etc. These are propagated to the deployment and operation stacks for supporting the cloud/edge interplay. The mechanism is evaluated functionally through creating, registering and executing functions and orchestrating workflows, adapting typical parallelization patterns and an edge data collection process.},
booktitle = {Companion of the 2023 ACM/SPEC International Conference on Performance Engineering},
pages = {165–172},
numpages = {8},
keywords = {software development, serverless computing, function orchestration, function as a service},
location = {Coimbra, Portugal},
series = {ICPE '23 Companion}
}

@inproceedings{10.1145/3365871.3365892,
author = {Mehran, Narges and Kimovski, Dragi and Prodan, Radu},
title = {MAPO: A Multi-Objective Model for IoT Application Placement in a Fog Environment},
year = {2019},
isbn = {9781450372077},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3365871.3365892},
doi = {10.1145/3365871.3365892},
abstract = {The emergence of the Fog computing paradigm that leverages innetwork virtualized resources raises important challenges in terms of resource and IoT application management in a heterogeneous environment with limited computing resources. In this work, we propose a novel Pareto-based approach for application placement close to the data sources called Multi-objective IoT Application Placement in fOg (MAPO). MAPO models applications based on a finite state machine using three conflicting optimization objectives, completion time, energy consumption, and economic cost, and considering both the computation and communication aspects. In contrast to existing solutions that optimize a single objective, MAPO enables multi-objective energy and cost-aware application placement. To evaluate the quality of the MAPO placements, we created both simulated and real-world testbeds tailored for a set of medical IoT application case studies. Compared to the state-of-the-art approaches, MAPO reduces the economic cost by 28%, while decreasing the energy requirements by 29-64% on average, and improves the completion time by a factor of six.},
booktitle = {Proceedings of the 9th International Conference on the Internet of Things},
articleno = {21},
numpages = {8},
keywords = {multi-objective optimization, energy consumption, IoT application placement, Fog computing},
location = {Bilbao, Spain},
series = {IoT '19}
}

@inproceedings{10.1145/2072298.2072375,
author = {Bell, Genevieve},
title = {"U are happy life": telling the future's stories},
year = {2011},
isbn = {9781450306164},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2072298.2072375},
doi = {10.1145/2072298.2072375},
booktitle = {Proceedings of the 19th ACM International Conference on Multimedia},
pages = {585–586},
numpages = {2},
location = {Scottsdale, Arizona, USA},
series = {MM '11}
}

@inproceedings{10.1145/3493229.3493306,
author = {Tzenetopoulos, Achilleas and Marantos, Charalampos and Gavrielides, Giannos and Xydis, Sotirios and Soudris, Dimitrios},
title = {FADE: FaaS-inspired application decomposition and Energy-aware function placement on the Edge},
year = {2021},
isbn = {9781450391665},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3493229.3493306},
doi = {10.1145/3493229.3493306},
abstract = {Lately, more and more applications are deployed on heterogeneous, power-constrained edge-computing devices. Bringing computation closer to the data, contributes both to latency and energy consumption reduction due to the elimination of excessive data transfers. However, while the main concern in such environments is the minimization of energy consumption, the heterogeneity in compute resources found at the edge may lead to Quality of Service (QoS) violations. At the same time, Serverless computing, the next frontier of Cloud computing has emerged to offer unprecedented elasticity by utilizing fine-grained, stateless functions. The reduction in the execution time and the modest memory footprint of such decomposed applications, allow for fine-grained resource multiplexing. In this work, we propose a methodology for application decomposition into fine-grained functions and energy-aware function placement on a cluster of edge devices subject to user-specified QoS guarantees.},
booktitle = {Proceedings of the 24th International Workshop on Software and Compilers for Embedded Systems},
pages = {7–10},
numpages = {4},
keywords = {serverless, resource management, energy-aware},
location = {Eindhoven, Netherlands},
series = {SCOPES '21}
}

@inproceedings{10.1145/3211890.3211914,
author = {Qui\~{n}ones, Eduardo and Bertogna, Marko and Hadad, Erez and Ferrer, Ana Juan and Chiantore, Luca and Reboa, Alfredo},
title = {Big Data Analytics for Smart Cities: The H2020 CLASS Project},
year = {2018},
isbn = {9781450358491},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3211890.3211914},
doi = {10.1145/3211890.3211914},
booktitle = {Proceedings of the 11th ACM International Systems and Storage Conference},
pages = {130},
numpages = {1},
location = {Haifa, Israel},
series = {SYSTOR '18}
}

@inproceedings{10.1145/3546037.3546056,
author = {Bartolomeo, Giovanni and B\"{a}urle, Simon and Mohan, Nitinder and Ott, J\"{o}rg},
title = {Oakestra: an orchestration framework for edge computing},
year = {2022},
isbn = {9781450394345},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3546037.3546056},
doi = {10.1145/3546037.3546056},
abstract = {Edge computing enables developers to deploy their services on compute resources deployed closer to the users. The abstraction requires powerful orchestration capabilities and the resolution of complex optimization problems. While edge computing is a consistently growing trend, the community (research and industry) still largely embraces adaptations and extensions of existing cloud technologies that have been proven ineffective on edge (e.g. Kubernetes). In this work, we present Oakestra, a novel hierarchical orchestration framework specifically designed for supporting service operation over heterogeneous edge infrastructures. In this demonstration, we showcase the various features and operations of Oakestra using our latency-critical augmented reality (AR) application.},
booktitle = {Proceedings of the SIGCOMM '22 Poster and Demo Sessions},
pages = {34–36},
numpages = {3},
keywords = {resource management, orchestration framework, edge computing},
location = {Amsterdam, Netherlands},
series = {SIGCOMM '22}
}

@inproceedings{10.1145/3560905.3568430,
author = {Zhang, Lei and Gao, Guanyu and Zhang, Huaizheng},
title = {Towards Data-Efficient Continuous Learning for Edge Video Analytics via Smart Caching},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568430},
doi = {10.1145/3560905.3568430},
abstract = {Continuous learning (CL) has recently been adopted into edge video analytics, gaining huge success in maintaining high accuracy without constantly retraining DNN models by human intervention. Though existing solutions offer optimized processing pipelines, the cost brought by CL should not be neglected. This vision paper starts an investigation by exploring two kinds of cost, human labeling and edge storage. The former comes from the need for CL's automatically tuning, and the latter is due to an exemplar pool (including both drift and historical data) maintained to prevent catastrophic forgetting caused by naive retraining. To alleviate the costs, we propose a new CL-based edge video analytics system by incorporating an active learner mechanism. Specifically, we revisit the current CL video system design and develop an active CL pipeline atop them. The pipeline first accepts the drift data stored in drift pool and utilizes an active learner to sample a small partition of them for labeling. Then it mixes up both small labeled drifted data and some historical data to send them to an exemplar pool for CL. Our preliminary benchmark studies exhibit that the new system can achieve competitive accuracy by spending only 30% labeling and storage cost compared to other baselines, showing a promising research direction for future study.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {1136–1140},
numpages = {5},
keywords = {video analytics, continual learning, active learning},
location = {<conf-loc>, <city>Boston</city>, <state>Massachusetts</state>, </conf-loc>},
series = {SenSys '22}
}

@inproceedings{10.1145/3524458.3547126,
author = {Mazzuca, Laura and Garbugli, Andrea and Sabbioni, Andrea and Bujari, Armir and Corradi, Antonio},
title = {Towards a Resource-aware Middleware Support for Distributed Game Engine Design},
year = {2022},
isbn = {9781450392846},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3524458.3547126},
doi = {10.1145/3524458.3547126},
abstract = {Recently, we are witnessing an increasing interest in a paradigm shift in the way video games are designed and implemented. Starting from an era where a single developer was in charge of the whole creative process, we have moved now toward extremely large groups with a multi-layered organisation. Moreover, today’s game engines suffer from a number of architectural constraints, and will not likely be able to meet the flexibility and scalability required by game developers of the next generation. This increasing complexity, the tremendous growth of projects size, and the rapidly evolving AR/VR trend, call for the adoption of agile development and cost-effective management approaches leveraging on distributed computing environments and primitives. In this work, we present the concept of a distributed game engine architecture, which relies on a resource-aware middleware solution providing run-time quality support to components spanning edge-cloud environments.},
booktitle = {Proceedings of the 2022 ACM Conference on Information Technology for Social Good},
pages = {409–413},
numpages = {5},
keywords = {Microservices, Gaming as a Service, Edge Cloud Computing},
location = {Limassol, Cyprus},
series = {GoodIT '22}
}

@inproceedings{10.1145/3578354.3592873,
author = {Pourreza, Maryam and Narasimhan, Priya},
title = {An Empirical Study of Resource-Stressing Faults in Edge-Computing Applications},
year = {2023},
isbn = {9798400700828},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3578354.3592873},
doi = {10.1145/3578354.3592873},
abstract = {Our growing reliance on edge-computing applications makes it crucial to improve the reliability of edge-computing systems. With multiple classes of edge-computing applications, different types of faults, and different kinds of resources needed by the applications, it remains unclear which resource exhaustion has the most disruptive impact on the latency experienced by the edge applications. Without this information, it is challenging to determine which faults to prioritize when implementing fault tolerance for edge computing. To address this challenge, we conduct an empirical study on a representative edge computing environment using well-known edge-computing benchmark applications (DeFog and ComB) and injecting resource-stressing faults (via stress-ng and hping). Our study reveals that memory overloads, CPU cache thrashing, frequent context switching, and page faults are the biggest disruptors of latency for edge-based applications.},
booktitle = {Proceedings of the 6th International Workshop on Edge Systems, Analytics and Networking},
pages = {54–59},
numpages = {6},
keywords = {benchmark, fault injection, fault tolerance, edge computing},
location = {Rome, Italy},
series = {EdgeSys '23}
}

@article{10.1145/3243929,
author = {Ferrer, Ana Juan and Marqu\`{e}s, Joan Manuel and Jorba, Josep},
title = {Towards the Decentralised Cloud: Survey on Approaches and Challenges for Mobile, Ad hoc, and Edge Computing},
year = {2019},
issue_date = {November 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {6},
issn = {0360-0300},
url = {https://doi.org/10.1145/3243929},
doi = {10.1145/3243929},
abstract = {Cloud computing emerged as a centralised paradigm that made “infinite” computing resources available on demand. Nevertheless, the ever-increasing computing capacities present on smart connected things and devices calls for the decentralisation of Cloud computing to avoid unnecessary latencies and fully exploit accessible computing capacities at the edges of the network. Whilst these decentralised Cloud models represent a significant breakthrough from a Cloud perspective, they are rooted in existing research areas such as Mobile Cloud Computing, Mobile Ad hoc Computing, and Edge computing. This article analyses the pre-existing works to determine their role in Decentralised Cloud and future computing development.},
journal = {ACM Comput. Surv.},
month = {jan},
articleno = {111},
numpages = {36},
keywords = {fog computing, edge computing, decentralised cloud, Mobile Cloud Computing, Mobile Ad hoc Cloud Computing, Cloud computing}
}

@inproceedings{10.1145/3417310.3431396,
author = {Gonzalez-Gil, Pedro and Skarmeta, Antonio F. and Martinez, Juan Antonio},
title = {The security framework of Fed4IoT},
year = {2020},
isbn = {9781450381314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3417310.3431396},
doi = {10.1145/3417310.3431396},
abstract = {The high number of IoT devices, and also their availability through the Internet, has made the topic of IoT virtualisation an emerging topic, which has gained a lot of interest from both academia and industry points of view. Fed4IoT is an H2020 EU-JPN Research Project, whose aim is precisely this one. Nevertheless, security, and more specifically authorisation or access control is a fundamental aspect that must be addressed, motivated by the increase of threats and attacks that the IoT domain has suffered. In this paper we propose the use of a distributed authorisation mechanism based on DCapBAC technology, to specifically deal with the IoT virtualisation aspect, in the scope of this project. This technology has proven its validity in the IoT domain because of its distributed nature and the flexibility of their authorisation policies.},
booktitle = {Proceedings of the Workshop on Cloud Continuum Services for Smart IoT Systems},
pages = {1–6},
numpages = {6},
keywords = {security, privacy, aaa, IoT},
location = {Virtual Event, Japan},
series = {CCIoT '20}
}

@inproceedings{10.1145/3452369.3463824,
author = {Coppola, Massimo and Iacono, Mauro and Migliardi, Mauro and Palmieri, Francesco},
title = {A Methodological Perspective on Lawful Internet Surveillance},
year = {2021},
isbn = {9781450383844},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3452369.3463824},
doi = {10.1145/3452369.3463824},
abstract = {In this paper we discuss research issues, practical matters and legal constraints driving the design and development of lawful tools and frameworks for a real-time, automated analysis of Internet traffic, supporting detection and recovery of hidden traffic and botnets, as well as preserving the integrity and confidentiality of evidences. We propose a methodological perspective and lines of development that in our vision are the basic pillars of such a framework, to address a multi-stakeholder, multinational scenario.},
booktitle = {Proceedings of the 1st Workshop on Flexible Resource and Application Management on the Edge},
pages = {21–25},
numpages = {5},
keywords = {telecommunication networks, security, privacy, machine learning, edge computing, data analysis, cyber-defense, cloud computing},
location = {Virtual Event, Sweden},
series = {FRAME '21}
}

@inproceedings{10.1145/3417310.3431397,
author = {Yamaguchi, Naoki and Nakazato, Hidenori},
title = {Distributed control function selection method for service function chaining in NDN},
year = {2020},
isbn = {9781450381314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3417310.3431397},
doi = {10.1145/3417310.3431397},
abstract = {In this article, we discuss the function selection method in Function Chaining (NDN-FC) on Named Data Networking (NDN), which is an information-centric networking technology, in order to solve the problems caused by the increase in IoT devices. There is a previous study [10] on the function selection method in NDN-FC, but their proposal is a centralized approach and a coordinator overlooking the entire network is required. We propose a distributed control type function selection method. In order to implement this method, it is necessary to extend interest packet, data packet and forwarding of each node. We compared the existing method and the proposed method using ndnSIM, which is an NDN network simulator. The results of the proposed method are close to those of the method that requires the coordinator in terms of service execution delay and load balancing.},
booktitle = {Proceedings of the Workshop on Cloud Continuum Services for Smart IoT Systems},
pages = {26–31},
numpages = {6},
keywords = {function selection, function chaining, NDN, IoT},
location = {Virtual Event, Japan},
series = {CCIoT '20}
}

@inproceedings{10.1145/3417310.3431399,
author = {Kanai, Kenji and Nakazato, Hidenori and Kanemitsu, Hidehiro and Detti, Andrea},
title = {ThingVisor factory: thing virtualization platform for things as a service},
year = {2020},
isbn = {9781450381314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3417310.3431399},
doi = {10.1145/3417310.3431399},
abstract = {In order to provide interoperability of cross-domain IoT applications involving different IoT platforms, the authors previously proposed a virtual IoT system called VirIoT. The proposed system is composed of two functionalities: ThingVisor and vSilo, and it aims at decoupling IoT device providers and IoT application developers. ThingVisor enables to produce virtual IoT devices, or Virtual Things, from physical IoT devices for sharing the physical devices among cross-domain IoT applications. In addition, vSilo enables to bridge between such Virtual Things and IoT applications for the interoperability of cross-domain IoT devices. In this paper, in order to enhance the VirIoT system, we propose ThingVisor Factory that helps to design ThingVisors in a user-friendly way and deploy them on demand autonomously by following container orchestration methodologies, such as Kubernetes. ThingVisor Factory is based on two concepts: dataflow programming-based Graphical User Interface (GUI) and service function chaining-based ThingVisor development.},
booktitle = {Proceedings of the Workshop on Cloud Continuum Services for Smart IoT Systems},
pages = {7–12},
numpages = {6},
keywords = {thing hypervisor, service function chaining, IoT virtualization, IoT platform},
location = {Virtual Event, Japan},
series = {CCIoT '20}
}

@inproceedings{10.1145/3487923.3487937,
author = {Jaiswal, Rituka and Davidrajuh, Reggie and Wondimagegnehu, S. M.},
title = {Fog Computing for Efficient Predictive Analysis in Smart Grids},
year = {2021},
isbn = {9781450385756},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3487923.3487937},
doi = {10.1145/3487923.3487937},
abstract = {The traditional centralized Cloud system for data processing is ineffective due to high application latency, data security issues, big data issues, and so on. Current Smart Grid sensors are producing huge amount of data and therefore need Fog Computing for real-time decision making. In this paper, we propose a Fog Computing architecture for executing a Smart Grid application. We use a crucial application of Smart Grid, which is future power consumption forecasting for processing on Fog and Cloud platforms. Also, to show the efficacy of Fog Computing for the power forecasting application, we measure and compare the run time and memory consumed on Fog and Cloud platforms. It is theoretically proved that Fog platforms performs better once the Fog network optimization is achieved.},
booktitle = {Proceedings of the International Conference on Artificial Intelligence and Its Applications},
articleno = {14},
numpages = {6},
keywords = {Smart Grids, Power consumption forecasting, Machine Learning, Internet Of Things, Fog Computing, Deep Learning, Cloud Computing},
location = {Virtual Event, Mauritius},
series = {icARTi '21}
}

@inproceedings{10.1145/3493651.3493669,
author = {Klingler, Raffael and Trifunovic, Nemanja and Spillner, Josef},
title = {Beyond @CloudFunction: Powerful Code Annotations to Capture Serverless Runtime Patterns},
year = {2021},
isbn = {9781450391726},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3493651.3493669},
doi = {10.1145/3493651.3493669},
abstract = {Simplicity in elastically scalable application development is a key concern addressed by the serverless computing paradigm, in particular the code-level Function-as-a-Service (FaaS). Various FaaSification frameworks demonstrated that marking code methods to streamline their offloading as cloud functions offers a simple bridge to software engineering habits. As application complexity increases, more complex runtime patterns with background activities, such as keeping containerised cloud functions warm to ensure the absence of cold starts, usually require giving up on simplicity and instead investing efforts into orchestrating infrastructure. By bringing infrastructure-as-code concepts into the function source via powerful code annotations, typical orchestration patterns can be simplified again. We evaluate this idea and demonstrate its practical feasibility with FaaS Fusion, an annotations library and transpiler framework for JavaScript.},
booktitle = {Proceedings of the Seventh International Workshop on Serverless Computing (WoSC7) 2021},
pages = {23–28},
numpages = {6},
keywords = {software engineering, serverless computing, deployment, cloudware},
location = {Virtual Event, Canada},
series = {WoSC '21}
}

@inproceedings{10.1145/3452369.3463820,
author = {Grossi, Valerio and Trasarti, Roberto and Dazzi, Patrizio},
title = {Data Science Workflows for the Cloud/Edge Computing Continuum},
year = {2021},
isbn = {9781450383844},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3452369.3463820},
doi = {10.1145/3452369.3463820},
abstract = {Research infrastructures play a crucial role in the development of data science. In fact, the conjunction of data, infrastructures and analytical methods enable multidisciplinary scientists and innovators to extract knowledge and to make the knowledge and experiments reusable by the scientific community, innovators providing an impact on science and society. Resources such as data and methods, help domain and data scientists to transform research in an innovation question into a responsible data-driven analytical. On the other hands, Edge computing is a new computing paradigm that is spreading and developing at an incredible pace. Edge computing is based on the assumption that for certain applications is beneficial to bring the computation as much close as possible to data or end-users. This paper introduces an approach for writing data science workflows targeting research infrastructures that encompass resources located at the edge of the network.},
booktitle = {Proceedings of the 1st Workshop on Flexible Resource and Application Management on the Edge},
pages = {41–44},
numpages = {4},
keywords = {workflow languages, research infrastructure, edge computing, data science},
location = {Virtual Event, Sweden},
series = {FRAME '21}
}

@inproceedings{10.1145/3423211.3425686,
author = {Xu, Zhuangdi and Shah, Harshil S and Ramachandran, Umakishore},
title = {Coral-Pie: A Geo-Distributed Edge-compute Solution for Space-Time Vehicle Tracking},
year = {2020},
isbn = {9781450381536},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3423211.3425686},
doi = {10.1145/3423211.3425686},
abstract = {We present a distributed system architecture which is scalable by design for cross-camera vehicle tracking at video ingestion time dubbed Coral-Pie. To meet the latency bounds for timely processing of every frame at each camera, we associate dedicated low-cost computational resource for each camera, which consists of two Raspberry Pi 3B+'s and one Coral Accelerator (EdgeTpu). The end-to-end system generates and stores the tracks in a graph database for easy querying. We use the Cloud-Edge-Device continuum to appropriately place the components of the distributed system architecture. Using the timing profiles of the sub-tasks involved in the continuous processing that needs to happen on every frame in each camera, we map the elements of the processing onto the computational resource associated with each camera. Performance evaluation of the proof-of-concept system is conducted using live streams from five campus cameras. The evaluation includes microbenchmarks as well as application level studies. The controlled experiments using live cameras are augmented with a simulation-based study to show the self-healing property of the system and the system scalability.},
booktitle = {Proceedings of the 21st International Middleware Conference},
pages = {400–414},
numpages = {15},
keywords = {multi-camera vehicle tracking, large-scale camera network, geo-distributed edge architecture},
location = {Delft, Netherlands},
series = {Middleware '20}
}

@inproceedings{10.1145/3417310.3431398,
author = {Dreyer, Julian and Fischer, Marten and T\"{o}njes, Ralf},
title = {Performance analysis of hyperledger fabric 2.0 blockchain platform},
year = {2020},
isbn = {9781450381314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3417310.3431398},
doi = {10.1145/3417310.3431398},
abstract = {Hyperledger Fabric is currently one of the most popular business Blockchain platforms. With its included functionality of executing custom smart contracts, Fabric has become one of the most widely used frameworks, e.g. for industry 4.0 applications. Though, most applications require a previously known data throughput. For a potentially interested developer, it is not trivial to decide, whether a given Fabric network configuration will meet the required expectations in regards to performance. Thus this work shows a performance analysis for Hyperledger Fabric v2.0 and focusses on the evaluation of throughput, latency and error rate, together with the overall scalability of the Fabric Blockchain platform. The results show, that Fabric v2.0 outperforms previous versions in almost any regard in addition to an improved smart contract lifecycle.},
booktitle = {Proceedings of the Workshop on Cloud Continuum Services for Smart IoT Systems},
pages = {32–38},
numpages = {7},
keywords = {throughput, scaling, performance analysis, latency, hyperledger fabric v2.0, error rate, distributed ledger technology, blockchain},
location = {Virtual Event, Japan},
series = {CCIoT '20}
}

@inproceedings{10.1145/3417310.3431401,
author = {Kumamoto, Yohei and Nakazato, Hidenori},
title = {Implementation of NDN function chaining using caching for IoT environments},
year = {2020},
isbn = {9781450381314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3417310.3431401},
doi = {10.1145/3417310.3431401},
abstract = {In this paper, we discuss how to implement a mechanism that combines function chaining and cache in Named Data Networking (NDN), an incarnation of information centric networking technology, for real-world IoT environments. We explain our new architecture, called NDN-FC+, for combining function chaining with cache over NDN, and how to extend existing NDN software to support function chaining and caching. The key features discussed in this paper are Interest and Data packet structure, forwarding methods, and naming schemes for a cached content. In particular, it is important to implement the cache, which is one of the major features of NDN. By using the cache, the network will be able to keep contents closer to the users and send them with low latency. Also, by combining function chaining and caching, and caching the content that has been processed by several functions in advance, it will be possible to communicate the processed content without processing. The feasibility of our proposed protocol for caching and forwarding methods is displayed through a prototype implementation. The performance evaluation was performed in a topology that executes the functions chained to the image data from the sensor, assuming use in the real world IoT environment.},
booktitle = {Proceedings of the Workshop on Cloud Continuum Services for Smart IoT Systems},
pages = {20–25},
numpages = {6},
keywords = {function chaining, caching, NDN, IoT},
location = {Virtual Event, Japan},
series = {CCIoT '20}
}

@inproceedings{10.1145/3417310.3431400,
author = {Cozzolino, Vittorio and Flum, Oliver and Ding, Aaron Yi and Ott, J\"{o}rg},
title = {MirageManager: enabling stateful migration for unikernels},
year = {2020},
isbn = {9781450381314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3417310.3431400},
doi = {10.1145/3417310.3431400},
abstract = {Unikernels are a new lightweight virtualization technology born as an alternative to virtual machines and containers. Geared towards service provisioning for the Internet of Things (IoT) and edge computing, they offer extremely small memory footprint and strong isolation properties. However, the unikernels ecosystem is still in its infancy and lacks quintessential functionalities found in more well-established virtualization technologies. For example, stateful migration is a highly desired feature for mobile edge services in distributed environments which is not yet supported by unikernels. This is one of the shortcomings preventing us from reaping the full benefits of unikernels outside of stateless applications.In this work, we aim bridging this gap with MirageManager: a ready-to-deploy unikernel migration system enabling lossless migration supported by a function-level, application logic check-pointing library of our design. Our evaluation results show that MirageManager is able to lower the service downtime by ~80%, and drastically reduce the state transfer data by almost ~100% when comparing against Podman. Additionally, MirageManager also beats Podman, a container-based engine, in parallel service migration across constrained edge networks reducing the overall migration time by up to ~6x.},
booktitle = {Proceedings of the Workshop on Cloud Continuum Services for Smart IoT Systems},
pages = {13–19},
numpages = {7},
keywords = {unikernel, service migration, edge computing},
location = {Virtual Event, Japan},
series = {CCIoT '20}
}

@inproceedings{10.1145/3538393.3544935,
author = {Caiazza, Chiara and Luconi, Valerio and Vecchio, Alessio},
title = {Saving energy on smartphones through edge computing: an experimental evaluation},
year = {2022},
isbn = {9781450393928},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3538393.3544935},
doi = {10.1145/3538393.3544935},
abstract = {Edge computing is a network architecture in which computing and storage capabilities are moved at the fringes of the Internet, close to the end-users. The main goal of edge computing is to enable responsive services, thanks to much shorter paths compared to the ones encountered when communicating with remotely positioned cloud servers. In this paper, we report experimental results concerning an overlooked benefit of edge computing: energy is saved on client devices. We carried out an experimental evaluation using both software-based and hardware-based energy estimation methods. Results show that, for HTTP-based communication, the lifetime of a device can be extended significantly when using the edge instead of a remote cloud.},
booktitle = {Proceedings of the ACM SIGCOMM Workshop on Networked Sensing Systems for a Sustainable Society},
pages = {20–25},
numpages = {6},
keywords = {energy consumption, edge computing, LTE},
location = {Amsterdam, Netherlands},
series = {NET4us '22}
}

@inproceedings{10.1145/3318216.3363299,
author = {McChesney, Jonathan and Wang, Nan and Tanwer, Ashish and de Lara, Eyal and Varghese, Blesson},
title = {DeFog: fog computing benchmarks},
year = {2019},
isbn = {9781450367332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3318216.3363299},
doi = {10.1145/3318216.3363299},
abstract = {There are currently no benchmarks that can directly compare the performance of an application across the cloud-only, edge-only and cloud-edge (Fog) deployment platforms to obtain any insight on potential performance improvement. This paper proposes DeFog, a first Fog benchmarking suite to: (i) alleviate the burden of Fog benchmarking by using a standard methodology, and (ii) facilitate the understanding of the target platform by collecting a catalogue of relevant metrics for a set of benchmarks. The current portfolio of DeFog benchmarks comprises six relevant applications conducive to using the edge. Experimental studies are carried out on multiple target platforms to demonstrate the use of DeFog for collecting metrics related to application latencies (communication and computation), for understanding the impact of stress and concurrent users on application latencies, and for understanding the performance of deploying different combination of services of an application across the cloud and edge. DeFog is available for public download (https://github.com/qub-blesson/DeFog).},
booktitle = {Proceedings of the 4th ACM/IEEE Symposium on Edge Computing},
pages = {47–58},
numpages = {12},
keywords = {fog computing, edge computing, containers, benchmarking},
location = {Arlington, Virginia},
series = {SEC '19}
}

@article{10.1145/3460352,
author = {Seo, Wonik and Cha, Sanghoon and Kim, Yeonjae and Huh, Jaehyuk and Park, Jongse},
title = {SLO-Aware Inference Scheduler for Heterogeneous Processors in Edge Platforms},
year = {2021},
issue_date = {December 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {18},
number = {4},
issn = {1544-3566},
url = {https://doi.org/10.1145/3460352},
doi = {10.1145/3460352},
abstract = {With the proliferation of applications with machine learning (ML), the importance of edge platforms has been growing to process streaming sensor, data locally without resorting to remote servers. Such edge platforms are commonly equipped with heterogeneous computing processors such as GPU, DSP, and other accelerators, but their computational and energy budget are severely constrained compared to the data center servers. However, as an edge platform must perform the processing of multiple machine learning models concurrently for multimodal sensor data, its scheduling problem poses a new challenge to map heterogeneous machine learning computation to heterogeneous computing processors. Furthermore, processing of each input must provide a certain level of bounded response latency, making the scheduling decision critical for the edge platform. This article proposes a set of new heterogeneity-aware ML inference scheduling policies for edge platforms. Based on the regularity of computation in common ML tasks, the scheduler uses the pre-profiled behavior of each ML model and routes requests to the most appropriate processors. It also aims to satisfy the service-level objective (SLO) requirement while reducing the energy consumption for each request. For such SLO supports, the challenge of ML computation on GPUs and DSP is its inflexible preemption capability. To avoid the delay caused by a long task, the proposed scheduler decomposes a large ML task to sub-tasks by its layer in the DNN model.},
journal = {ACM Trans. Archit. Code Optim.},
month = {jul},
articleno = {43},
numpages = {26},
keywords = {task scheduling, machine learning, inference, heterogeneous computing, Edge computing}
}

@inproceedings{10.1145/3587135.3592207,
author = {Azhar, Muhammad Waqar and Zouzoula, Stavroula and Trancoso, Pedro},
title = {ARADA: Adaptive Resource Allocation for Improving Energy Efficiency in Deep Learning Accelerators},
year = {2023},
isbn = {9798400701405},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3587135.3592207},
doi = {10.1145/3587135.3592207},
abstract = {Deep Learning (DL) applications are entering every part of our life given their ability to solve complex problems. Nevertheless, energy efficiency is still a major concern due to the large computational and memory requirements. State-of-the-art accelerators strive to address this issue by optimizing the architecture to the compute requirements of DL algorithms. However, there is always a mismatch between compute and memory requirements and what is offered by a particular design. A way to close this gap is by providing run-time adaptation or resource allocation to improve efficiency.This paper proposes an adaptive resource allocation for deep learning applications (ARADA) with the goal of improving energy efficiency for deep learning accelerators. This is leveraged by having a layer-by-layer resource allocation. The rationale is that each layer in the DL model has a unique compute and memory bandwidth requirement and allocating fixed resources to all layers leads to inefficiencies. This can be achieved by means of resource allocation (e.g., voltage-frequency, memory bandwidth) to save energy without sacrificing performance. Experimental results show that applying ARADA to the execution of 9 state-of-the-art CNN models results in an energy savings of 38% on average compared to race-to-idle for an Edge TPU coupled with LPDDR4 off-chip memory.},
booktitle = {Proceedings of the 20th ACM International Conference on Computing Frontiers},
pages = {63–72},
numpages = {10},
keywords = {Resource Allocation, Energy Efficiency, CNNs, Accelerators},
location = {Bologna, Italy},
series = {CF '23}
}

@proceedings{10.1145/3528226,
title = {WETSEB '22: Proceedings of the 5th International Workshop on Emerging Trends in Software Engineering for Blockchain},
year = {2022},
isbn = {9781450393317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {The 5th Workshop on Emerging Trends in Software Engineering for Blockchain gathers the interests of researchers and practitioneers, from both academia and industry, as well as Ph.D. students working in the field of Blockchain technology, to investigate on and to and tackle the new challenges defined by BOSE. The Workshop's goal is to discuss the progresses made by software engineering on the research and on the practical applications of blockchain technologies and smart contracts, focusing on software engineering principles and practices adopted to deal with such new software technology, and for the technologies relying on it.},
location = {Pittsburgh, Pennsylvania}
}

@inproceedings{10.1145/3600160.3604997,
author = {Sayeed, Sarwar and Pitropakis, Nikolaos and Buchanan, William J. and Markakis, Evangelos and Papatsaroucha, Dimitra and Politis, Ilias},
title = {TRUSTEE: Towards the creation of secure, trustworthy and privacy-preserving framework},
year = {2023},
isbn = {9798400707728},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3600160.3604997},
doi = {10.1145/3600160.3604997},
abstract = {Digital transformation is a method where new technologies replace the old to meet essential organisational requirements and enhance the end-user experience. Technological transformation often improvises the manner in which a facility or resources are delivered to the recipient. Data is one of the key assets of every organisation which influences significantly reaching the long-term objective. Thus, the entities, as well as technologies involved in the data management process, have a significant role to play to secure different data types. However, the traditional data governance process often follows a centralised approach and thus resulting in various cyber attacks, whereas the distributed approaches are mostly research prototypes and often comprise various security challenges. Security incidents such as data theft fabricate the integrity of confidential data and thus the consequences are often disastrous. To address the challenges, we introduce TRUSTEE, a data-driven platform which aims to provide a secure and privacy-by-design framework to empower companies, organisations, and individuals to access different data domains, use and re-use the data and metadata to extract knowledge with trust and confidentiality. In this paper, we assess the effectiveness of the platform by reviewing the potential challenges and threats associated with the incorporated technologies. Our research emphasises the efficacy of distributed technologies to indicate their significance in data integrity and security.},
booktitle = {Proceedings of the 18th International Conference on Availability, Reliability and Security},
articleno = {145},
numpages = {10},
keywords = {Trust, Security, Privacy, IPFS, Distributed Ledger},
location = {<conf-loc>, <city>Benevento</city>, <country>Italy</country>, </conf-loc>},
series = {ARES '23}
}

@inproceedings{10.1145/3583678.3596899,
author = {Gerig, Pascal and M\'{e}n\'{e}trey, J\"{a}mes and Lanoix, Baptiste and Stoller, Florian and Felber, Pascal and Pasin, Marcelo and Schiavoni, Valerio},
title = {Preventing EFail Attacks with Client-Side WebAssembly: The Case of Swiss Post's IncaMail},
year = {2023},
isbn = {9798400701221},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3583678.3596899},
doi = {10.1145/3583678.3596899},
abstract = {Traditional email encryption schemes are vulnerable to EFail attacks, which exploit the lack of message authentication by manipulating ciphertexts and exfiltrating plaintext via HTML backchannels. Swiss Post's IncaMail, a secure email service for transmitting legally binding, encrypted, and verifiable emails, counters EFail attacks using an authenticated-encryption with associated data (AEAD) encryption scheme to ensure message privacy and authentication between servers. IncaMail relies on a trusted infrastructure backend and encrypts messages per user policy. This paper presents a revised IncaMail architecture that offloads the majority of cryptographic operations to clients, offering benefits such as reduced computational load and energy footprint, relaxed trust assumptions, and per-message encryption key policies. Our proof-of-concept prototype and benchmarks demonstrate the robustness of the proposed scheme, with client-side WebAssembly-based cryptographic operations yielding significant performance improvements (up to ~14\texttimes{}) over conventional JavaScript implementations.},
booktitle = {Proceedings of the 17th ACM International Conference on Distributed and Event-Based Systems},
pages = {151–156},
numpages = {6},
keywords = {mitigation, cryptography, webassembly, email, EFail},
location = {Neuchatel, Switzerland},
series = {DEBS '23}
}

@inproceedings{10.1145/3578354.3592867,
author = {Elkhatib, Yehia and Poyato, Jose Povedano},
title = {An Evaluation of Service Mesh Frameworks for Edge Systems},
year = {2023},
isbn = {9798400700828},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3578354.3592867},
doi = {10.1145/3578354.3592867},
abstract = {Service Mesh Technologies (SMTs) are increasingly popular in simplifying the networking between microservices. They allow one to declaratively and programmatically define service-to-service policies and interactions, and take all sorts of network management logic (e.g., traffic splitting, request tracing, security, reliability) out of the application. This simplifies the development of microservice architectures, which are widely used in cloud and edge applications. However, the suitability for different SMTs for use in edge applications is unclear. Thus, this work compares the two most popular SMTs (Istio and Linkerd) in terms of performance and overhead for resource-constrained devices. Through extensive experimentation and comparing with a baseline of standard networking in a Kubernetes cluster, we identify that Linkerd offers a more edge-friendly SMT option in contrast to Istio. Overall, Istio's communications are ≈10% slower than Linkerd at an increased 1.2--1.4x more memory and ≈1.2x more CPU utilization.},
booktitle = {Proceedings of the 6th International Workshop on Edge Systems, Analytics and Networking},
pages = {19–24},
numpages = {6},
keywords = {system performance and measurement, IoT networking, edge computing, service mesh},
location = {Rome, Italy},
series = {EdgeSys '23}
}

@article{10.1145/1646353.1646364,
author = {Groth, Dennis P. and MacKie-Mason, Jeffrey K.},
title = {Why an informatics degree?},
year = {2010},
issue_date = {February 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {53},
number = {2},
issn = {0001-0782},
url = {https://doi.org/10.1145/1646353.1646364},
doi = {10.1145/1646353.1646364},
abstract = {Isn't computer science enough?},
journal = {Commun. ACM},
month = {feb},
pages = {26–28},
numpages = {3}
}

@inproceedings{10.1145/3551663.3558680,
author = {Hervella, Cristina and Diez, Luis and Fern\'{a}ndez, F\'{a}tima and Hern\'{a}ndez Marcano, N\'{e}stor J. and Hylsberg Jacobsen, Rune and Ag\"{u}ero, Ram\'{o}n},
title = {Realistic Assessment of Transport Protocols Performance over LEO-based Communications},
year = {2022},
isbn = {9781450394833},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3551663.3558680},
doi = {10.1145/3551663.3558680},
abstract = {We study the performance exhibited by transport protocols, TCP and QUIC, over realistic satellite networks. We propose a novel methodology, which combines real implementation (exploiting virtualization techniques) and simulation, to carry out systematic and repetitive experiments. We modify the default operation of the ns-3 framework and we integrate the dynamism that characterizes links in satellite communications, particularly links to LEO satellites. We carry out a thorough assessment over different setups, changing the operating band and the buffer length. In addition, we ascertain the impact of using the multi-streaming feature that QUIC includes. The results show that QUIC yields lower delays than TCP, although in particular setups it might suffer from higher jitter. In addition, using multiple streams in QUIC does not yield a relevant gain. In any case, we can conclude that the behavior of transport protocols over non-terrestrial-networks might not be always optimum and that QUIC can bring benefits when compared to TCP.},
booktitle = {Proceedings of the 19th ACM International Symposium on Performance Evaluation of Wireless Ad Hoc, Sensor, &amp; Ubiquitous Networks},
pages = {91–98},
numpages = {8},
keywords = {ns-3, docker, delay, QUIC, LMS, LEO},
location = {Montreal, Quebec, Canada},
series = {PE-WASUN '22}
}

@inproceedings{10.1145/3589010.3594892,
author = {Korontanis, Ioannis and Makris, Antonios and Theodoropoulos, Theodoros and Tserpes, Konstantinos},
title = {Real-time Monitoring and Analysis of Edge and Cloud Resources},
year = {2023},
isbn = {9798400701641},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589010.3594892},
doi = {10.1145/3589010.3594892},
abstract = {As Edge and Cloud platforms increasingly become the basis for hosting applications, monitoring systems need to be able to monitor both the hosts and the deployed applications. Ensuring seamless monitoring of Edge hosts is the most crucial factor, regardless of whether they are virtual machines, Raspberry Pis, or even typical personal computers. The application orchestration process could benefit greatly from monitoring systems, as they could serve as the main source of characterizing hosts and reporting metrics related to users and platforms. This paper introduces a Prometheus-based monitoring stack that is able to monitor both applications and resources on Kubernetes clusters. This monitoring stack has been tested and is already in use within the ACCORDION platform to efficiently monitor applications, regardless of their development unit and host types.},
booktitle = {Proceedings of the 3rd Workshop on Flexible Resource and Application Management on the Edge},
pages = {13–18},
numpages = {6},
keywords = {prometheus, monitoring, edge, cluster, cloud, characterization},
location = {Orlando, FL, USA},
series = {FRAME '23}
}

@proceedings{10.1145/3578354,
title = {EdgeSys '23: Proceedings of the 6th International Workshop on Edge Systems, Analytics and Networking},
year = {2023},
isbn = {9798400700828},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Rome, Italy}
}

@inproceedings{10.1145/3578245.3585329,
author = {Iosup, Alexandru and Prodan, Radu and Varbanescu, Ana-Lucia and Talluri, Sacheendra and Magalhaes, Gilles and Hokstam, Kailhan and Zwaan, Hugo and van Beek, Vincent and Farahani, Reza and Kimovski, Dragi},
title = {Graph Greenifier: Towards Sustainable and Energy-Aware Massive Graph Processing in the Computing Continuum},
year = {2023},
isbn = {9798400700729},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3578245.3585329},
doi = {10.1145/3578245.3585329},
abstract = {Our society is increasingly digital, and its processes are increasingly digitalized. As an emerging technology for the digital society, graphs provide a universal abstraction to represent concepts and objects, and the relationships between them. However, processing graphs at a massive scale raises numerous sustainability challenges; becoming energy-aware could help graph-processing infrastructure alleviate its climate impact. Graph Greenifier aims to address this challenge in the conceptual framework offered by the Graph Massivizer architecture. We present an early vision of how Graph Greenifier could provide sustainability analysis and decision-making capabilities for extreme graph-processing workloads. Graph Greenifier leverages an advanced digital twin for data center operations, based on the OpenDC open-source simulator, a novel toolchain for workload-driven simulation of graph processing at scale, and a sustainability predictor. The input to the digital twin combines monitoring of the information and communication technology infrastructure used for graph processing with data collected from the power grid. Graph Greenifier thus informs providers and consumers on operational sustainability aspects, requiring mutual information sharing, reducing energy consumption for graph analytics, and increasing the use of electricity from renewable sources.},
booktitle = {Companion of the 2023 ACM/SPEC International Conference on Performance Engineering},
pages = {209–214},
numpages = {6},
keywords = {sustainability, scalability, graph processing, graph massivizer, graph greenifier, energy-awareness, digital twin, computing continuum},
location = {Coimbra, Portugal},
series = {ICPE '23 Companion}
}

@inproceedings{10.1145/3582515.3609568,
author = {Calvio, Alessandro and Sabbioni, Andrea and Bujari, Armir and Foschini, Luca},
title = {An Event and Service Mesh Architecture Supporting Service Integration in Society 5.0 enabled Smart Cities},
year = {2023},
isbn = {9798400701160},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3582515.3609568},
doi = {10.1145/3582515.3609568},
abstract = {Society 5.0 envisions a more resilient, sustainable, and human-centered society fostered by ever-evolving cooperation and knowledge sharing among the many digital systems already shaping our daily lives. However, the current state of smart cities often consists of siloed systems, with different actors and stakeholders managing their services and assets independently. This phenomenon is evident in both technological and operational domains, posing challenges to seamless collaboration. In this context, new cloud computing models and technologies like event and service mesh promise to reduce the burden associated with the development and integration of solutions. In the attempt to pave the way for more integrated IT environments, we propose a practical architecture that combines service and event mesh technologies, enabling the seamless exploitation of service invocation and composition based on event distribution and direct service calls. Our proposal allows applications to remain transparent of the underlying technology, facilitating various optimizations on the network and management plane, necessary to meet the diverse operational requirements of complex and heterogeneous applications. We validate our proposal in a real-use case scenario implementation, discussing the tradeoffs that emerge.},
booktitle = {Proceedings of the 2023 ACM Conference on Information Technology for Social Good},
pages = {462–470},
numpages = {9},
keywords = {Smart City, Service Mesh, Service Integration, Middleware, Event Mesh},
location = {Lisbon, Portugal},
series = {GoodIT '23}
}

@inproceedings{10.5555/3370272.3370308,
author = {Varghese, Blesson and Ray, Suprio and Gohil, Bhavesh N. and Vega, Sergio},
title = {Research challenges in query processing and data analytics on the edge},
year = {2019},
publisher = {IBM Corp.},
address = {USA},
abstract = {The accelerated growth of data has made efficient query processing and data analytics more important than ever. While the Cloud has provided an excellent underpinning solution to store, manage and process data, it is becoming increasingly difficult, as the Cloud necessitates sending all data that is generated by billions of user devices and sensors to distant data centres far away from the data source. This is expected to make query processing and data analytics challenging. This paper examines the challenges in developing pragmatic solutions for processing queries and performing analytics using the emerging Edge computing paradigm. In this paradigm, compute infrastructure is offered at the edge of the network, which is closer to the data source. A simulation study to highlight the advantages of Edge computing over the Cloud is presented.},
booktitle = {Proceedings of the 29th Annual International Conference on Computer Science and Software Engineering},
pages = {317–322},
numpages = {6},
location = {Toronto, Ontario, Canada},
series = {CASCON '19}
}

@article{10.1109/TNET.2020.2979361,
author = {Cao, Xiaofeng and Tang, Guoming and Guo, Deke and Li, Yan and Zhang, Weiming},
title = {Edge Federation: Towards an Integrated Service Provisioning Model},
year = {2020},
issue_date = {June 2020},
publisher = {IEEE Press},
volume = {28},
number = {3},
issn = {1063-6692},
url = {https://doi.org/10.1109/TNET.2020.2979361},
doi = {10.1109/TNET.2020.2979361},
abstract = {Edge computing is a promising computing paradigm by pushing the cloud service to the network edge. To this end, edge infrastructure providers (EIPs) need to bring computation and storage resources to the network edge and allow edge service providers (ESPs) to provision latency-critical services for end users. Currently, EIPs prefer to establish a series of private edge-computing environments to serve specific requirements of users. This kind of resource provisioning mechanism severely limits the development and spread of edge computing in serving diverse user requirements. In this paper, we propose an integrated resource provisioning model, named edge federation, to seamlessly realize the resource cooperation and service provisioning across standalone edge computing providers and clouds. To efficiently schedule and utilize the resources across multiple EIPs, we systematically characterize the provisioning process as a large-scale linear programming (LP) problem and transform it into an easily solved form. Accordingly, we design a dynamic algorithm to tackle the varying service demands from users. We conduct extensive experiments over the base station networks in Toronto. Compared with the fixed contract model and multihoming model, edge federation can reduce the overall costs of EIPs by 23.3% to 24.5%, and 15.5% to 16.3%, respectively.},
journal = {IEEE/ACM Trans. Netw.},
month = {jun},
pages = {1116–1129},
numpages = {14}
}

@inproceedings{10.1145/3565476.3569099,
author = {Afzal, Samira and Tashtarian, Farzad and Hadian, Hamid and Erfanian, Alireza and Timmerer, Christian and Prodan, Radu},
title = {OTEC: an optimized transcoding task scheduler for cloud and fog environments},
year = {2022},
isbn = {9781450399364},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3565476.3569099},
doi = {10.1145/3565476.3569099},
abstract = {Encoding and transcoding videos into multiple codecs and representations is a significant challenge that requires seconds or even days on high-performance computers depending on many technical characteristics, such as video complexity or encoding parameters. Cloud computing offering on-demand computing resources optimized to meet the needs of customers and their budgets is a promising technology for accelerating dynamic transcoding workloads. In this work, we propose OTEC, a novel multi-objective optimization method based on the mixed-integer linear programming model to optimize the computing instance selection for transcoding processes. OTEC determines the type and number of cloud and fog resource instances for video encoding and transcoding tasks with optimized computation cost and time. We evaluated OTEC on AWS EC2 and Exoscale instances for various administrator priorities, the number of encoded video segments, and segment transcoding times. The results show that OTEC can achieve appropriate resource selections and satisfy the administrator's priorities in terms of time and cost minimization.},
booktitle = {Proceedings of the 2nd International Workshop on Design, Deployment, and Evaluation of Network-Assisted Video Streaming},
pages = {21–26},
numpages = {6},
keywords = {transcoding, scheduler, optimization, multi-objective, fog, cloud, MILP},
location = {Rome, Italy},
series = {ViSNext '22}
}

@inproceedings{10.1145/3578245.3585022,
author = {Jansen, Matthijs and Donkervliet, Jesse and Trivedi, Animesh and Iosup, Alexandru},
title = {Can My WiFi Handle the Metaverse? A Performance Evaluation Of Meta's Flagship Virtual Reality Hardware},
year = {2023},
isbn = {9798400700729},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3578245.3585022},
doi = {10.1145/3578245.3585022},
abstract = {Extending human societies into virtual space through the construction of a metaverse has been a long-term challenge in both industry and academia. Achieving this challenge is now closer than ever due to advances in computer systems, facilitating large-scale online platforms such as Minecraft and Roblox that fulfill an increasing number of societal needs, and extended reality (XR) hardware, which provides users with state-of-the-art immersive experiences. For a metaverse to succeed, we argue that all involved systems must provide consistently good performance. However, there is a lack of knowledge on the performance characteristics of extended reality devices. In this paper, we address this gap and focus on extended- and virtual-reality hardware. We synthesize a user-centered system model that models common deployments of XR hardware and their trade-offs. Based on this model, we design and conduct real-world experiments with Meta's flagship virtual reality device, the Quest Pro. We highlight two surprising results from our findings which show that (i) under our workload, the battery drains 15% faster when using wireless offloading compared to local execution, and (ii) the outdated 2.4 GHz WiFi4 gives surprisingly good performance, with 99% of samples achieving a frame rate of at least 65 Hz, compared to the 72 Hz performance target. Our experimental setup and data are available at https://github.com/atlarge-research/measuring-the-metaverse.},
booktitle = {Companion of the 2023 ACM/SPEC International Conference on Performance Engineering},
pages = {297–303},
numpages = {7},
keywords = {virtual worlds, virtual reality, task offloading, performance analysis, networking, metaverse, gaming, computation},
location = {Coimbra, Portugal},
series = {ICPE '23 Companion}
}

@inproceedings{10.1145/3522664.3528603,
author = {Husom, Erik Johannes and Tverdal, Simeon and Goknil, Arda and Sen, Sagar},
title = {UDAVA: an unsupervised learning pipeline for sensor data validation in manufacturing},
year = {2022},
isbn = {9781450392754},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3522664.3528603},
doi = {10.1145/3522664.3528603},
abstract = {Manufacturing has enabled the mechanized mass production of the same (or similar) products by replacing craftsmen with assembly lines of machines. The quality of each product in an assembly line greatly hinges on continual observation and error compensation during machining using sensors that measure quantities such as position and torque of a cutting tool and vibrations due to possible imperfections in the cutting tool and raw material. Patterns observed in sensor data from a (near-)optimal production cycle should ideally recur in subsequent production cycles with minimal deviation. Manually labeling and comparing such patterns is an insurmountable task due to the massive amount of streaming data that can be generated from a production process. We present UDAVA, an unsupervised machine learning pipeline that automatically discovers process behavior patterns in sensor data for a reference production cycle. UDAVA performs clustering of reduced dimensionality summary statistics of raw sensor data to enable high-speed clustering of dense time-series data. It deploys the model as a service to verify batch data from subsequent production cycles to detect recurring behavior patterns and quantify deviation from the reference behavior. We have evaluated UDAVA from an AI Engineering perspective using two industrial case studies.},
booktitle = {Proceedings of the 1st International Conference on AI Engineering: Software Engineering for AI},
pages = {159–169},
numpages = {11},
location = {Pittsburgh, Pennsylvania},
series = {CAIN '22}
}

@inproceedings{10.1145/3526073.3527584,
author = {Kolltveit, Ask Berstad and Li, Jingyue},
title = {Operationalizing machine learning models: a systematic literature review},
year = {2023},
isbn = {9781450393195},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3526073.3527584},
doi = {10.1145/3526073.3527584},
abstract = {Deploying machine learning (ML) models to production with the same level of rigor and automation as traditional software systems has shown itself to be a non-trivial task, requiring extra care and infrastructure to deal with the additional challenges. Although many studies focus on adapting ML software engineering (SE) approaches and techniques, few studies have summarized the status and challenges of operationalizing ML models. Model operationalization encompasses all steps after model training and evaluation, including packaging the model in a format appropriate for deployment, publishing to a model registry or storage, integrating the model into a broader software system, serving, and monitoring. This study is the first systematic literature review investigating the techniques, tools, and infrastructures to operationalize ML models. After reviewing 24 primary studies, the results show that there are a number of tools for most use cases to operationalize ML models and cloud deployment in particular. The review also revealed several research opportunities, such as dynamic model-switching, continuous model-monitoring, and efficient edge ML deployments.},
booktitle = {Proceedings of the 1st Workshop on Software Engineering for Responsible AI},
pages = {1–8},
numpages = {8},
keywords = {systematic literature review, operationalization, machine learning, deployment, MLOps},
location = {Pittsburgh, Pennsylvania},
series = {SE4RAI '22}
}

@inproceedings{10.1145/2737909.2737913,
author = {Reed, Daniel A.},
title = {Beowulf Clusters: From Research Curiosity to Exascale},
year = {2014},
isbn = {9781450330312},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2737909.2737913},
doi = {10.1145/2737909.2737913},
abstract = {This paper reviews the technical and social events that stimulated early deployments of large-scale Beowulf-style clusters for production scientific and engineering use at the National Center for Supercomputing Applications (NCSA) and the subsequent development of the NSF TeraGrid. Insights and lessons from these experiences have shaped further development of high-performance computing environments and exposed a set of research challenges for creation of exascale computing systems.},
booktitle = {Proceedings of the 20 Years of Beowulf Workshop on Honor of Thomas Sterling's 65th Birthday},
pages = {28–33},
numpages = {6},
keywords = {Top500, TeraGrid, Scheduling, Scalability, Resilience, Reliability, PACI, NCSA, Linux, GPUs, Exascale, Energy Efficiency, Big Data, Beowulf cluster, Accelerators},
location = {Annapolis, MD, USA},
series = {Beowulf '14}
}

@proceedings{10.1145/3599733,
title = {e-Energy '23 Companion: Companion Proceedings of the 14th ACM International Conference on Future Energy Systems},
year = {2023},
isbn = {9798400702273},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Orlando, FL, USA}
}

@inproceedings{10.1145/3528535.3531517,
author = {Pfandzelter, Tobias and Bermbach, David},
title = {Celestial: Virtual Software System Testbeds for the LEO Edge},
year = {2022},
isbn = {9781450393409},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3528535.3531517},
doi = {10.1145/3528535.3531517},
abstract = {As private space companies such as SpaceX and Telesat are building large LEO satellite constellations to provide global broadband Internet access, researchers have proposed to embed compute services within satellite constellations to provide computing services on the *LEO edge*. While the LEO edge is merely theoretical at the moment, providers are expected to rapidly develop their satellite technologies to keep the upper hand in the new space race.In this paper, we answer the question of how researchers can explore the possibilities of LEO edge computing and evaluate arbitrary software systems in an accurate runtime environment and with cost-efficient scalability. To that end, we present Celestial, a virtual testbed for the LEO edge based on microVMs. Celestial can efficiently emulate individual satellites and their movement as well as ground station servers with realistic network conditions and in an application-agnostic manner, which we show empirically. Additionally, we explore opportunities and implications of deploying a real-time remote sensing application on LEO edge infrastructure in a case study on Celestial.},
booktitle = {Proceedings of the 23rd ACM/IFIP International Middleware Conference},
pages = {69–81},
numpages = {13},
keywords = {LEO edge, satellite networks, software testbeds},
location = {<conf-loc>, <city>Quebec</city>, <state>QC</state>, <country>Canada</country>, </conf-loc>},
series = {Middleware '22}
}

@proceedings{10.1145/3528229,
title = {SESoS '22: Proceedings of the 10th IEEE/ACM International Workshop on Software Engineering for Systems-of-Systems and Software Ecosystems},
year = {2022},
isbn = {9781450393348},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {SESoS 2022 provides researchers and practitioners with a forum to exchange ideas and experiences, analyze research and development issues, discuss promising solutions, and propose theoretical foundations for development and evolution of complex software-intensive systems, inspiring visions for the future of Software Engineering for Systems-of-Systems (SoS) and Software Ecosystems (SECO), as well as paving the way for a more structured community effort.},
location = {Pittsburgh, Pennsylvania}
}

@article{10.1145/3510411,
author = {Korala, Harindu and Georgakopoulos, Dimitrios and Jayaraman, Prem Prakash and Yavari, Ali},
title = {A Survey of Techniques for Fulfilling the Time-Bound Requirements of Time-Sensitive IoT Applications},
year = {2022},
issue_date = {January 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {11s},
issn = {0360-0300},
url = {https://doi.org/10.1145/3510411},
doi = {10.1145/3510411},
abstract = {This article surveys existing techniques for meeting the time-bound requirements of time-sensitive applications in the Internet of Things (IoT). To provide the foundation for identifying and classifying relevant techniques, we present three sample time-sensitive IoT applications and their time-bound requirements, describe the main computation and network resources in IoT that can be used to process such applications, and identify the main challenges in meeting their time-bound requirements. Based on these, the article presents a comprehensive literature review of existing techniques and tools that can help meet application-specific time-bound requirements in IoT. The article also includes a gap analysis in existing research outcomes and proposes research directions for bridging the remaining research gaps in supporting time-sensitive IoT applications.},
journal = {ACM Comput. Surv.},
month = {sep},
articleno = {228},
numpages = {36},
keywords = {time-bound, time sensitive, Internet of Things (IoT)}
}

@article{10.1145/3616014,
author = {Savaglio, Claudio and Barbuto, Vincenzo and Awan, Faraz Malik and Minerva, Roberto and Crespi, Noel and Fortino, Giancarlo},
title = {Opportunistic Digital Twin: an Edge Intelligence enabler for Smart City},
year = {2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1550-4859},
url = {https://doi.org/10.1145/3616014},
doi = {10.1145/3616014},
abstract = {Although Digital Twins (DTs) became very popular in industry, nowadays they represent a pre-requisite of many systems across different domains, by taking advantage of the disrupting digital technologies such as Artificial Intelligence (AI), Edge Computing and Internet of Things (IoT). In this paper we present our “opportunistic” interpretation, which advances the traditional DT concept and provides a valid support for enabling next-generation solutions in dynamic, distributed and large scale scenarios as smart cities. Indeed, by collecting simple data from the environment and by opportunistically elaborating them through AI techniques directly at the network edge (also referred to as Edge Intelligence), a digital version of a physical object can be built from the bottom up as well as dynamically manipulated and operated in a data-driven manner, thus enabling prompt responses to external stimuli and effective command actuation. To demonstrate the viability of our Opportunistic Digital Twin (ODT) a real use case focused on a traffic prediction task has been incrementally developed and presented, showing improved inference performance and reduced network latency, bandwidth and power consumption.},
note = {Just Accepted},
journal = {ACM Trans. Sen. Netw.},
month = {aug},
keywords = {Synthetic Sensing, Internet of Things, Edge Intelligence, Digital Twins}
}

@inproceedings{10.1145/3472883.3487008,
author = {Saurez, Enrique and Gupta, Harshit and Daglis, Alexandros and Ramachandran, Umakishore},
title = {OneEdge: An Efficient Control Plane for Geo-Distributed Infrastructures},
year = {2021},
isbn = {9781450386388},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3472883.3487008},
doi = {10.1145/3472883.3487008},
abstract = {Resource management for geo-distributed infrastructures is challenging due to the scarcity and non-uniformity of edge resources, as well as the high client mobility and workload surges inherent to situation awareness applications. Due to their centralized nature, state-of-the-art schedulers that work well in datacenters lack the performance and feature requirements of such applications. We present OneEdge, a hybrid control plane that enables autonomous decision-making at edge sites for localized, rapid single-site application deployment. Edge sites handle mobility, churn, and load spikes, by cooperating with a centralized controller that allows coordinated multi-site scheduling and dynamic reconfiguration.OneEdge's scheduling decisions are driven by each application's end-to-end service level objective (E2E SLO) as well as the specific requirements of situation awareness applications. OneEdge's novel distributed state management combines autonomous decision-making at the edge sites for rapid localized resource allocations with decision-making at the central controller when multi-site application deployment is needed.Using a mix of applications on multi-region Azure instances, we show that, in contrast to centralized or fully distributed control planes, OneEdge caters to the unique requirements of situation awareness applications. Compared to a centralized control plane, OneEdge reduces deployment latency by 66% for single-site applications, without compromising E2E SLOs.},
booktitle = {Proceedings of the ACM Symposium on Cloud Computing},
pages = {182–196},
numpages = {15},
keywords = {Geo Distributed, Edge Computing, Control Plane Architecture},
location = {Seattle, WA, USA},
series = {SoCC '21}
}

@inproceedings{10.1145/3437378.3444367,
author = {Aslanpour, Mohammad S. and Toosi, Adel N. and Cicconetti, Claudio and Javadi, Bahman and Sbarski, Peter and Taibi, Davide and Assuncao, Marcos and Gill, Sukhpal Singh and Gaire, Raj and Dustdar, Schahram},
title = {Serverless Edge Computing: Vision and Challenges},
year = {2021},
isbn = {9781450389563},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3437378.3444367},
doi = {10.1145/3437378.3444367},
abstract = {Born from a need for a pure “pay-per-use” model and highly scalable platform, the “Serverless” paradigm emerged and has the potential to become a dominant way of building cloud applications. Although it was originally designed for cloud environments, Serverless is finding its position in the Edge Computing landscape, aiming to bring computational resources closer to the data source. That is, Serverless is crossing cloud borders to assess its merits in Edge computing, whose principal partner will be the Internet of Things (IoT) applications. This move sounds promising as Serverless brings particular benefits such as eliminating always-on services causing high electricity usage, for instance. However, the community is still hesitant to uptake Serverless Edge Computing because of the cloud-driven design of current Serverless platforms, and distinctive characteristics of edge landscape and IoT applications. In this paper, we evaluate both sides to shed light on the Serverless new territory. Our in-depth analysis promotes a broad vision for bringing Serverless to the Edge Computing. It also issues major challenges for Serverless to be met before entering Edge computing.},
booktitle = {Proceedings of the 2021 Australasian Computer Science Week Multiconference},
articleno = {10},
numpages = {10},
location = {Dunedin, New Zealand},
series = {ACSW '21}
}

@article{10.1145/3555308,
author = {Kong, Linghe and Tan, Jinlin and Huang, Junqin and Chen, Guihai and Wang, Shuaitian and Jin, Xi and Zeng, Peng and Khan, Muhammad and Das, Sajal K.},
title = {Edge-computing-driven Internet of Things: A Survey},
year = {2022},
issue_date = {August 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {55},
number = {8},
issn = {0360-0300},
url = {https://doi.org/10.1145/3555308},
doi = {10.1145/3555308},
abstract = {The Internet of Things (IoT) is impacting the world’s connectivity landscape. More and more IoT devices are connected, bringing many benefits to our daily lives. However, the influx of IoT devices poses non-trivial challenges for the existing cloud-based computing paradigm. In the cloud-based architecture, a large amount of IoT data is transferred to the cloud for data management, analysis, and decision making. It could not only cause a heavy workload on the cloud but also result in unacceptable network latency, ultimately undermining the benefits of cloud-based computing. To address these challenges, researchers are looking for new computing models for the IoT. Edge computing, a new decentralized computing model, is valued by more and more researchers in academia and industry. The main idea of edge computing is placing data processing in near-edge devices instead of remote cloud servers. It is promising to build more scalable, low-latency IoT systems. Many studies have been proposed on edge computing and IoT, but a comprehensive survey of this crossover area is still lacking.In this survey, we first introduce the impact of edge computing on the development of IoT and point out why edge computing is more suitable for IoT than other computing paradigms. Then, we analyze the necessity of systematical investigation on the edge-computing-driven IoT (ECDriven-IoT) and summarize new challenges occurring in ECDriven-IoT. We categorize recent advances from bottom to top, covering six aspects of ECDriven-IoT. Finally, we conclude lessons learned and propose some challenging},
journal = {ACM Comput. Surv.},
month = {dec},
articleno = {174},
numpages = {41},
keywords = {Internet of Things, Edge computing}
}

@inproceedings{10.1145/3282308.3282342,
author = {Seitz, Andreas and Thiele, Felix and Bruegge, Bernd},
title = {Fogxy: An Architectural Pattern for Fog Computing},
year = {2018},
isbn = {9781450363877},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3282308.3282342},
doi = {10.1145/3282308.3282342},
abstract = {Fog computing is an emergent approach that tries to overcome challenges the cloud faces by introducing a fog tier in between the cloud and the edge of the network. With the advent of the cloud, computing power shifted back again to centralized locations. In past decades, we have seen an alternation between centralization and decentralization. Although the cloud is highly scalable and performant, it exhibits limitations such as real-time capabilities. Fog computing is an approach that tries to overcome these shortcomings. The implementation guidelines for fog computing system are vague to be implemented in real-world applications. Smart objects at the edge benefit from low latency responses, location awareness, and higher availability provided by fog computing. In this paper, we present Fogxy, an architectural pattern for fog computing. It serves as an implementation guidance that describes a solution to a recurring problem in a given context. Fogxy is composed of different patterns and is based on the idea of the proxy pattern. Fogxy gives an overview of the implementation of fog computing applications and takes into account the integration of cloud computing and Internet of Things (IoT) technologies.},
booktitle = {Proceedings of the 23rd European Conference on Pattern Languages of Programs},
articleno = {33},
numpages = {8},
keywords = {Real-Time, Internet of Things, Fog Computing, Edge Computing, Cloud Computing, Architectural Pattern},
location = {Irsee, Germany},
series = {EuroPLoP '18}
}

@inproceedings{10.1145/3576842.3582376,
author = {Nouma, Saif E. and Yavuz, Attila A.},
title = {Practical Cryptographic Forensic Tools for Lightweight Internet of Things and Cold Storage Systems},
year = {2023},
isbn = {9798400700378},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3576842.3582376},
doi = {10.1145/3576842.3582376},
abstract = {Internet of Things (IoT) and Storage-as-a-Service (STaaS) continuum permit cost-effective maintenance of security-sensitive information collected by IoT devices over cloud systems. It is necessary to guarantee the security of sensitive data in IoT-STaaS applications. Especially, log entries trace critical events in computer systems and play a vital role in the trustworthiness of IoT-STaaS. An ideal log protection tool must be scalable and lightweight for vast quantities of resource-limited IoT devices while permitting efficient and public verification at STaaS. However, the existing cryptographic logging schemes either incur significant computation/signature overhead to the logger or extreme storage and verification costs to the cloud. There is a critical need for a cryptographic forensic log tool that respects the efficiency requirements of the IoT-STaaS continuum. In this paper, we created novel digital signatures for logs called Optimal Signatures for secure Logging (), which are the first (to the best of our knowledge) to offer both small-constant signature and public key sizes with near-optimal signing and batch verification via various granularities. We introduce new design features such as one-time randomness management, flexible aggregation along with various optimizations to attain these seemingly conflicting properties simultaneously. Our experiments show that &nbsp;offers 50 \texttimes{} faster verification (for 235 entries) than the most compact alternative with equal signature sizes, while also being several magnitudes of more compact than its most logger efficient counterparts. These properties make &nbsp;an ideal choice for the IoT-STaaS, wherein lightweight logging and efficient batch verification of massive-size logs are vital for the IoT edge and cold storage servers, respectively.},
booktitle = {Proceedings of the 8th ACM/IEEE Conference on Internet of Things Design and Implementation},
pages = {340–353},
numpages = {14},
keywords = {secure logs, digital signatures, cold storage, Authentication},
location = {<conf-loc>, <city>San Antonio</city>, <state>TX</state>, <country>USA</country>, </conf-loc>},
series = {IoTDI '23}
}

@article{10.1145/3444692,
author = {Varghese, Blesson and Wang, Nan and Bermbach, David and Hong, Cheol-Ho and Lara, Eyal De and Shi, Weisong and Stewart, Christopher},
title = {A Survey on Edge Performance Benchmarking},
year = {2021},
issue_date = {April 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/3444692},
doi = {10.1145/3444692},
abstract = {Edge computing is the next Internet frontier that will leverage computing resources located near users, sensors, and data stores to provide more responsive services. Therefore, it is envisioned that a large-scale, geographically dispersed, and resource-rich distributed system will emerge and play a key role in the future Internet. However, given the loosely coupled nature of such complex systems, their operational conditions are expected to change significantly over time. In this context, the performance characteristics of such systems will need to be captured rapidly, which is referred to as performance benchmarking, for application deployment, resource orchestration, and adaptive decision-making. Edge performance benchmarking is a nascent research avenue that has started gaining momentum over the past five years. This article first reviews articles published over the past three decades to trace the history of performance benchmarking from tightly coupled to loosely coupled systems. It then systematically classifies previous research to identify the system under test, techniques analyzed, and benchmark runtime in edge performance benchmarking.},
journal = {ACM Comput. Surv.},
month = {apr},
articleno = {66},
numpages = {33},
keywords = {techniques analyzed, system under test, edge performance benchmarking, benchmark runtime, Edge computing}
}

@inproceedings{10.1145/3524844.3528055,
author = {Colombo, Vera and Tundo, Alessandro and Ciavotta, Michele and Mariani, Leonardo},
title = {Towards self-adaptive peer-to-peer monitoring for fog environments},
year = {2022},
isbn = {9781450393058},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3524844.3528055},
doi = {10.1145/3524844.3528055},
abstract = {Monitoring is a critical component in fog environments: it promptly provides insights about the behavior of systems, reveals Service Level Agreements (SLAs) violations, enables the autonomous orchestration of services and platforms, calls for the intervention of operators, and triggers self-healing actions.In such environments, monitoring solutions have to cope with the heterogeneity of the devices and platforms present in the Fog, the limited resources available at the edge of the network, and the high dynamism of the whole Cloud-to-Thing continuum.This paper addresses the challenge of accurately and efficiently monitoring the Fog with a self-adaptive peer-to-peer (P2P) monitoring solution that can opportunistically adjust its behavior according to the collected data exploiting a lightweight rule-based expert system.Empirical results show that adaptation can improve monitoring accuracy, while reducing network and power consumption at the cost of higher memory consumption.},
booktitle = {Proceedings of the 17th Symposium on Software Engineering for Adaptive and Self-Managing Systems},
pages = {156–166},
numpages = {11},
keywords = {self-adaptive, peer-to-peer, monitoring, fog computing},
location = {Pittsburgh, Pennsylvania},
series = {SEAMS '22}
}

@article{10.1109/TNET.2023.3262482,
author = {Ganguly, Bhargav and Hosseinalipour, Seyyedali and Kim, Kwang Taik and Brinton, Christopher G. and Aggarwal, Vaneet and Love, David J. and Chiang, Mung},
title = {Multi-Edge Server-Assisted Dynamic Federated Learning With an Optimized Floating Aggregation Point},
year = {2023},
issue_date = {Dec. 2023},
publisher = {IEEE Press},
volume = {31},
number = {6},
issn = {1063-6692},
url = {https://doi.org/10.1109/TNET.2023.3262482},
doi = {10.1109/TNET.2023.3262482},
abstract = {We propose cooperative edge-assisted dynamic federated learning (&lt;monospace&gt;CE-FL&lt;/monospace&gt;). &lt;monospace&gt;CE-FL&lt;/monospace&gt; introduces a distributed machine learning (ML) architecture, where data collection is carried out at the end devices, while the model training is conducted cooperatively at the end devices and the edge servers, enabled via data offloading from the end devices to the edge servers through base stations. &lt;monospace&gt;CE-FL&lt;/monospace&gt; also introduces floating aggregation point, where the local models generated at the devices and the servers are aggregated at an edge server, which varies from one model training round to another to cope with the network evolution in terms of data distribution and users’ mobility. &lt;monospace&gt;CE-FL&lt;/monospace&gt; considers the heterogeneity of network elements in terms of communication/computation models and the proximity to one another. &lt;monospace&gt;CE-FL&lt;/monospace&gt; further presumes a dynamic environment with online variation of data at the network devices which causes a drift at the ML model performance. We model the processes taken during &lt;monospace&gt;CE-FL&lt;/monospace&gt;, and conduct analytical convergence analysis of its ML model training. We then formulate network-aware &lt;monospace&gt;CE-FL&lt;/monospace&gt; which aims to adaptively optimize all the network elements via tuning their contribution to the learning process, which turns out to be a non-convex mixed integer problem. Motivated by the large scale of the system, we propose a distributed optimization solver to break down the computation of the solution across the network elements. We finally demonstrate the effectiveness of our framework with the data collected from a real-world testbed.},
journal = {IEEE/ACM Trans. Netw.},
month = {apr},
pages = {2682–2697},
numpages = {16}
}

@proceedings{10.1145/3589806,
title = {ACM REP '23: Proceedings of the 2023 ACM Conference on Reproducibility and Replicability},
year = {2023},
isbn = {9798400701764},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Santa Cruz, CA, USA}
}

@proceedings{10.1145/3549037,
title = {SEA4DQ 2022: Proceedings of the 2nd International Workshop on Software Engineering and AI for Data Quality in Cyber-Physical Systems/Internet of Things},
year = {2022},
isbn = {9781450394598},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Cyber-physical systems (CPS)/Internet of Things (IoT) are omnipresent in many industrial sectors and application domains in which the quality of the data acquired and used for decision support is a common factor. Data quality can deteriorate due to factors such as sensor faults and failures due to operating in harsh and uncertain environments. How can software engineering and artificial intelligence (AI) help manage and tame data quality issues in CPS/IoT? In this workshop, we aim to answer this question.},
location = {Singapore, Singapore}
}

@article{10.1145/3429252,
author = {Bellavista, Paolo and Foschini, Luca and Mora, Alessio},
title = {Decentralised Learning in Federated Deployment Environments: A System-Level Survey},
year = {2021},
issue_date = {January 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/3429252},
doi = {10.1145/3429252},
abstract = {Decentralised learning is attracting more and more interest because it embodies the principles of data minimisation and focused data collection, while favouring the transparency of purpose specification (i.e., the objective for which a model is built). Cloud-centric-only processing and deep learning are no longer strict necessities to train high-fidelity models; edge devices can actively participate in the decentralised learning process by exchanging meta-level information in place of raw data, thus paving the way for better privacy guarantees. In addition, these new possibilities can relieve the network backbone from unnecessary data transfer and allow it to meet strict low-latency requirements by leveraging on-device model inference. This survey provides a detailed and up-to-date overview of the most recent contributions available in the state-of-the-art decentralised learning literature. In particular, it originally provides the reader audience with a clear presentation of the peculiarities of federated settings, with a novel taxonomy of decentralised learning approaches, and with a detailed description of the most relevant and specific system-level contributions of the surveyed solutions for privacy, communication efficiency, non-IIDness, device heterogeneity, and poisoning defense.},
journal = {ACM Comput. Surv.},
month = {feb},
articleno = {15},
numpages = {38},
keywords = {privacy, poisoning defense, federated deployment, communication efficiency, Decentralised learning}
}

@proceedings{10.1145/3565476,
title = {ViSNext '22: Proceedings of the 2nd International Workshop on Design, Deployment, and Evaluation of Network-Assisted Video Streaming},
year = {2022},
isbn = {9781450399364},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {In recent years, we have witnessed phenomenal growth in live video traffic over the Internet, accelerated by the rise of novel video streaming technologies, advancements in networking paradigms, and our ability to generate, process, and display videos on heterogeneous devices. Regarding the existing constraints and limitations in different components on the video delivery path from the origin server to clients, the network plays an essential role in boosting the perceived Quality of Experience (QoE) by clients. In other words, the network can enable us to optimize serving videos in the application layer by providing helpful information ranging from the status of clients' requests to the capacity of links. Therefore, the network can assist players or other entities (e.g., network edge servers) to make better decisions and improve the Quality of Experience (QoE). However, selecting, collecting, analyzing, and leveraging network information to ensure the highest user quality of experience poses many fundamental challenges that attract researchers from both academia and industry. The ViSNext workshop aims to bring together researchers and developers working on all aspects of video streaming, in particular network-assisted concepts backed up by experimental evidence.},
location = {Rome, Italy}
}

@article{10.1145/3419634,
author = {Bansal, Maggi and Chana, Inderveer and Clarke, Siobh\'{a}n},
title = {A Survey on IoT Big Data: Current Status, 13 V’s Challenges, and Future Directions},
year = {2020},
issue_date = {November 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {53},
number = {6},
issn = {0360-0300},
url = {https://doi.org/10.1145/3419634},
doi = {10.1145/3419634},
abstract = {Driven by the core technologies, i.e., sensor-based autonomous data acquisition and the cloud-based big data analysis, IoT automates the actuation of data-driven intelligent actions on the connected objects. This automation enables numerous useful real-life use-cases, such as smart transport, smart living, smart cities, and so on. However, recent industry surveys reflect that data-related challenges are responsible for slower growth of IoT in recent years. For this reason, this article presents a systematic and comprehensive survey on IoT Big Data (IoTBD) with the aim to identify the uncharted challenges for IoTBD. This article analyzes the state-of-the-art academic works in IoT and big data management across various domains and proposes a taxonomy for IoTBD management. Then, the survey explores the IoT portfolio of major cloud vendors and provides a classification of vendor services for the integration of IoT and IoTBD on their cloud platforms. After that, the survey identifies the IoTBD challenges in terms of 13 V’s challenges and envisions IoTBD as “Big Data 2.0.” Then the survey provides comprehensive analysis of recent works that address IoTBD challenges by highlighting their strengths and weaknesses to assess the recent trends and future research directions. Finally, the survey concludes with discussion on open research issues for IoTBD.},
journal = {ACM Comput. Surv.},
month = {dec},
articleno = {131},
numpages = {59},
keywords = {cloud computing in IoT, cloud IoT services, big data 2.0, V’s challenges for IoT big data, IoT big data survey, IoT big data}
}

@proceedings{10.1145/3579142,
title = {BiDEDE '23: Proceedings of the International Workshop on Big Data in Emergent Distributed Environments},
year = {2023},
isbn = {9798400700934},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Seattle, WA, USA}
}

@proceedings{10.1145/3526073,
title = {SE4RAI '22: Proceedings of the 1st Workshop on Software Engineering for Responsible AI},
year = {2022},
isbn = {9781450393195},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {SE4RAI'22 is a forum where researchers, innovators, and leading professionals from both academia and industry can discuss the state and future of software engineering for responsible AI. SE4RAI'22 also aims to bring together researchers and practitioners from diverse disciplines such as software engineering, AI and social science to help tackle the end-to-end engineering challenges in developing AI systems responsibly. We hope that SE4RAI'22 will actively encourage a growing number of researchers to join this area.},
location = {Pittsburgh, Pennsylvania}
}

@proceedings{10.1145/3524458,
title = {GoodIT '22: Proceedings of the 2022 ACM Conference on Information Technology for Social Good},
year = {2022},
isbn = {9781450392846},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Limassol, Cyprus}
}

@proceedings{10.1145/3576914,
title = {CPS-IoT Week '23: Proceedings of Cyber-Physical Systems and Internet of Things Week 2023},
year = {2023},
isbn = {9798400700491},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {San Antonio, TX, USA}
}

@proceedings{10.1145/3590837,
title = {ICIMMI '22: Proceedings of the 4th International Conference on Information Management &amp; Machine Intelligence},
year = {2022},
isbn = {9781450399937},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Jaipur, India}
}

@proceedings{10.1145/3583678,
title = {DEBS '23: Proceedings of the 17th ACM International Conference on Distributed and Event-based Systems},
year = {2023},
isbn = {9798400701221},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {DEBS 2023 is the seventeenth in a series that spans more than 20 years of history, with 16 past editions as a conference and five editions as a workshop co-located with major conferences.The objectives of DEBS have been to provide a forum dedicated to the dissemination of original research, the discussion of practical insights, and the reporting of experiences relevant to distributed systems and event-based computing. The conference provides a forum for academia and industry to exchange ideas through its tutorials, research papers, and the grand challenge. Recently, the ACM International Conference on Distributed and Event-Based Systems, including DEBS 2022, has become the premier venue for cutting-edge research in the integration of distributed and event-based systems in relevant domains such as Big Data, AI, ML, IoT, and Blockchain.},
location = {Neuchatel, Switzerland}
}

@proceedings{10.1145/3528535,
title = {Middleware '22: Proceedings of the 23rd ACM/IFIP International Middleware Conference},
year = {2022},
isbn = {9781450393409},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {<conf-loc>, <city>Quebec</city>, <state>QC</state>, <country>Canada</country>, </conf-loc>}
}

@proceedings{10.1145/3583120,
title = {IPSN '23: Proceedings of the 22nd International Conference on Information Processing in Sensor Networks},
year = {2023},
isbn = {9798400701184},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {San Antonio, TX, USA}
}

@proceedings{10.1145/3600160,
title = {ARES '23: Proceedings of the 18th International Conference on Availability, Reliability and Security},
year = {2023},
isbn = {9798400707728},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {<conf-loc>, <city>Benevento</city>, <country>Italy</country>, </conf-loc>}
}

@proceedings{10.1145/3576842,
title = {IoTDI '23: Proceedings of the 8th ACM/IEEE Conference on Internet of Things Design and Implementation},
year = {2023},
isbn = {9798400700378},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {<conf-loc>, <city>San Antonio</city>, <state>TX</state>, <country>USA</country>, </conf-loc>}
}

@proceedings{10.1145/3582515,
title = {GoodIT '23: Proceedings of the 2023 ACM Conference on Information Technology for Social Good},
year = {2023},
isbn = {9798400701160},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Lisbon, Portugal}
}

@proceedings{10.1145/3555776,
title = {SAC '23: Proceedings of the 38th ACM/SIGAPP Symposium on Applied Computing},
year = {2023},
isbn = {9781450395175},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Tallinn, Estonia}
}

@proceedings{10.1145/3560905,
title = {SenSys '22: Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
year = {2022},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to ACM SenSys 2022, the 20th ACM Conference on Embedded Networked Sensor Systems, the premier computer systems conference focused on networked sensing systems and applications.},
location = {<conf-loc>, <city>Boston</city>, <state>Massachusetts</state>, </conf-loc>}
}

