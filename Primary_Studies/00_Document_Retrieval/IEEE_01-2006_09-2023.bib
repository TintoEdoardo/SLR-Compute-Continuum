@ARTICLE{10266810,
  author={Durán, Amador and Fernández, Pablo and García, José María and Dustdar, Schahram},
  journal={IEEE Internet Computing}, 
  title={FIDES: A Proposal for Federated Accountability in the Compute Continuum}, 
  year={2023},
  volume={27},
  number={5},
  pages={33-42},
  abstract={In this visionary article, we present the concept of federated accountability, an innovative approach that distributes accountability-related computation and data across the compute continuum. To demonstrate the feasibility and versatility of our approach, we developed a prototype using blockchain technology that serves as a tangible illustration of how federated accountability can be applied across various domains.},
  keywords={Privacy;Computational modeling;Biological system modeling;Prototypes;Blockchains;Reliability;Federated learning;Distributed computing},
  doi={10.1109/MIC.2023.3301585},
  ISSN={1941-0131},
  month={Sep.},}@INPROCEEDINGS{10257300,
  author={Marozzo, Fabrizio and Orsino, Alessio and Talia, Domenico and Trunfio, Paolo},
  booktitle={2023 19th International Conference on Distributed Computing in Smart Systems and the Internet of Things (DCOSS-IoT)}, 
  title={Scaling Machine Learning at the Edge-Cloud: A Distributed Computing Perspective}, 
  year={2023},
  volume={},
  number={},
  pages={761-767},
  abstract={The widespread diffusion of Internet of Things (IoT) devices has led to an exponential growth in the volume of data generated at the edge of the network. With the rapid spread of machine learning (ML)-based applications, performing compute and resource-intensive learning tasks at the edge has become a critical issue, resulting in the need for scalable and efficient solutions that can overcome the resource constraints of edge devices. This paper analyzes the problem of scaling ML applications and algorithms at the edge-cloud continuum from a distributed computing perspective. In particular, we first highlight the limitations of traditional distributed architectures (e.g., clusters, clouds, and HPC systems) when running ML applications that use data generated at the edge. Next, we discuss how to enable traditional ML algorithms combining the benefits of edge computing, such as low-latency processing and privacy preservation of personal user data, with those of cloud computing, such as virtually unlimited computational and storage capabilities. Our analysis provides insights into how properly separated parts of a ML application can be deployed across edge-cloud architectures in order to optimize its execution. More-over, examples of ML applications and algorithms appropriately adapted for the edge-cloud continuum are shown.},
  keywords={Training;Cloud computing;Machine learning algorithms;Distributed databases;Clustering algorithms;Machine learning;Computer architecture;Machine learning;distributed machine learning;Internet of Things;edge computing;cloud computing;edge-cloud continuum},
  doi={10.1109/DCOSS-IoT58021.2023.00119},
  ISSN={2325-2944},
  month={June},}@INPROCEEDINGS{10254968,
  author={Marchese, Angelo and Tomarchio, Orazio},
  booktitle={2023 IEEE 16th International Conference on Cloud Computing (CLOUD)}, 
  title={Application and Infrastructure-Aware Orchestration in the Cloud-to-Edge Continuum}, 
  year={2023},
  volume={},
  number={},
  pages={262-271},
  abstract={Defining a scheduling and orchestration strategy for modern distributed microservices-based applications is a complex problem to deal with, especially if they are deployed on geo-distributed Cloud-to-Edge environments. Kubernetes is today the de-facto standard for container orchestration on Cloud data centers. However, its static container scheduling strategy is not suitable for the placement of complex and distributed microservices-based applications on Edge environments. Current infrastructure network conditions and resource availability neither run time application state are taken into account when scheduling microservices. To deal with these limitations in this work we present an extension of the Kubernetes platform in order to implement an effective application and infrastructure-aware container scheduling and orchestration strategy. In particular, we propose an extension of the default Kubernetes scheduler that considers application and infrastructure telemetry data when taking scheduling decisions. Furthermore, a descheduler component is also proposed that continuously tunes the application placement based on the ever changing application and infrastructure states. An evaluation of the proposed approach is presented by comparing it with the default Kubernetes scheduling strategy.},
  keywords={Cloud computing;Data centers;Microservice architectures;Containers;Dynamic scheduling;Time factors;Telemetry;Cloud-to-Edge continuum;Containers technology;Kubernetes scheduler;Kubernetes descheduler;Cluster Monitoring;Application Monitoring},
  doi={10.1109/CLOUD60044.2023.00037},
  ISSN={2159-6190},
  month={July},}@INPROCEEDINGS{10255001,
  author={Theodoropoulos, Theodoros and Makris, Antonios and Psomakelis, Evangelos and Carlini, Emanuele and Mordacchini, Matteo and Dazzi, Patrizio and Tserpes, Konstantinos},
  booktitle={2023 IEEE 16th International Conference on Cloud Computing (CLOUD)}, 
  title={GNOSIS: Proactive Image Placement Using Graph Neural Networks & Deep Reinforcement Learning}, 
  year={2023},
  volume={},
  number={},
  pages={120-128},
  abstract={The transition from Cloud Computing to a Cloud-Edge continuum brings many new exciting possibilities for interactive and data-intensive Next Generation applications, but as many challenges. Approaches and solutions that successfully worked in the Cloud space now need to be rethought for the Edge's distributed, heterogeneous and dynamic ecosystem. The placement of application images needs to be proactively devised to reduce as much as possible the image transfer time and comply with the dynamic nature and strict requirements of the applications. To this end, this paper proposes an approach based on the combination of Graph Neural Networks and actor-critic Reinforcement Learning. The approach is analyzed empirically and compared with a state-of-the-art solution. The results show that the proposed approach exhibits a larger execution times but generally better results in terms of application image placement.},
  keywords={Greedy algorithms;Cloud computing;Network topology;Image edge detection;Metaheuristics;Reinforcement learning;Integer linear programming;Edge Computing;Cloud Computing;Component Placement;Proactive Image Placement;Graph Neural Networks},
  doi={10.1109/CLOUD60044.2023.00022},
  ISSN={2159-6190},
  month={July},}@INPROCEEDINGS{10255019,
  author={Alabbas, Areej and Kaushal, Ashish and Almurshed, Osama and Rana, Omer and Auluck, Nitin and Perera, Charith},
  booktitle={2023 IEEE 16th International Conference on Cloud Computing (CLOUD)}, 
  title={Performance Analysis of Apache OpenWhisk Across the Edge-Cloud Continuum}, 
  year={2023},
  volume={},
  number={},
  pages={401-407},
  abstract={Serverless computing offers opportunities for auto-scaling, a pay-for-use cost model, quicker deployment and faster updates to support computing services. Apache OpenWhisk is one such open-source, distributed serverless platform that can be used to execute user functions in a stateless manner. We conduct a performance analysis of OpenWhisk on an edge-cloud continuum, using a function chain of video analysis applications. We consider a combination of Raspberry Pi and cloud nodes to deploy OpenWhisk, modifying a number of parameters, such as maximum memory limit and runtime, to investigate application behaviours. The five main factors considered are: cold and warm activation, memory and input size, CPU architecture, runtime packages used, and concurrent invocations. The results have been evaluated using initialization, and execution time, minimum memory requirement, inference time and accuracy.},
  keywords={Cloud computing;Runtime;Costs;Economic indicators;Computational modeling;Memory management;Memory architecture;edge-cloud computing;serverless;function as a service;OpenWhisk;performance evaluation},
  doi={10.1109/CLOUD60044.2023.00054},
  ISSN={2159-6190},
  month={July},}@INPROCEEDINGS{10254955,
  author={Anisetti, Marco and Berto, Filippo and Bondaruc, Ruslan},
  booktitle={2023 IEEE 16th International Conference on Cloud Computing (CLOUD)}, 
  title={QoS-Aware Deployment of Service Compositions in 5G-Empowered Edge-Cloud Continuum}, 
  year={2023},
  volume={},
  number={},
  pages={471-478},
  abstract={Nowadays, modern service compositions are increasingly adopted in critical scenarios where advanced Quality of Services (QoS) such as low latency, security, and privacy are fundamental. The landing platforms for the deployment of such compositions are progressively becoming capable to offer capabil-ities that support such advanced QoS requests (e.g., low latency via 5G network slice) spanning the Edge-Cloud Continuum. Actual deployment solutions focus mainly on resource allocation (i.e., CPU, memory, and storage), falling short of addressing advanced QoS and unleashing the true potential of the Edge-Cloud Continuum. In this paper, we present an automatic QoS-aware deployment solution for composed services in the Edge-Cloud Continuum. It compares QoS requests on the service composition with the capabilities of a given continuum in order to find, generate and execute suitable deployment recipes. Our preliminary experimental evaluation demonstrates the feasibility of our solution in a realistic scenario.},
  keywords={Cloud computing;Privacy;Network topology;5G mobile communication;Quality of service;Security;Resource management;Service Composition;Service Deployment;Non-Functional properties;5G MEC;Edge-Cloud Continuum},
  doi={10.1109/CLOUD60044.2023.00063},
  ISSN={2159-6190},
  month={July},}@INPROCEEDINGS{10254827,
  author={Withana, Sachith and Plale, Beth},
  booktitle={2023 IEEE 19th International Conference on e-Science (e-Science)}, 
  title={CKN: An Edge AI Distributed Framework}, 
  year={2023},
  volume={},
  number={},
  pages={1-10},
  abstract={The edge-cloud-HPC continuum is transformative for AI processing at the edge. With greater availability of both edge and cloud resources, AI inference, training, and optimization can be distributed across the continuum. We target edge-cloud in particular where the workload at the Edge server can exhibit discrete changes, for instance, when motion is detected. We optimize for Quality of Experience (QoE) and utilize historical data from the Edge, graphs, and Deep Learning to infer the next action to take. Using a large synthetic workload and publicly profiled inference models, our results show that predictive guidance outperforms random choice or best guess in optimal QoE of the edge-cloud continuum.},
  keywords={Training;Deep learning;Image edge detection;Predictive models;Quality of experience;Servers;Artificial intelligence;Edge-cloud continuum;provenance;streaming;Edge AI;Knowledge Graphs},
  doi={10.1109/e-Science58273.2023.10254827},
  ISSN={2325-3703},
  month={Oct},}@INPROCEEDINGS{10254882,
  author={Sanchez-Gallegos, Dante D. and Carrizales-Espinoza, Diana and Gonzalez-Compean, José L. and Carretero, Jesus},
  booktitle={2023 IEEE 19th International Conference on e-Science (e-Science)}, 
  title={eScience Serverless Data Storage Services in the Edge-Fog-Cloud Continuum}, 
  year={2023},
  volume={},
  number={},
  pages={1-4},
  abstract={MeshStore, a fault-tolerant serverless storage model for edge-fog-cloud continuum systems, enables organizations to integrate distributed heterogeneous storage resources into a single unified storage service for the sharing of data through serverless functions deployed on edge-fog-cloud environments to create continuum dataflows. This unified service automatically and transparently manages the input/output data of serverless functions by coupling storage structures, including load-balancing and data allocation/location algorithms. Organizations also can add non-functional requirement properties (e.g., either reliability or security) to the storage structures when managing sensitive data.},
  keywords={Computational modeling;Source coding;Transportation;Organizations;Data models;Software;Software reliability;eScience;storage services;dataflows;serverless;meshes},
  doi={10.1109/e-Science58273.2023.10254882},
  ISSN={2325-3703},
  month={Oct},}@INPROCEEDINGS{10254822,
  author={Souza, Renan and Skluzacek, Tyler J. and Wilkinson, Sean R. and Ziatdinov, Maxim and da Silva, Rafael Ferreira},
  booktitle={2023 IEEE 19th International Conference on e-Science (e-Science)}, 
  title={Towards Lightweight Data Integration Using Multi-Workflow Provenance and Data Observability}, 
  year={2023},
  volume={},
  number={},
  pages={1-10},
  abstract={Modern large-scale scientific discovery requires multidisciplinary collaboration across diverse computing facilities, including High Performance Computing (HPC) machines and the Edge-to-Cloud continuum. Integrated data analysis plays a crucial role in scientific discovery, especially in the current AI era, by enabling Responsible AI development, FAIR, Reproducibility, and User Steering. However, the heterogeneous nature of science poses challenges such as dealing with multiple supporting tools, cross-facility environments, and efficient HPC execution. Building on data observability, adapter system design, and provenance, we propose MIDA: an approach for lightweight runtime Multi-workflow Integrated Data Analysis. MIDA defines data observability strategies and adaptability methods for various parallel systems and machine learning tools. With observability, it intercepts the dataflows in the background without requiring instrumentation while integrating domain, provenance, and telemetry data at runtime into a unified database ready for user steering queries. We conduct experiments showing end-to-end multi-workflow analysis integrating data from Dask and MLFlow in a real distributed deep learning use case for materials science that runs on multiple environments with up to 276 GPUs in parallel. We show near-zero overhead running up to 100,000 tasks on 1,680 CPU cores on the Summit supercomputer.},
  keywords={Deep learning;Materials science and technology;Runtime;Data analysis;Buildings;Data integration;Reproducibility of results;Workflows;Data Integration;Data Observability;Adaptability;Cross-facility;Machine Learning;Deep Learning;Lineage;Provenance;Responsible AI;Explainability;Dask},
  doi={10.1109/e-Science58273.2023.10254822},
  ISSN={2325-3703},
  month={Oct},}@INPROCEEDINGS{10254763,
  author={Patel, Yashwant Singh and Townend, Paul and Östberg, Per-Olov},
  booktitle={2023 IEEE International Conference on Service-Oriented System Engineering (SOSE)}, 
  title={Formal Models for the Energy-Aware Cloud-Edge Computing Continuum: Analysis and Challenges}, 
  year={2023},
  volume={},
  number={},
  pages={48-59},
  abstract={Cloud infrastructures are rapidly evolving from centralised systems to geographically distributed federations of edge devices, fog nodes, and clouds. These federations (often referred to as the Cloud-Edge Continuum) are the foundation upon which most modern digital systems depend, and consume enormous amounts of energy. This consumption is becoming a critical issue as society's energy challenges grow, and is a great concern for power grids which must balance the needs of clouds against other users. The Continuum is highly dynamic, mobile, and complex; new methods to improve energy efficiency must be based on formal scientific models that identify and take into account a huge range of heterogeneous components, interactions, stochastic properties, and (potentially contradictory) service-level agreements and stakeholder objectives. Currently, few formal models of federated Cloud-Edge systems exist - and none adequately represent and integrate energy considerations (e.g. multiple providers, renewable energy sources, pricing, and the need to balance consumption over large-areas with other non-Cloud consumers, etc.). This paper conducts a systematic analysis of current approaches to modelling Cloud, Cloud-Edge, and federated Continuum systems with an emphasis on the integration of energy considerations. We identify key omissions in the literature, and propose an initial high-level architecture and approach to begin addressing these - with the ultimate goal to develop a set of integrated models that include data centres, edge devices, fog nodes, energy providers, software workloads, end users, and stakeholder requirements and objectives. We conclude by highlighting the key research challenges that must be addressed to enable meaningful energy-aware Cloud-Edge Continuum modelling and simulation.},
  keywords={Analytical models;Renewable energy sources;Systematics;Computational modeling;Stochastic processes;Pricing;Computer architecture;Continuum;modelling;green energy;brown energy;cloud computing;edge computing;fog computing},
  doi={10.1109/SOSE58276.2023.00012},
  ISSN={2642-6587},
  month={July},}@INPROCEEDINGS{10254740,
  author={Pujol, Victor Casamayor and Morichetta, Andrea and Nastic, Stefan},
  booktitle={2023 IEEE International Conference on Service-Oriented System Engineering (SOSE)}, 
  title={Intelligent Sampling: A Novel Approach to Optimize Workload Scheduling in Large-Scale Heterogeneous Computing Continuum}, 
  year={2023},
  volume={},
  number={},
  pages={140-149},
  abstract={Scheduling workloads on large-scale infrastructures, such as in the Edge-Cloud continuum is a challenging task. Usually, the scheduling algorithm considers only a limited sample of the infrastructure nodes, typically obtained through random sampling. The sampling reduces the number of nodes, which need to be evaluated in the scheduling pipeline, making the scheduling process more saleable. Unfortunately, current sampling approaches become largely inefficient when the infrastructure is heterogeneous and specific, scarce node characteristics are required to successfully execute a workload. Computing continuum infrastructures are heterogeneous, hence, we need to re-think the sampling process to keep it viable at scale while also being able to identify and leverage the heterogeneity of the Edge-Cloud continuum resources. In this article, we present Intelligent Sampling - a novel technique for improving sampling in large-scale and heterogeneous infrastructures. We develop a model for any heterogeneous infrastructure. Based on this model, we provide a method to sample the infrastructure nodes more accurately, considering the specific task at hand. Finally, we leverage the Alibaba PAI dataset to show that our approach is 2.5x times more accurate compared with other state-of-the-art sampling mechanisms while retaining comparable performance and scalability.},
  keywords={Service-oriented systems engineering;Scheduling algorithms;Computational modeling;Scalability;Pipelines;Heterogeneous networks;Complexity theory;Computing continuum;Intelligent sampling;Workloads scheduling;Heterogeneous infrastructure model},
  doi={10.1109/SOSE58276.2023.00024},
  ISSN={2642-6587},
  month={July},}@INPROCEEDINGS{10238564,
  author={Vicenzi, Julio Costella and Korol, Guilherme and Jordan, Michael G. and Morais, Wagner Ourique de and Ali, Hazem and Freitas, Edison Pignaton De and Rutzig, Mateus Beck and Beck, Antonio Carlos Schneider},
  booktitle={2023 IEEE Computer Society Annual Symposium on VLSI (ISVLSI)}, 
  title={Dynamic Offloading for Improved Performance and Energy Efficiency in Heterogeneous IoT-Edge-Cloud Continuum}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={While machine learning applications in IoT devices are getting more widespread, the computational and power limitations of these devices pose a great challenge. To handle this increasing computational burden, edge, and cloud solutions emerge as a means to offload computation to more powerful devices. However, the unstable nature of network connections constantly changes the communication costs, making the offload process (i.e., when and where to transfer data) a dynamic trade-off. In this work, we propose DECOS: a framework to automatically select at run-time the best offloading solution with minimum latency based on the computational capabilities of devices and network status at a given moment. We use heterogeneous devices for edge and Cloud nodes to evaluate the framework’s performance using MobileNetV1 CNN and network traffic data from a real-world 4G bandwidth dataset. DECOS effectively selects the best processing node to maintain the minimum possible latency, reducing it up to 29% compared to Cloud-exclusive processing while reducing the energy consumption by 1.9$\times$ compared to IoT-exclusive execution.},
  keywords={Performance evaluation;Runtime;Neural networks;Graphics processing units;Telecommunication traffic;Machine learning;Very large scale integration;Neural Networks;IoT;Cloud;Edge;Offloading},
  doi={10.1109/ISVLSI59464.2023.10238564},
  ISSN={2159-3477},
  month={June},}@INPROCEEDINGS{10234242,
  author={Droob, Alexander and Morratz, Daniel and Jakobsen, Frederik Langkilde and Carstensen, Jacob and Mathiesen, Magnus and Bohnstedt, Rune and Albano, Michele and Moreschini, Sergio and Taibi, Davide},
  booktitle={2023 IEEE International Conference on Edge Computing and Communications (EDGE)}, 
  title={Fault Tolerant Horizontal Computation Offloading}, 
  year={2023},
  volume={},
  number={},
  pages={177-182},
  abstract={The broad development and usage of edge devices has highlighted the importance of creating resilient and computationally advanced edge-to-cloud continuum environments. When working with edge devices these desiderata are usually achieved through replication and offloading. This paper reports on the design and implementation of a fault-tolerant service that enables the offloading of jobs from devices with limited computational power. We propose a solution that allows users to upload jobs through a web service, which will be executed on edge nodes within the system. The solution is designed to be fault tolerant and scalable, with no single point of failure as well as the ability to accommodate growth, if the service is expanded. The use of Docker checkpointing on the worker machines ensures that jobs can be resumed in the event of a fault. We provide a mathematical approach to optimize the number of checkpoints that are created along a computation, given that we can forecast the time needed to execute a job. We present experiments that indicate in which scenarios checkpointing benefits job execution. Our experiments shows the benefits of using checkpointing and restore when the completion jobs’ time rises compared with the forecast fault rate.},
  keywords={Checkpointing;Performance evaluation;Fault tolerance;Time-frequency analysis;Web services;Fault tolerant systems;Resumes;checkpointing;edge nodes;workers;orchestration;replication;totally ordered multicast},
  doi={10.1109/EDGE60047.2023.00036},
  ISSN={2767-9918},
  month={July},}@INPROCEEDINGS{10234252,
  author={Pautasso, Cesare},
  booktitle={2023 IEEE International Conference on Edge Computing and Communications (EDGE)}, 
  title={A Brief History of Liquid Software}, 
  year={2023},
  volume={},
  number={},
  pages={354-363},
  abstract={The concept of liquid software, i.e., software with flexible deployment, over the past two decades has appeared in the fields of edge computing, Internet of Things (IoT), Human-Computer Interaction, DevOps and Web engineering. In this paper, we survey, compare, and provide a comprehensive definition of liquid software by analyzing how the metaphor has been used in existing literature and identifying gaps and inconsistencies in the current vs. past understanding of the concept. Overall, liquid software can be seamlessly deployed and redeployed within a dynamic and distributed runtime environment in response to changes applied to the set of available devices and to the software itself. Liquid software has been introduced in the context of active networks and intelligent environments, it has been applied to describe the user interaction with multi and cross-device user interfaces, it has found a promising foundation in Web technology, continuous software delivery pipelines, as well as isomorphic software architectures running across the IoT, edge and Cloud continuum.},
  keywords={Surveys;Runtime environment;Privacy;Liquids;Software architecture;Software;Internet of Things;Liquid Software;Software Deployment;Isomorphic Software Architecture;Continuum;Liquid User Experience;Multi-Device User Interface;Cross-Device User Interface},
  doi={10.1109/EDGE60047.2023.00058},
  ISSN={2767-9918},
  month={July},}@INPROCEEDINGS{10234326,
  author={Townend, Paul and Martí, Alberto P. and De La Iglesia, Idoia and Matskanis, Nikolaos and Timoudas, Thomas Ohlson and Hallmann, Torsten and Lalaguna, Antonio and Swat, Kaja and Renzi, Francesco and Bocheński, Dominik and Mancini, Marco and Bhuyan, Monowar and González-Hierro, Marco and Dupont, Sébastien and Kristiansson, Johan and Montero, Rubén S. and Elmroth, Erik and Valdés, Iván and Massonet, Philippe and Olsson, Daniel and Llorente, Ignacio M. and Östberg, Per-Olov and Abdou, Michael},
  booktitle={2023 IEEE International Conference on Edge Computing and Communications (EDGE)}, 
  title={COGNIT: Challenges and Vision for a Serverless and Multi-Provider Cognitive Cloud-Edge Continuum}, 
  year={2023},
  volume={},
  number={},
  pages={12-22},
  abstract={Use of the serverless paradigm in cloud application development is growing rapidly, primarily driven by its promise to free developers from the responsibility of provisioning, operating, and scaling the underlying infrastructure. However, modern cloud-edge infrastructures are characterized by large numbers of disparate providers, constrained resource devices, platform heterogeneity, infrastructural dynamicity, and the need to orchestrate geographically distributed nodes and devices over public networks. This presents significant management complexity that must be addressed if serverless technologies are to be used in production systems. This position paper introduces COGNIT, a major new European initiative aiming to integrate AI technology into cloud-edge management systems to create a Cognitive Cloud reference framework and associated tools for serverless computing at the edge. COGNIT aims to: 1) support an innovative new serverless paradigm for edge application management and enhanced digital sovereignty for users and developers; 2) enable on-demand deployment of large-scale, highly distributed and self-adaptive serverless environments using existing cloud resources; 3) optimize data placement according to changes in energy efficiency heuristics and application demands and behavior; 4) enable secure and trusted execution of serverless runtimes. We identify and discuss seven research challenges related to the integration of serverless technologies with multi-provider Edge infrastructures and present our vision for how these challenges can be solved. We introduce a high-level view of our reference architecture for serverless cloud-edge continuum systems, and detail four motivating real-world use cases that will be used for validation, drawing from domains within Smart Cities, Agriculture and Environment, Energy, and Cybersecurity.},
  keywords={Adaptation models;Smart cities;Biological system modeling;Computational modeling;Europe;Serverless computing;Distributed databases;serverless;FaaS;edge computing;resource management;multi-provider;cognitive cloud;open source},
  doi={10.1109/EDGE60047.2023.00015},
  ISSN={2767-9918},
  month={July},}@INPROCEEDINGS{10234305,
  author={Furutanpey, Alireza and Barzen, Johanna and Bechtold, Marvin and Dustdar, Schahram and Leymann, Frank and Raith, Philipp and Truger, Felix},
  booktitle={2023 IEEE International Conference on Quantum Software (QSW)}, 
  title={Architectural Vision for Quantum Computing in the Edge-Cloud Continuum}, 
  year={2023},
  volume={},
  number={},
  pages={88-103},
  abstract={Quantum processing units (QPUs) are currently exclusively available from cloud vendors. However, with recent advancements, hosting QPUs will soon be possible everywhere. Existing work has yet to draw from research in edge computing to explore systems exploiting mobile QPUs, or how hybrid applications can benefit from distributed heterogeneous resources. Hence, this work presents an architecture for Quantum Computing in the edge-cloud continuum. We discuss the necessity, challenges, and solution approaches for extending existing work on classical edge computing to integrate QPUs. We describe how warm-starting allows defining workflows that exploit the hierarchical resources spread across the continuum. Then, we introduce a distributed inference engine with hybrid classical-quantum neural networks (QNNs) to aid system designers in accommodating applications with complex requirements that incur the highest degree of heterogeneity. We propose solutions focusing on classical layer partitioning and quantum circuit cutting to demonstrate the potential of utilizing classical and quantum computation across the continuum. To evaluate the importance and feasibility of our vision, we provide a proof of concept that exemplifies how extending a classical partition method to integrate quantum circuits can improve the solution quality. Specifically, we implement a split neural network with optional hybrid QNN predictors. Our results show that extending classical methods with QNNs is viable and promising for future work.},
  keywords={Neural networks;Focusing;Computer architecture;Software;Quantum circuit;Task analysis;Artificial intelligence;Quantum Computing;Edge Computing;Compute Continuum;Split Computing;Circuit Cutting;Task Partitioning;DNN Partitioning;Classical-Quantum Hybrid Machine Learning;Quantum Neural Networks;Warm-Starting},
  doi={10.1109/QSW59989.2023.00021},
  ISSN={},
  month={July},}@INPROCEEDINGS{10217920,
  author={Sicari, Christian and Catalfamo, Alessio and Carnevale, Lorenzo and Galletta, Antonino and Balouek-Thomert, Daniel and Parashar, Manish and Villari, Massimo},
  booktitle={2023 IEEE Symposium on Computers and Communications (ISCC)}, 
  title={TEMA: Event Driven Serverless Workflows Platform for Natural Disaster Management}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={TEMA project is a Horizon Europe funded project that aims at addressing Natural Disaster Management by the use of sophisticated Cloud-Edge Continuum infrastructures by means of data analysis algorithms wrapped in Serverless functions deployed on a distributed infrastructure according to a Federated Learning scheduler that constantly monitors the infrastructure in search of the best way to satisfy required QoS constraints. In this paper, we discuss the advantages of Serverless workflow and how they can be used and monitored to natively trigger complex algorithm pipelines in the continuum, dynamically placing and relocating them taking into account incoming IoT data, QoS constraints, and the current status of the continuum infrastructure. Therefore we presented the Urgent Function Enabler (UFE) platform, a fully distributed architecture able to define, spread, and manage FaaS functions, using local IOT data managed using the Fiware ecosystem and a computing infrastructure composed of mobile and stable nodes.},
  keywords={Data analysis;Federated learning;Heuristic algorithms;Pipelines;Ecosystems;Europe;Distributed databases;faas;event-driven workflows;natural disaster management;ambient intelligence;ndm},
  doi={10.1109/ISCC58397.2023.10217920},
  ISSN={2642-7389},
  month={July},}@INPROCEEDINGS{10217933,
  author={Lukaj, Valeria and Catalfamo, Alessio and Martella, Francesco and Fazio, Maria and Villari, Massimo and Celesti, Antonio},
  booktitle={2023 IEEE Symposium on Computers and Communications (ISCC)}, 
  title={A NoSQL DBMS Transparent Data Encryption Approach for Cloud/Edge Continuum}, 
  year={2023},
  volume={},
  number={},
  pages={430-435},
  abstract={Edge systems are increasingly popular for data collection and processing. Typically, due to their limited storage capacity, pieces of data are continuously exchanged with Cloud systems which store them in distributed DataBase Management System (DBMS). This scenario, known as Cloud/Edge Continuum, is critical from a data security point of view as it is exposed to many risks. Transparent Data Encryption (TDE) is proposed as a possible solution for encrypting database files. However, current solutions do not suit the Cloud/Edge continuum requirements. In this paper, we aim at fulfilling this gap by proposing a solution to encrypt the data locally at the Edge and transfer them to a distributed database over the Cloud. Our approach allows us to perform queries directly on encrypted data over the Cloud and to retrieve them on the Edge for decryption. Experiments performed on different NoSQL DBMS solutions demonstrate the feasibility of our approach.},
  keywords={Privacy;Fault tolerance;Fault tolerant systems;Distributed databases;Medical services;Data collection;Database systems;Cloud/Edge Continuum;NoSQL;Database;Security;Transparent Data Encryption},
  doi={10.1109/ISCC58397.2023.10217933},
  ISSN={2642-7389},
  month={July},}@INPROCEEDINGS{10218062,
  author={León, Luis Jesús Martín and Herrera, Juan Luis and Berrocal, Javier and Galán-Jiménez, Jaime},
  booktitle={2023 IEEE Symposium on Computers and Communications (ISCC)}, 
  title={EFCC: a flexible Emulation Framework to evaluate network, computing and application deployments in the Cloud Continuum}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={In recent years, the number of devices connected to the Internet (and hence the data traffic) has significantly increased. The adoption of the Internet of Things paradigm, the use of the MicroServices Architecture for applications and the possibility of deploying such applications at different layers (fog, edge, cloud), makes the selection of an appropriate deployment a critical task for network operators and developers. In this paper, an emulation framework is proposed to allow them make a decision for the network, computing and application deployment in the cloud continuum, while satisfying the required Quality of Service. The framework is compatible both for IP and SDN network paradigms and is extensible to different types of scenarios thanks to its approach based on Docker containers. The evaluation over a realistic network scenario shows that it is extensible to any scenario and deployment required by the research community working on the cloud continuum.},
  keywords={Computers;Cloud computing;Emulation;Microservice architectures;Quality of service;Computer architecture;Containers;Cloud continuum;SDN;framework;Fog;IoT},
  doi={10.1109/ISCC58397.2023.10218062},
  ISSN={2642-7389},
  month={July},}@ARTICLE{10229131,
  author={Rodis, Panteleimon and Papadimitriou, Panagiotis},
  journal={IEEE Access}, 
  title={Unsupervised Deep Learning for Distributed Service Function Chain Embedding}, 
  year={2023},
  volume={11},
  number={},
  pages={91660-91672},
  abstract={Network Function Virtualization (NFV) has paved the way for the migration of Virtual Network Functions (VNFs) into multi-tenant datacenters, lowering the barrier for the introduction of new processing functionality into the network. Recent trends for resource orchestration across the entire compute continuum raise the need for decision making at low timescales, a requirement which can be hardly met by centralized resource optimizers that rely either on Linear Programming or Machine Learning (ML). In this respect, we present a distributed approach tailored to a crucial resource orchestration aspect, i.e., the embedding of Service Function Chains (SFCs) onto large-scale virtualized network infrastructures. In order to confront the computational hardness of the SFC embedding problem, we utilize a clustering method for the partitioning of the solution space, empowering the search for efficient solutions in parallel across all clusters. Another salient feature of our approach is the use of unsupervised deep learning for the computation of embeddings within each cluster. Our distributed SFC embedding framework is benchmarked against a state-of-the-art heuristic and a distributed greedy algorithm. Our evaluation results uncover notable gains in terms of resource efficiency, combined with solver runtimes in the order of milliseconds with thousands of substrate nodes.},
  keywords={Substrates;Greedy algorithms;Deep learning;Computational modeling;Bandwidth;Service function chaining;Search problems;Network function virtualization;Distributed computing;Network function virtualization;resource orchestration;deep learning;distributed computation},
  doi={10.1109/ACCESS.2023.3308492},
  ISSN={2169-3536},
  month={},}@ARTICLE{10229195,
  author={Esmat, Haitham H. and Lorenzo, Beatriz},
  journal={IEEE/ACM Transactions on Networking}, 
  title={Self-Learning Multi-Mode Slicing Mechanism for Dynamic Network Architectures}, 
  year={2023},
  volume={},
  number={},
  pages={1-16},
  abstract={Dynamic network architectures that utilize communication, computing, and storage resources at the wireless edge are key to delivering emerging services in next-generation networks (e.g., AR/VR, 3D video, intelligent cars, etc). Network slicing can be significantly enhanced by including dynamically available resources throughout the fog/edge/cloud continuum and using mmWave/THz bands. However, network slicing of dynamic multi-tier computing networks remains under-explored. In this paper, we present a self-learning end-to-end network slicing mechanism (SELF-E2E-NS) that facilitates collaboration between the Infrastructure Provider (InP) and tenants to slice their subscribers’ resources (i.e., radio, computing, and storage) as fog resources. To adapt to the uncertain availability of resources at the edge and minimize the risk of non-satisfying service level agreements (SLAs), our slicing mechanism has two operational modes. Operational mode 1 is for joint network slicing (JNS) in which the InP infrastructure is augmented with fog resources and jointly sliced to meet high throughput and delay tolerant requirements. Operational mode 2 is for independent network slicing (INS) in which the InP infrastructure and fog resources are sliced separately to achieve high throughput, low-latency, and high-reliability requirements. Our schemes leverage mmWave/THz, fog/edge/cloud computing, and caching to achieve new service requirements. We design a DQ-E2E-JNS algorithm that uses Deep Dueling network and a MAAC-E2E-INS algorithm based on multi-agent actor-critic, which incorporate service-aware pricing feedback and fog trading matching, respectively. These algorithms find the optimal slice request admission and collaboration policy that maximizes the long-term revenue of the InP and tenants for each mode. The simulation results show that our novel slicing mechanism can serve up to 4 times more requests and effectively exploits different spectrum bands and fog resources to improve revenue and performance.},
  keywords={Indium phosphide;III-V semiconductor materials;Network slicing;Low latency communication;Reliability;Millimeter wave communication;Throughput;Dynamic network architectures;network slicing;multi-agent actor-critic;fog/edge/cloud;risk model},
  doi={10.1109/TNET.2023.3305975},
  ISSN={1558-2566},
  month={},}@INPROCEEDINGS{10207454,
  author={Pittalà, Gaetano Francesco and Borsatti, Davide and Davoli, Gianluca and Cerroni, Walter and Tarchi, Daniele and Raffaelli, Carla},
  booktitle={2023 23rd International Conference on Transparent Optical Networks (ICTON)}, 
  title={Towards 6G AI-enabled Service Orchestration in the Cloud Continuum}, 
  year={2023},
  volume={},
  number={},
  pages={1-4},
  abstract={End-to-end service orchestration leveraging computing and communication resources in the cloud continuum is addressed. A modular architecture is proposed to facilitate data-driven/AI adoption, while achieving enhanced energy efficient automation in 6G service provisioning. A selection of available enabling technologies to deploy the architecture is presented.},
  keywords={6G mobile communication;Cloud computing;Computer architecture;Standardization;Optical fiber networks;Energy efficiency;Security;6G;Service Orchestration;Cloud continuum;Artificial Intelligence;Energy efficiency},
  doi={10.1109/ICTON59386.2023.10207454},
  ISSN={2161-2064},
  month={July},}@INPROCEEDINGS{10205816,
  author={Kakati, Sangeeta and Brorsson, Mats},
  booktitle={2023 3rd International Conference on Intelligent Technologies (CONIT)}, 
  title={WebAssembly Beyond the Web: A Review for the Edge-Cloud Continuum}, 
  year={2023},
  volume={},
  number={},
  pages={1-8},
  abstract={The cloud computing environment has changed over the past years, transitioning from a centralized architecture including big data centers to a dispersed and heterogeneous architecture that incorporates edge followed by device and processing units. This transformation calls for a cross-platform, interoperable solution, a feature that WebAssembly (Wasm) offers. Wasm can be used as a compact and effective representation of server-less functions or micro-services deployment at the cloud edge. In heterogeneous edge settings, where various hardware and software systems might be employed, this is especially crucial. Developers can create applications that can operate on any Wasm-compatible device without spending time worrying about platform-specific challenges by using a common runtime environment.In this survey, we indicate the main challenges and opportunities for Wasm runtimes in the edge-cloud continuum, such as performance optimisation, security, and interoperability with other programming languages and platforms. We provide a comprehensive overview of the current landscape of Wasm outside the web, including possible standardization efforts and best practices for using these runtimes, thus serving as a valuable resource for researchers and practitioners in the field.},
  keywords={Surveys;Cloud computing;Runtime environment;Runtime;Codes;Computer architecture;Standardization;WebAssembly;Cloud computing;Edge computing;IoT;Heterogeneity;Runtimes},
  doi={10.1109/CONIT59222.2023.10205816},
  ISSN={},
  month={June},}@INPROCEEDINGS{10196847,
  author={Aldinucci, Marco and Birke, Robert and Brogi, Antonio and Carlini, Emanuele and Coppola, Massimo and Danelutto, Marco and Dazzi, Patrizio and Ferrucci, Luca and Forti, Stefano and Kavalionak, Hanna and Mencagli, Gabriele and Mordacchini, Matteo and Pasin, Marcelo and Paganelli, Federica and Torquati, Massimo},
  booktitle={2023 IEEE 47th Annual Computers, Software, and Applications Conference (COMPSAC)}, 
  title={A Proposal for a Continuum-aware Programming Model: From Workflows to Services Autonomously Interacting in the Compute Continuum}, 
  year={2023},
  volume={},
  number={},
  pages={1852-1857},
  abstract={This paper proposes a continuum-aware programming model enabling the execution of application workflows across the compute continuum: cloud, fog and edge resources. It simplifies the management of heterogeneous nodes while alleviating the burden of programmers and unleashing innovation. This model optimizes the continuum through advanced development experiences by transforming workflows into autonomous service collaborations. It reduces complexity in positioning/interconnecting services across the continuum. A meta-model introduces high-level workflow descriptions as service networks with defined contracts and quality of service, thus enabling the deployment/management of workflows as first-class entities. It also provides automation based on policies, monitoring and heuristics. Tailored mechanisms orchestrate/manage services across the continuum, optimizing performance, cost, data protection and sustainability while managing risks. This model facilitates incremental development with visibility of design impacts and seamless evolution of applications and infrastructures. In this work, we explore this new computing paradigm showing how it can trigger the development of a new generation of tools to support the compute continuum progress.},
  keywords={Technological innovation;Costs;Computational modeling;Data protection;Quality of service;Programming;Software;Workflows;Compute continuum;Programming models},
  doi={10.1109/COMPSAC57700.2023.00287},
  ISSN={0730-3157},
  month={June},}@INPROCEEDINGS{10193730,
  author={Fortino, Giancarlo},
  booktitle={2023 International Conference on Intelligent Computing, Communication, Networking and Services (ICCNS)}, 
  title={Keynote Speech 1: Integrating Machine Learning and Multi-Agent Systems for Fully Enabling Device-Edge-Cloud Continuum in Complex IoT Worlds}, 
  year={2023},
  volume={},
  number={},
  pages={1-1},
  abstract={Recently the device-edge-cloud paradigm is gaining momentum due to the benefits it could provide for the development of highly effective, efficient, and complex IoT ecosystems of diversified scale. However, there are many issues related to unsupervised control aspects that need to be addressed in order to fully realize the approach and make it fully operative in real complex environments. In order to address such issues, in this talk, we propose an holistic integration of machine learning and multi-agent systems to create a data-driven control architecture capable to autonomically monitor and control the device-edge-cloud continuum. This objective is being developed in the context of the Horizon Europe project named MLSysOps (https://mlsysops.eu/). Some use cases will be proposed to elucidate our current findings.},
  keywords={Multi-agent systems;Machine learning;Internet of Things;IEEE Press;Wearable computers;Special issues and sections;Sensors},
  doi={10.1109/ICCNS58795.2023.10193730},
  ISSN={},
  month={June},}@INPROCEEDINGS{10188371,
  author={Kartsakli, Elli and Perez-Romero, Jordi and Sallent, Oriol and Bartzoudis, Nikolaos and Frascolla, Valerio and Mohalik, Swarup Kumar and Metsch, Thiis and Antonopoulos, Angelos and Tuna, Ömer Faruk and Deng, Yansha and Tao, Xin and Serrano, Maria A. and Quiñones, Eduardo},
  booktitle={2023 Joint European Conference on Networks and Communications & 6G Summit (EuCNC/6G Summit)}, 
  title={AI-Powered Edge Computing Evolution for Beyond 5G Communication Networks}, 
  year={2023},
  volume={},
  number={},
  pages={478-483},
  abstract={Edge computing is a key enabling technology that is expected to play a crucial role in beyond 5G (B5G) and 6G communication networks. By bringing computation closer to where the data is generated, and leveraging Artificial Intelligence (AI) capabilities for advanced automation and orchestration, edge computing can enable a wide range of emerging applications with extreme requirements in terms of latency and computation, across multiple vertical domains. In this context, this paper first discusses the key technological challenges for the seamless integration of edge computing within B5G/6G and then presents a roadmap for the edge computing evolution, proposing a novel design approach for an open, intelligent, trustworthy, and distributed edge architecture.},
  keywords={6G mobile communication;Intelligent automation;Privacy;5G mobile communication;Ecosystems;Safety;Communication networks;Security;Artificial intelligence;Edge computing;Edge computing;AI/ML-based optimization;security and trustworthiness;B5G/6G evolution;edge-cloud compute continuum;closed-loop automation},
  doi={10.1109/EuCNC/6GSummit58263.2023.10188371},
  ISSN={2575-4912},
  month={June},}@INPROCEEDINGS{10181202,
  author={Morabito, Gabriele and Sicari, Christian and Carnevale, Lorenzo and Galletta, Antonino and Modica, Giuseppe Di and Villari, Massimo},
  booktitle={2023 IEEE/ACM 23rd International Symposium on Cluster, Cloud and Internet Computing Workshops (CCGridW)}, 
  title={Securing Serverless Workflows on the Cloud Edge Continuum}, 
  year={2023},
  volume={},
  number={},
  pages={118-124},
  abstract={Serverless Computing is an emergent solution that helps deploy applications in the Cloud and sometimes on the Edge, reducing the integration time and the maintenance cost of the data centers. The lack of a standard for functions and the impossibility of connecting them together in complex workflows is currently holding back the growth of Function-as-a-Service (FaaS) use. In this scenario, OpenWolf tries to overcome these issues by implementing a solution to spread functions over the Cloud-Edge Continuum and connecting them using a standardized Domain-Specific Language (DSL) to describe a serverless based workflow. In this work, we aim to enhance the OpenWolf project, solving many security threats the engine suffers, like the authenticated and authorized execution of workflows and the injection of malicious functions inside a workflow. We will validate this new version of OpenWolf in a Smart City surveillance scenario, providing validation and performance tests.},
  keywords={Smart cities;Surveillance;Serverless computing;Maintenance engineering;Malware;Security;Engines;serverless;faas;workflows;cloud-edge continuum;security;authentication},
  doi={10.1109/CCGridW59191.2023.00032},
  ISSN={},
  month={May},}@INPROCEEDINGS{10175414,
  author={Palomares, Javier and Coronado, Estefanía and Cervelló-Pastor, Cristina and Siddiqui, Shuaib},
  booktitle={2023 IEEE 9th International Conference on Network Softwarization (NetSoft)}, 
  title={Enabling Intelligence Inclusiveness in Edge to Cloud Continuum: Challenges and Opportunities}, 
  year={2023},
  volume={},
  number={},
  pages={362-365},
  abstract={Edge to Cloud Continuum is a concept that integrates cloud computing and cellular networks that has been gaining popularity due to its potential to provide a seamless user experience and address the challenges of managing complex multi-domain networks involving massive IoT devices. Enabling intelligence in the Edge to Cloud Continuum can further enhance its capabilities, offering benefits such as reduced latency, improved scalability, enhanced resource utilization, and increased context awareness. This paper provides insights into the opportunities and challenges of enabling intelligence in Edge to Cloud Continuum, highlighting the potential of this technology. This study presents a comprehensive review of the existing literature on enabling intelligence in Edge to Cloud Continuum, to reach the research questions that will construct the PhD. Various tools and technologies that can be used to integrate intelligence into the Edge to Cloud Continuum system were explored and analyzed. In addition, this study provides a detailed work plan for the upcoming months of the project.},
  keywords={Cellular networks;Cloud computing;Scalability;Systems architecture;Context awareness;User experience;Resource management;Edge to Cloud Continuum;Multi-domain;Enabling Intelligence;Distributed Systems;6G},
  doi={10.1109/NetSoft57336.2023.10175414},
  ISSN={2693-9789},
  month={June},}@INPROCEEDINGS{10175449,
  author={Massa, Jacopo and Forti, Stefano and Paganelli, Federica and Dazzi, Patrizio and Brogi, Antonio},
  booktitle={2023 IEEE 9th International Conference on Network Softwarization (NetSoft)}, 
  title={Declarative Provisioning of Virtual Network Function Chains in Intent-based Networks}, 
  year={2023},
  volume={},
  number={},
  pages={522-527},
  abstract={Intent-based Networking (IBN) aims at simplifying network configuration and management by using high-level objectives that express the desired state of the network rather than the details of how to implement it. In this article, we propose a declarative methodology and an associated open-source Prolog prototype (i) to model IBN intents related to the provisioning of Virtual Network Function (VNF) chains, and (ii) to process those intents to assemble and place a VNF chain that fulfils them. Our prototype is assessed over a lifelike motivating scenario.},
  keywords={Prototypes;Configuration management;intent-based networking;declarative programming;virtual network functions;cloud-edge continuum},
  doi={10.1109/NetSoft57336.2023.10175449},
  ISSN={2693-9789},
  month={June},}@INPROCEEDINGS{10175444,
  author={Raza, Syed Mohsan and Minerva, Roberto and Crespi, Noel and Karech, Mehdi},
  booktitle={2023 IEEE 9th International Conference on Network Softwarization (NetSoft)}, 
  title={Definition Of Digital Twin Network Data Model in The Context of Edge-Cloud Continuum}, 
  year={2023},
  volume={},
  number={},
  pages={402-407},
  abstract={The telecommunications sector is devoting an initial interest in the representation of complex networks as Digital Twins. The concept of a Digital Twin Network (DTN) is a research topic, but it promises to be an important step for harmonizing different models of the Edge-Cloud Continuum. The DTN software framework aims at helping network operations by providing updated and complete views on the network or parts of it, and it also introduces the possibility to simulate the network behavior or to learn from network events history (Machine Learning) without jeopardizing the actual operations of resources. In addition, thanks to the representation capabilities of the DT, its usage in the network promises to support different stakeholders’ views on their virtualized and physical infrastructure. This work tries to consolidate a DTN data model representing the elements of the Edge-Cloud Continuum by providing a layered (horizontal) and segmented (vertical) view of the infrastructure to all the involved stakeholders. The DTN model is an ontology where the linked classes represent properties and relations of networked components. This work aims to design a flexible and extensible ontology that describes the Edge-Cloud continuum usable in the telecommunications as well in the Cloud (IT and web) industries creating a bridge between the two.},
  keywords={Industries;Machine learning;Ontologies;Data models;Software;Digital twins;Telecommunications;Digital Twin Network;Edge-Cloud Continuum;Data Model;Ontology;Service User},
  doi={10.1109/NetSoft57336.2023.10175444},
  ISSN={2693-9789},
  month={June},}@INPROCEEDINGS{10171469,
  author={Angelelli, Luc and da Silva, Anderson Andrei and Georgiou, Yiannis and Mercier, Michael and Mounié, Gregory and Trystram, Denis},
  booktitle={2023 IEEE/ACM 23rd International Symposium on Cluster, Cloud and Internet Computing (CCGrid)}, 
  title={Towards a Multi-objective Scheduling Policy for Serverless-based Edge-Cloud Continuum}, 
  year={2023},
  volume={},
  number={},
  pages={485-497},
  abstract={The cloud is extended towards the edge to form a computing continuum while managing resources' heterogeneity. The serverless technology simplified how to build cloud applications and use resources, becoming a driving force in consolidating the continuum with the deployment of small functions with short execution. However, the adaptation of serverless to the edge-cloud continuum brings new challenges mainly related to resource management and scheduling. Standard cloud scheduling policies are based on greedy algorithms that do not efficiently handle platforms' heterogeneity nor deal with problems such as cold start delays. This work introduces a new scheduling policy that tries to address these issues. It is based on multi-objective optimization for data transfers and makespan while considering heterogeneity. Using simulations that vary workloads, platforms, and heterogeneity levels, we study the system utilization, the trade-offs between the targets, and the impacts of considering platforms' heterogeneity. We perform comparisons with a baseline inspired by a Kubernetes-based policy, representing greedy algorithms. Our experiments show considerable gaps between the efficiency of a greedy-based scheduling policy and a multi-objective-based one. The last outperforms the baseline by reducing makespan, data transfers, and system utilization by up to two orders of magnitudes in relevant cases for the edge-cloud continuum.},
  keywords={Greedy algorithms;Cloud computing;Processor scheduling;Force;Data transfer;Scheduling;Delays;Scheduling Policies;Serverless Computing;Edge-Cloud Continuum;Heterogeneous Platforms},
  doi={10.1109/CCGrid57682.2023.00052},
  ISSN={},
  month={May},}@INPROCEEDINGS{10171523,
  author={Jansen, Matthijs and Al-Dulaimy, Auday and Papadopoulos, Alessandro V. and Trivedi, Animesh and Iosup, Alexandru},
  booktitle={2023 IEEE/ACM 23rd International Symposium on Cluster, Cloud and Internet Computing (CCGrid)}, 
  title={The SPEC-RG Reference Architecture for The Compute Continuum}, 
  year={2023},
  volume={},
  number={},
  pages={469-484},
  abstract={As the next generation of diverse workloads like autonomous driving and augmented/virtual reality evolves, computation is shifting from cloud-based services to the edge, leading to the emergence of a cloud-edge compute continuum. This continuum promises a wide spectrum of deployment opportunities for workloads that can leverage the strengths of cloud (scalable infrastructure, high reliability) and edge (energy efficient, low latencies). Despite its promises, the continuum has only been studied in silos of various computing models, thus lacking strong end-to-end theoretical and engineering foundations for computing and resource management across the continuum. Consequently, devel-opers resort to ad hoc approaches to reason about performance and resource utilization of workloads in the continuum. In this work, we conduct a first-of-its-kind systematic study of various computing models, identify salient properties, and make a case to unify them under a compute continuum reference architecture. This architecture provides an end-to-end analysis framework for developers to reason about resource management, workload distribution, and performance analysis. We demonstrate the utility of the reference architecture by analyzing two popular continuum workloads, deep learning and industrial IoT. We have developed an accompanying deployment and benchmarking framework and first-order analytical model for quantitative reasoning of continuum workloads. The framework is open-sourced and available at https://github.com/atlarge-research/continuum.},
  keywords={Cloud computing;Systematics;Computational modeling;Computer architecture;Reliability theory;Energy efficiency;Performance analysis;Compute continuum;reference architecture;edge computing;resource management;offloading;benchmark},
  doi={10.1109/CCGrid57682.2023.00051},
  ISSN={},
  month={May},}@INPROCEEDINGS{10158559,
  author={Petcu, Dana},
  booktitle={2023 IEEE 17th International Symposium on Applied Computational Intelligence and Informatics (SACI)}, 
  title={Cognitive Cloud Continuum : Plenary Talk}, 
  year={2023},
  volume={},
  number={},
  pages={000011-000012},
  abstract={Cloud Continuum is the extension of the traditional Cloud towards multiple entities like Internet of Things devices, Edge or Fog nodes that provide analysis, processing, storage, and data generation capabilities [1]. Cognitive Cloud Continuum, i.e. AI-enabled Cloud continuum, aims to automatically adapt to the growing complexity and data deluge by integrating seamlessly diverse computing and data environments by learning from monitoring and management of deployed services or applying AI techniques for dynamic load balancing to optimize energy consumption, resource usage or network traffic. To achieve this aim several efforts are underway. We will focus on the recent results related to coupling federated learning mechanisms and intelligent resource discovery to achieve an adaptive hosting environment capable of running both on Cloud and close to the Edge, machine learning in anomaly detection, or transprecision computing for distributed stream processing [2], [3], [4].},
  keywords={Cloud computing;Energy consumption;Federated learning;Image edge detection;Telecommunication traffic;Load management;Dynamic scheduling},
  doi={10.1109/SACI58269.2023.10158559},
  ISSN={2765-818X},
  month={May},}@INPROCEEDINGS{10155023,
  author={Bocci, Alessandro and Forti, Stefano and Brogi, Antonio},
  booktitle={2023 12th Mediterranean Conference on Embedded Computing (MECO)}, 
  title={Sustainable Cloud-Edge Infrastructure as a Service}, 
  year={2023},
  volume={},
  number={},
  pages={1-4},
  abstract={Utility computing paradigms (e.g, Fog, Edge, Mist computing) allow application operators to deploy applications onto heterogeneous resources along the infrastructure continuum spanning from virtually unbounded datacenters to resource-constrained Edge and IoT devices. Application operators must suitably select infrastructure resources where to deploy at best the services that compose their applications, and then manage the application life-cycle across the infrastructure. We propose a new view of the Cloud-Edge continuum, where infrastructure providers lease tailored portions of the infrastructure, determined by taking into account the hardware and QoS requirements as well as the sustainability goals expressed by application operators. Most importantly, infrastructure providers offer the selected Cloud-Edge infrastructure portion as a single virtual infrastructure node that customers can exploit to deploy and manage their applications in a seamless way.},
  keywords={Cloud computing;Embedded computing;Quality of service;Hardware;Internet of Things;Sustainable development;Cloud-Edge computing;sustainability;*aaS},
  doi={10.1109/MECO58584.2023.10155023},
  ISSN={2637-9511},
  month={June},}@INPROCEEDINGS{10155683,
  author={Becker, Matthias and Dasari, Dakshina and Casini, Daniel},
  booktitle={2023 IEEE 29th Real-Time and Embedded Technology and Applications Symposium (RTAS)}, 
  title={On the QNX IPC: Assessing Predictability for Local and Distributed Real-Time Systems}, 
  year={2023},
  volume={},
  number={},
  pages={289-302},
  abstract={With the advent of massively distributed applications such as those required by the IoT-to-Edge-to-Cloud compute continuum (i.e., automotive, smart agriculture, smart manufacturing, and more), real-time communication mechanisms allowing physically distributed nodes to seamlessly communicate as if they were running on the same host acquired noteworthy importance. To this end, the synchronous inter-process communication (IPC) mechanism provided by the QNX operating system (OS) is a promising candidate, as it allows using the application programming interface for communicating both on a single- and multi-node setting. Furthermore, it provides priority and partition inheritance mechanisms to improve predictability when working with the Adaptive Partitioning Scheduler (APS), a reservationbased scheduler provided by the QNX OS. This paper explores the behavior of the QNX synchronous message-passing (SyncMP) IPC with an extensive set of experiments, using them to formalize its behavior and model it from a real-time perspective. Then, it provides a response-time analysis for client-server applications based on the QNX SyncMP building upon self-suspending task theory. Finally, we evaluate the analysis on an application based on the WATERS 2019 Challenge by Bosch.},
  keywords={Smart agriculture;Adaptation models;Operating systems;Buildings;Predictive models;Real-time systems;Behavioral sciences;real time systems;inter process communication;IPC;distributed system},
  doi={10.1109/RTAS58335.2023.00030},
  ISSN={2642-7346},
  month={May},}@INPROCEEDINGS{10150375,
  author={Di Modica, Giuseppe and Galletta, Antonino and Carnevale, Lorenzo and Alkhansa, Ahmad and Costantini, Alessandro and Cesini, Daniele and Bellavista, Paolo and Villari, Massimo},
  booktitle={2023 IEEE International Conference on Pervasive Computing and Communications Workshops and other Affiliated Events (PerCom Workshops)}, 
  title={Orchestration of Containerized Applications in the Cloud Continuum}, 
  year={2023},
  volume={},
  number={},
  pages={44-49},
  abstract={Cloud Service orchestration is a hot topic addressed by both the academia and the business world. The increasing diversification of the Cloud offer, coupled with the strong need of flexible and scalable applications demanded by customers, is calling up for efficient and agile mechanisms that streamline the devops practices. The novel opportunity of running software applications or just application portions on resources located on the Edge of the network poses an additional challenge to the already tough problem of flexibly and seamlessly provisioning services. Orchestrators must deal with a continuum of heterogeneous computing resources, contributed by both the Edge and the Cloud, that promises several benefits yet at a higher management cost. In this paper, we introduce a continuum-enabled orchestrator and discuss an application provisioning paradigm that helps the users to easily configure and deploy composite applications. Finally, we showcase the potential of the orchestrator in a simple yet practical smart-city scenario.},
  keywords={Pervasive computing;Costs;Conferences;Software;Heterogeneous networks;Business;Service orchestration;Computing Continuum;Cloud;Edge;IoT;Machine Learning;OCR},
  doi={10.1109/PerComWorkshops56833.2023.10150375},
  ISSN={2766-8576},
  month={March},}@INPROCEEDINGS{10150251,
  author={Balouek-Thomert, Daniel and Perez, Ismael and Faulstich, Sam D. and Holmes, Heather A and Altintas, Ilkay and Parashar, Manish},
  booktitle={2023 IEEE International Conference on Pervasive Computing and Communications Workshops and other Affiliated Events (PerCom Workshops)}, 
  title={Keynote Talk: Leveraging the Edge-Cloud Continuum to Manage the Impact of Wildfires on Air Quality}, 
  year={2023},
  volume={},
  number={},
  pages={27-31},
  abstract={The emergence of large-scale cyberinfrastructure composed of heterogeneous computing capabilities and diverse sensors and other data sources are enabling new classes of dynamic data-driven “urgent” applications. However, as the variety of data sources, and the volume and velocity of data grow, processing this data while considering the uncertainty of infrastructure and timeliness constraints of urgent application workflows can be nontrivial and presents a new set of challenges. In this paper, we use an application workflow that monitors and manage the air quality impacts of remote wildfires to illustrate how the R-Pulsar programming system, leveraging the SAGE and WIFIRE platforms, can enable urgent analytics across the computing continuum. R-Pulsar supports urgent data-processing pipelines that tradeoff the content of data, cost of computation, and urgency of the results to support such workflows. We also discuss research challenges associated with programming urgent application workflows and managing resources in an autonomic manner.},
  keywords={Pervasive computing;Uncertainty;Runtime;Soft sensors;Conferences;Pipelines;Fires;Urgent computing;Continuum computing;Edge-Cloud integration;Cyberinfrastructure;Uncertainty},
  doi={10.1109/PerComWorkshops56833.2023.10150251},
  ISSN={2766-8576},
  month={March},}@INPROCEEDINGS{10150345,
  author={Russo, Gabriele Russo and Mannucci, Tiziana and Cardellini, Valeria and Presti, Francesco Lo},
  booktitle={2023 IEEE International Conference on Pervasive Computing and Communications Workshops and other Affiliated Events (PerCom Workshops)}, 
  title={Artifact: Serverledge: Decentralized Function-as-a-Service for the Edge-Cloud Continuum}, 
  year={2023},
  volume={},
  number={},
  pages={1-2},
  abstract={Serverledge is a research prototype to run serverless functions in the Edge-Cloud Continuum. This artifact guide illustrates the minimal steps required to obtain, configure and run Serverledge. We also explain how to access the evaluation results presented in the paper and generate the associated figures.},
  keywords={Pervasive computing;Conferences;Prototypes;serverless;edge computing;offloading},
  doi={10.1109/PerComWorkshops56833.2023.10150345},
  ISSN={2766-8576},
  month={March},}@INPROCEEDINGS{10154398,
  author={Kukliński, Sławomir and Batalla, Jordi Mongay and Pieczerak, Janusz},
  booktitle={NOMS 2023-2023 IEEE/IFIP Network Operations and Management Symposium}, 
  title={Dynamic and Multiprovider-based Resource Infrastructure in the NFV MANO Framework}, 
  year={2023},
  volume={},
  number={},
  pages={1-4},
  abstract={The Cloud Continuum concept proposes integrating Edge, Central Clouds as well as constrained, dynamic and unreliable Far-Edge resources (terminals, IoT) owned by users and different providers and exposing them to services uniformly. The ETSI NFV MANO framework assumes almost static NFV Infrastructure (NFVI) and has no business interfaces nor mechanisms for the dynamic adding or removing data centres. It is also not able to cope with constrained and unreliable resources. The paper presents a modification of the MANO framework to cope with the mentioned issues. In the described concept, all resources are exposed to the orchestrators via the Resource Layer, which also provides business interfaces to different infrastructure providers and improves exposed resources’ reliability by hiding infrastructure dynamicity to a certain extent. The idea also contributes to orchestration scalability by allowing multiple orchestrators atop the same resource pool.},
  keywords={Cloud computing;Data centers;Scalability;Logic gates;Dynamic scheduling;Reliability;Business;network virtualization;network orchestration;virtualized infrastructure;MANO;NFV;cloud},
  doi={10.1109/NOMS56928.2023.10154398},
  ISSN={2374-9709},
  month={May},}@ARTICLE{10158366,
  author={Kontodimas, Konstantinos and Soumplis, Polyzois and Kretsis, Aristotelis and Kokkinos, Panagiotis and Fehér, Marcell and Lucani, Daniel E. and Varvarigos, Emmanouel},
  journal={IEEE Transactions on Cloud Computing}, 
  title={Secure Distributed Storage Orchestration on Heterogeneous Cloud-Edge Infrastructures}, 
  year={2023},
  volume={11},
  number={4},
  pages={3407-3425},
  abstract={Distributed storage systems spanning across different cloud data centers have substantially improved availability and flexibility for data storage and retrieval operations. However, stringent latency requirements of emerging applications necessitate optimized selection of storage resources that exhibit smaller delay. Introducing edge resources into distributed storage systems enables data placement closer to its source, but simultaneously increases the complexity of decision-making and orchestration processes for optimal data placement. In this work, we develop mechanisms for storing data across an infrastructure that includes both edge and cloud resources. Our approach focuses on optimizing data integrity, longevity, security, and cost, while leveraging erasure coding when performing the resource allocation. We first present a comprehensive mixed integer linear programming formulation of the storage resource orchestration problem. As the search space for the optimal solution can be vast and the execution time prohibitively large for real size problems, we also propose an innovative multi-agent heuristic approach that uses the rollout, a reinforcement based policy, to balance performance and execution time efficiently. Through various simulation experiments, we evaluate the developed mechanisms and trade-offs involved in our approach. By incorporating data from a multi-cloud provider, we further enhance the validity of the simulations and the conclusions drawn.},
  keywords={Cloud computing;Costs;Encoding;Resource management;Distributed databases;Codes;Logic gates;Distributed storage;cloud-edge continuum;erasure coding;resource allocation;data security;data availability},
  doi={10.1109/TCC.2023.3287653},
  ISSN={2168-7161},
  month={Oct},}@INPROCEEDINGS{10152231,
  author={Kovacevic, Ivana and Ul Haq, Rana Inzimam and Okwuibe, Jude and Kumar, Tanesh and Glisic, Savo and Ylianttila, Mika and Harjula, Erkki},
  booktitle={2023 IEEE 17th International Symposium on Medical Information and Communication Technology (ISMICT)}, 
  title={Reinforcement Learning based Cloud and Edge Resource Allocation for Real-Time Telemedicine}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={Future healthcare services will extensively exploit wireless telehealth solutions in various healthcare use cases from preventive home monitoring to highly demanding real-time scenarios, such as monitoring an emergency patient's vital functions in an ambulance or ICU unit. Reliable real-time communications and computing are needed to enable these highly critical health services. However, the majority of current telehealth use cases are cloud - based, which poses a challenge to provide sufficient Quality of Service (QoS). The traditional centralized cloud infrastructure cannot meet the latency and reliability requirements due to long and unreliable communication routes. Therefore, the most advanced cloud solutions integrate edge computing as an integral part of the computational architecture to bring a part of the computational infrastructure to the proximity of the data sources and end-nodes, thus constituting an edge-cloud continuum. This continuum is capable of serving applications with real-time requirements. However, since edge computing capacity is a limited resource, solutions are needed for deciding which tasks should be run on edge and which at the data center. In this paper, we propose a machine learning-based solution to prioritize ultra-low-latency tasks for running on the edge to meet their strict delay requirements while leaving other tasks to be executed at remote servers. Our proposed solution in comparison to the baseline has a significantly lower dropping rate and outperforms fixed - interval scheduling solutions in terms of resource efficiency.},
  keywords={Processor scheduling;Telemedicine;Quality of service;Reinforcement learning;Real-time systems;Delays;Resource management;edge-cloud continuum;internet of medical things;real-time computing;latency-limited computing;resource allocation;reinforcement learning;Q-learning},
  doi={10.1109/ISMICT58261.2023.10152231},
  ISSN={2326-8301},
  month={May},}@ARTICLE{10145008,
  author={Tang, Chaogang and Wu, Huaming and Xiao, Shuo},
  journal={IEEE Internet of Things Magazine}, 
  title={Lightweight Reputation Management for Multi-Role Internet of Vehicles}, 
  year={2023},
  volume={6},
  number={2},
  pages={38-42},
  abstract={With the rapid development of the Internet of Vehicles (IoV), smart vehicles can fulfill multiple roles in either the information-centric IoV or the task-oriented IoV. However, malicious vehicles may undermine the trustiness of vehicles towards each other, and further damage these IoV networks. Given the multiple roles undertaken by vehicles in IoV networks, we aim to design a lightweight reputation-based mechanism for a hybrid IoV network in this article. This mechanism can realize real-time reputation updates and synchronization in the device-edge-cloud continuum. Simulation is conducted to validate the reputation management strategy in this article. We also discuss some opportunities and challenges to shed a light on the future research directions in this topic.},
  keywords={Real-time systems;Synchronization;Resource management;Task analysis;Internet of Vehicles},
  doi={10.1109/IOTM.001.2200230},
  ISSN={2576-3199},
  month={June},}@INPROCEEDINGS{10137039,
  author={Ferikoglou, Aggelos and Kokkinis, Argyris and Danopoulos, Dimitrios and Oroutzoglou, Ioannis and Nanos, Anastasios and Karanastasis, Stathis and Sipos, Marton and Ghotbi, Javad Fadaie and Vegas Olmos, Juan Jose and Masouros, Dimosthenis and Siozios, Kostas},
  booktitle={2023 Design, Automation & Test in Europe Conference & Exhibition (DATE)}, 
  title={The SERRANO platform: Stepping towards seamless application development & deployment in the heterogeneous edge-cloud continuum}, 
  year={2023},
  volume={},
  number={},
  pages={1-4},
  abstract={The need for real-time analytics and faster decision-making mechanisms has led to the adoption of hardware accelerators such as GPUs and FPGAs within the edge cloud computing continuum. However, their programmability and lack of orchestration mechanisms for seamless deployment make them difficult to use efficiently. We address these challenges by presenting SERRANO, a project for transparent application deployment in a secure, accelerated, and cognitive cloud continuum. In this work, we introduce the SERRANO platform and its software, orchestration, and deployment services, focusing on its methods for automated GPU/FPGA acceleration and efficient, isolated, and secure deployments. By evaluating these services against representative use cases, we highlight SERRANO 's ability to simplify the development and deployment process without sacrificing performance.},
  keywords={Cloud computing;Decision making;Focusing;Software;Real-time systems;Hardware acceleration;Field programmable gate arrays;Edge-Cloud Continuum;Heterogeneity;SDK},
  doi={10.23919/DATE56975.2023.10137039},
  ISSN={1558-1101},
  month={April},}@INPROCEEDINGS{10136957,
  author={Russo, Gabriele Russo and Cardellini, Valeria and Presti, Francesco Lo},
  booktitle={2023 31st Euromicro International Conference on Parallel, Distributed and Network-Based Processing (PDP)}, 
  title={Serverless Functions in the Cloud-Edge Continuum: Challenges and Opportunities}, 
  year={2023},
  volume={},
  number={},
  pages={321-328},
  abstract={The Function-as-a-Service (FaaS) paradigm is increasingly adopted for the development of Cloud-native applications, which especially benefit from the seamless scalability and attractive pricing models of serverless deployments. With the continuous emergence of latency-sensitive applications and services, including Internet-of-Things and augmented reality, it is now natural to wonder whether and how the FaaS paradigm can be efficiently exploited in the Cloud-Edge Continuum, where serverless functions may benefit from reduced network delay between their invoking users and the FaaS platform. In this paper, we illustrate the key challenges that must be faced to effectively deploy serverless functions in the Cloud-Edge Continuum and review recent contributions proposed by the research community towards overcoming those challenges. We also discuss the key issues that currently remain unsolved and highlight a few research opportunities for better support of FaaS in the Compute Continuum.},
  keywords={Scalability;Pricing;Distance measurement;Delays;Augmented reality;Serverless;compute continuum;edge computing},
  doi={10.1109/PDP59025.2023.00056},
  ISSN={2377-5750},
  month={March},}@INPROCEEDINGS{10136967,
  author={Belcastro, Loris and Marozzo, Fabrizio and Orsino, Alessio and Talia, Domenico and Trunfio, Paolo},
  booktitle={2023 31st Euromicro International Conference on Parallel, Distributed and Network-Based Processing (PDP)}, 
  title={Using the Compute Continuum for Data Analysis: Edge-cloud Integration for Urban Mobility}, 
  year={2023},
  volume={},
  number={},
  pages={338-344},
  abstract={More and more in recent years, IT companies have adopted edge-cloud continuum solutions to efficiently perform analysis tasks on data generated by IoT devices. As an example, in the context of urban mobility, the use of edge solutions can be extremely effective in managing tasks that require real-time analysis and low response times, such as driver assistance, collision avoidance and traffic sign recognition. On the other hand, the integration with cloud systems can be convenient for tasks that require a lot of computing resources for accessing and analyzing big data collections, such as route calculations and targeted advertising. Designing and testing such hybrid edge-cloud architectures are still open issues due to their novelty, large scale, heterogeneity, and complexity. In this paper, we analyze how the compute continuum can be exploited for efficiently managing urban mobility tasks. In particular, we focus on a case study related to taxi fleets that need to find locations where they are more likely to find new passengers. Through a simulation-based approach, we demonstrate that these solutions turn out to be effective for this class of problems, especially as the number of connected vehicles increases.},
  keywords={Processor scheduling;Computer architecture;Reinforcement learning;Software;Real-time systems;Internet of Things;Time factors;Edge-cloud architecture;IoT infrastructure;Edge computing;Urban computing;Smart cities;Urban mobility},
  doi={10.1109/PDP59025.2023.00058},
  ISSN={2377-5750},
  month={March},}@ARTICLE{10136731,
  author={Campolo, Claudia and Iera, Antonio and Molinaro, Antonella},
  journal={IEEE Access}, 
  title={Network for Distributed Intelligence: A Survey and Future Perspectives}, 
  year={2023},
  volume={11},
  number={},
  pages={52840-52861},
  abstract={To keep pace with the explosive growth of Artificial Intelligence (AI) and Machine Learning (ML)-dominated applications, distributed intelligence solutions are gaining momentum, which exploit cloud facilities, edge nodes and end-devices to increase the overall computational power, meet application requirements, and optimize performance. Despite the benefits in terms of data privacy and efficient usage of resources, distributing intelligence throughout the cloud-to-things continuum raises unprecedented challenges to the network design. Distributed AI/ML components need high-bandwidth, low-latency connectivity to execute learning and inference tasks, while ensuring high-accuracy and energy-efficiency. This paper aims to explore the new challenging distributed intelligence scenario by extensively and critically scanning the main research achievements in the literature. In addition, starting from them, the main building blocks of a network ecosystem that can enable distributed intelligence are identified and the authors’ views are dissected to provide guidelines for the design of a “future network for distributed Intelligence”.},
  keywords={Artificial intelligence;Computational modeling;Data models;Training;Distributed databases;Wireless communication;Cloud computing;Machine learning;Artificial intelligence;cloud continuum;distributed intelligence;machine learning;network},
  doi={10.1109/ACCESS.2023.3280411},
  ISSN={2169-3536},
  month={},}@ARTICLE{10133912,
  author={Caiazza, Chiara and Luconi, Valerio and Vecchio, Alessio},
  journal={IEEE Internet Computing}, 
  title={Measuring the Energy of Smartphone Communications in the Edge-Cloud Continuum: Approaches, Challenges, and a Case Study}, 
  year={2023},
  volume={27},
  number={6},
  pages={29-35},
  abstract={As computational resources are placed at different points in the edge-cloud continuum, not only is the responsiveness on the client side affected, so too is the amount of energy spent during communications. We summarize the main approaches used to estimate the energy consumption of smartphones and the main difficulties typically encountered. A case study then shows how such approaches can be put into practice. The results show that the edge is favorable in terms of energy consumption, compared to more remote locations.},
  keywords={Monitoring;Hardware;Software;Batteries;Energy consumption;Task analysis;Servers},
  doi={10.1109/MIC.2023.3279438},
  ISSN={1941-0131},
  month={Nov},}@INPROCEEDINGS{10116068,
  author={Pelle, István and Paolucci, Francesco and Sonkoly, Balázs and Cugini, Filippo},
  booktitle={2023 Optical Fiber Communications Conference and Exhibition (OFC)}, 
  title={P4-based Hitless FaaS Load Balancer for Packet-Optical Network Edge Continuum}, 
  year={2023},
  volume={},
  number={},
  pages={1-3},
  abstract={P4 and novel node telemetry are leveraged to provide load balancing of ultralow latency serverless application to multiple edges. Handling the overload of one edge without observable change in application delay is demonstrated.},
  keywords={5G mobile communication;Serverless computing;Load management;Optical fiber communication;Delays;Telemetry;Reliability},
  doi={10.1364/OFC.2023.Th1D.5},
  ISSN={},
  month={March},}@ARTICLE{10122723,
  author={Kennedy, Jason and Sharma, Vishal and Varghese, Blesson and Reaño, Carlos},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={Multi-Tier GPU Virtualization for Deep Learning in Cloud-Edge Systems}, 
  year={2023},
  volume={34},
  number={7},
  pages={2107-2123},
  abstract={Accelerator virtualization offers several advantages in the context of cloud-edge computing. Relatively weak user devices can enhance performance when running workloads by accessing virtualized accelerators available on other resources in the cloud-edge continuum. However, cloud-edge systems are heterogeneous, often leading to compatibility issues arising from various hardware and software stacks present in the system. One mechanism to alleviate this issue is using containers for deploying workloads. Containers isolate applications and their dependencies and store them as images that can run on any device. In addition, user devices may move during the course of application execution, and thus mechanisms such as container migration are required to move running workloads from one resource to another in the network. Furthermore, an optimal destination will need to be determined when migrating between virtual accelerators. Scheduling and placement strategies are incorporated to choose the best possible location depending on the workload requirements. This paper presents AVEC, a framework for accelerator virtualization in cloud-edge computing. The AVEC framework enables the offloading of deep learning workloads for inference from weak user devices to computationally more powerful devices in a cloud-edge network. AVEC incorporates a mechanism that efficiently manages and schedules the virtualization of accelerators. It also supports migration between accelerators to enable stateless container migration. The experimental analysis highlights that AVEC can achieve up to 7x speedup by offloading applications to remote resources. Furthermore, AVEC features a low migration downtime that is less than 5 seconds.},
  keywords={Cloud computing;Containers;Virtualization;Graphics processing units;Deep learning;Data centers;Virtual machine monitors;Accelerators;containers;edge computing;migration;virtualization},
  doi={10.1109/TPDS.2023.3274957},
  ISSN={1558-2183},
  month={July},}@ARTICLE{10122638,
  author={Raith, Philipp and Nastic, Stefan and Dustdar, Schahram},
  journal={IEEE Internet Computing}, 
  title={Serverless Edge Computing—Where We Are and What Lies Ahead}, 
  year={2023},
  volume={27},
  number={3},
  pages={50-64},
  abstract={The edge–cloud continuum combines heterogeneous resources, which are complex to manage. Serverless edge computing is a suitable candidate to manage the continuum by abstracting away the underlying infrastructure, improving developers’ experiences, and optimizing overall resource utilization. However, understanding and overcoming programming support, reliability, and performance engineering challenges are essential for the success of serverless edge computing. In this article, we review and evaluate the maturity of serverless approaches for the edge–cloud continuum. Our review includes commercial, community-driven offerings and approaches from academia. We identify several maturity levels of serverless edge computing and use them as criteria to evaluate the maturity of current state-of-the-art serverless approaches with a special focus on the programming, reliability, and performance challenges. Finally, we lay a road map toward the next generation of serverless edge computing systems.},
  keywords={Edge computing;Computational modeling;Serverless computing;Programming;Reliability engineering;Data models;Internet},
  doi={10.1109/MIC.2023.3260939},
  ISSN={1941-0131},
  month={May},}
  @ARTICLE{10122618,
  author={Cohen, Itamar and Chiasserini, Carla Fabiana and Giaccone, Paolo and Scalosub, Gabriel},
  journal={IEEE/ACM Transactions on Networking}, 
  title={Dynamic Service Provisioning in the Edge-Cloud Continuum With Bounded Resources}, 
  year={2023},
  volume={31},
  number={6},
  pages={3096-3111},
  abstract={We consider a hierarchical edge-cloud architecture in which services are provided to mobile users as chains of virtual network functions. Each service has specific computation requirements and target delay performance, which require placing the corresponding chain properly and allocating a suitable amount of computing resources. Furthermore, chain migration may be necessary to meet the services’ target delay. We model and formalize the problem of finding a feasible chain placement and resource allocation, while minimizing the migration, bandwidth, and computation costs. We tackle this problem by partitioning it into a (i) CPU allocation problem, and a (ii) placement problem. For the CPU allocation problem, we find an optimal solution. For the placement problem, we show that even finding a feasible solution is NP-hard, and envision an algorithm that is guaranteed to find a feasible solution while leveraging a bounded amount of resource augmentation. Our algorithms are incorporated into a solution framework that aims to minimize both the cost and the required resource augmentation. The results, obtained through trace-driven, large-scale simulations, show that our framework can provide a close-to-optimal solution while running several orders of magnitude faster than an ILP solver.},
  keywords={Delays;Costs;Computational modeling;Cloud computing;Service function chaining;IEEE transactions;Topology;Edge computing;service function chaining;5G mobile communication},
  doi={10.1109/TNET.2023.3271674},
  ISSN={1558-2566},
  month={Dec},}@INPROCEEDINGS{10092668,
  author={Khalyeyev, Danylo and Bureš, Tomáš and Hnětynka, Petr},
  booktitle={2023 IEEE 20th International Conference on Software Architecture Companion (ICSA-C)}, 
  title={Towards a Reference Component Model of Edge-Cloud Continuum}, 
  year={2023},
  volume={},
  number={},
  pages={91-95},
  abstract={Edge-cloud continuum (ECC) is a novel paradigm that seeks to blend the worlds of cloud computing and IoT into a continuous ecosystem capable of providing access to a range of previously impossible applications with significantly improved quality of service. However, while using the term ECC becomes increasingly common, there is still no clear and commonly accepted consensus on what the term entails and which properties the ECC environment must possess. Consequently, there is a lack of tools and examples for reasoning about applications in ECC and their specific properties. In this paper, we present the results of our literature study aimed at identifying the most common properties ascribed to ECC. Based on this, we outline a reference component model that can serve as a tool for reasoning about ECC systems and their properties.},
  keywords={Cloud computing;Software architecture;Computational modeling;Ecosystems;Quality of service;Cognition;Edge-cloud continuum;edge computing;fog computing;Internet of Things;component model},
  doi={10.1109/ICSA-C57050.2023.00030},
  ISSN={2768-4288},
  month={March},}@INPROCEEDINGS{10104570,
  author={de Cola, Tomaso},
  booktitle={WSA & SCC 2023; 26th International ITG Workshop on Smart Antennas and 13th Conference on Systems, Communications, and Coding}, 
  title={Enabling Effective Multi-Link Data Distribution in NTN-based 6G Networks}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={The extreme service requirements posed by 6G are particularly challenging in environments where terrestrial infrastructure is not continuously available, whereby connectivity complements offered by non-terrestrial networks are an appealing option. The 5G standardisation process currently carried out within 3GPP has instead proven the need for non-terrestrial networks and their seamless integration into terrestrial networks, so as to enable several use-cases in the context of un(der) served scenarios and eventually achieve the largely advertised concept of “connecting the unconnected”. In such a context, the data connectivity model is not exclusively based on pushing video contents to demanding users like in typical satellite business, but is embracing more attractive use-cases for the entire 6G ecosystem, i.e. ranging from device manufacturers to cloud/service providers through mobile/satellite operators. In particular, effective data distribution over multiple links, AI-driven network management, routing and resource allocation, as well as cloud-continuum in heterogeneous networks are key objectives for paving the way towards NTN-inclusive 6G systems. Behind the many potentials that such an ambitious network concept offers, important research challenges emerge, hence motivating a multi-folded analysis, including network architecture, protocol, and algorithm optimisations. Some of the most interesting research directions are addressed in this paper, in order to shed some lights into the main elements characterising the considered technology problems and delve into the corresponding solution space. Additionally, an initial evaluation of AI-driven network management and routing approaches is provided.},
  keywords={},
  doi={},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{10099372,
  author={Russo, Gabriele Russo and Mannucci, Tiziana and Cardellini, Valeria and Presti, Francesco Lo},
  booktitle={2023 IEEE International Conference on Pervasive Computing and Communications (PerCom)}, 
  title={Serverledge: Decentralized Function-as-a-Service for the Edge-Cloud Continuum}, 
  year={2023},
  volume={},
  number={},
  pages={131-140},
  abstract={As the Function-as-a-Service (FaaS) paradigm enjoys growing popularity within Cloud-based systems, there is increasing interest in moving serverless functions towards the Edge, to better support geo-distributed and pervasive applications. However, enjoying both the reduced latency of Edge and the scalability of FaaS requires new architectures and implementations to cope with typical Edge challenges (e.g., nodes with limited computational capacity). While first solutions have been proposed for Edge-based FaaS, including light function sandboxing techniques, we lack a platform with the ability to span both Edge and Cloud and adaptively exploit both. In this paper, we present Serverledge, a FaaS platform designed for the Edge-to-Cloud continuum. Serverledge adopts a decentralized architecture, where function invocation requests can be fully served within Edge nodes. To cope with load peaks, Serverledge also supports vertical (i.e., from Edge to Cloud) and horizontal (i.e., among Edge nodes) computation offloading. Our evaluation shows that Serverledge outperforms Apache OpenWhisk in an Edge-like scenario and has competitive performance with state-of-the-art frameworks optimized for the Edge, with the advantage of built-in support for vertical and horizontal offloading.},
  keywords={Pervasive computing;Scalability;Decentralized control;Computer architecture;serverless;edge computing;offloading},
  doi={10.1109/PERCOM56429.2023.10099372},
  ISSN={2474-249X},
  month={March},}@ARTICLE{10103507,
  author={Belcastro, Loris and Marozzo, Fabrizio and Orsino, Alessio and Talia, Domenico and Trunfio, Paolo},
  journal={IEEE Access}, 
  title={Edge-Cloud Continuum Solutions for Urban Mobility Prediction and Planning}, 
  year={2023},
  volume={11},
  number={},
  pages={38864-38874},
  abstract={In recent years, there has been an increase in the use of edge-cloud continuum solutions to efficiently collect and analyze data generated by IoT devices. In this paper, we investigate to what extent these solutions can manage tasks related to urban mobility, by combining real-time and low latency analysis offered by the edge with large computing and storage resources provided by the cloud. Our proposal is organized into three parts. The first part focuses on defining three application scenarios in which geotagged data generated by IoT objects, such as taxis, cars, and smartphones, are collected and analyzed through machine learning-based algorithms (i.e., next location prediction, location-based advertising, and points of interest recommendation). The second part is dedicated to modeling an edge-cloud continuum architecture capable of managing a large number of IoT devices and executing machine learning algorithms to analyze the data they generate. The third part analyzes the experimental results in which different design choices were evaluated, such as the number of devices and orchestration policies, to improve the performance of machine learning algorithms in terms of processing time, network delay, task failure, and computational resource utilization. The results highlight the potential benefits of edge and cloud cooperation in the three application scenarios, demonstrating that it significantly improves resource utilization and reduces the task failure rate compared to other widely adopted architectures, such as edge- or cloud-only architectures.},
  keywords={Internet of Things;Cloud computing;Computer architecture;Task analysis;Public transportation;Machine learning algorithms;Data models;Edge-cloud architecture;IoT infrastructure;edge computing;urban computing;smart cities;urban mobility},
  doi={10.1109/ACCESS.2023.3267471},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10073502,
  author={Escobar, Juan José López and Gil-Castiñeira, Felipe and Díaz Redondo, Rebeca P.},
  booktitle={2023 26th Conference on Innovation in Clouds, Internet and Networks and Workshops (ICIN)}, 
  title={Decentralized Serverless IoT Dataflow Architecture for the Cloud-to-Edge Continuum}, 
  year={2023},
  volume={},
  number={},
  pages={42-49},
  abstract={The advent of new computing and communication trends that link pervasive data sources and consumers, such as Edge Computing, 5G and IIoT, has led to the development of the Cloud-to-Edge Continuum in order to take advantage of the resources available in massive IoT scenarios, and to conduct data analysis to leverage intelligence at all levels. This paper outlines the challenging requirements of this novel IoT context and presents an innovative IoT framework to develop dataflow applications for data-centric environments. The proposed design takes advantage of decentralized Pub/Sub communication and serverless nanoservice architecture, using novel technologies such as Zenoh and WebAssembly, respectively, to implement lightweight services along the Cloud-to-Edge infrastructure. We also describe some use cases to illustrate the benefits and concerns of the coming IoT generation.},
  keywords={Cloud computing;Technological innovation;Data analysis;Soft sensors;Conferences;Computer architecture;Publish-subscribe;Cloud-to-Edge Continuum;IoT Framework;Serverless (FaaS) Dataflow Computing;Decentralized Publish-Subscribe;Zenoh;WebAssembly (WASM)},
  doi={10.1109/ICIN56760.2023.10073502},
  ISSN={2472-8144},
  month={March},}@INPROCEEDINGS{10073495,
  author={Al-Naday, Mays and Reed, Martin and Dobre, Vlad and Toor, Salman and Volckaert, Bruno and De Turck, Filip},
  booktitle={2023 26th Conference on Innovation in Clouds, Internet and Networks and Workshops (ICIN)}, 
  title={Service-based Federated Deep Reinforcement Learning for Anomaly Detection in Fog Ecosystems}, 
  year={2023},
  volume={},
  number={},
  pages={121-128},
  abstract={With Digital transformation, the diversity of services and infrastructure in backhaul fog network(s) is rising to unprecedented levels. This is causing a rising threat of a wider range of cyber attacks coupled with a growing integration of constrained range of infrastructure, particularly seen at the network edge. Deep reinforcement-based learning is an attractive approach to detecting attacks, as it allows less dependency on labeled data with better ability to classify different attacks. However, current approaches to learning are known to be computationally expensive (cost) and the learning experience can be negatively impacted by the presence of outliers and noise (quality). This work tackles both the cost and quality challenges with a novel service-based federated deep reinforcement learning solution, enabling anomaly detection and attack classification at a reduced data cost and with better quality. The federated settings in the proposed approach enable multiple edge units to create clusters that follow a bottom-up learning approach. The proposed solution adapts deep Q-learning Network (DQN) for service-tunable flow classification, and introduces a novel federated DQN (FDQN) for federated learning. Through such targeted training and validation, variation in data patterns and noise is reduced. This leads to improved performance per service with lower training cost. Performance and cost of the solution, along with sensitivity to exploration parameters are evaluated using an example publicly available dataset (UNSW-NB15). Evaluation results show the proposed solution to maintain detection accuracy with lower data supply, while improving the classification rate by a factor of ≈ 2.},
  keywords={Deep learning;Training;Cloud computing;Technological innovation;Costs;Q-learning;Sensitivity;cyber security;federated deep reinforcement learning;Deep Q-Learning;anomaly detection;cloud-to-edge continuum;fog computing},
  doi={10.1109/ICIN56760.2023.10073495},
  ISSN={2472-8144},
  month={March},}@ARTICLE{10000402,
  author={Wang, Luhui and Ren, Xuebin and Zhao, Cong and Zhao, Fangyuan and Yang, Shusen},
  journal={IEEE Internet of Things Journal}, 
  title={MPDM: A Multi-Paradigm Deployment Model for Large-Scale Edge-Cloud Intelligence}, 
  year={2023},
  volume={10},
  number={10},
  pages={8773-8785},
  abstract={The development of cloud and edge computing has enabled the easy access of artificial intelligence (AI) services for massive heterogeneous and resource-constrained devices. Particularly, computation-intensive AI services can be orchestrated and deployed in the cloud or edge according to varying performance and cost requirements. Nonetheless, the improved accessibility of deep learning (DL) model variants and the evolving of computational intelligence paradigms pose great challenges for orchestrating large-scale DL inference services in the cloud-edge continuum. Focusing on cloud or edge-based deployment, existing work on multi-variant service orchestration often has a limited solution space of deployment plans. To address this limitation, we first propose a novel multi-paradigm deployment model (MPDM) for service orchestration, which not only considers the model variants but also allows the co-existence of multiple paradigms for large-scale inference service deployment. The service deployment in the MPDM model is then formulated as a multiobjective optimization problem of seeking a better tradeoff among the system accuracy, service scale, and deployment cost. To solve the multiobjective optimization, we further propose a weighted metric-based constructive heuristic algorithm (WCH), which can efficiently obtain an approximately optimal Pareto frontier. Extensive experimental results have validated the effectiveness and efficiency of WCH, and revealed the impacts of both multi-paradigm deployment and edge-cloud collaborative intelligence (ECCI) paradigm on large-scale DL serving systems.},
  keywords={Cloud computing;Artificial intelligence;Internet of Things;Computational modeling;Costs;Optimization;Analytical models;Edge-cloud collaborative intelligence (ECCI);multiobjective optimization;service deployment;service orchestration},
  doi={10.1109/JIOT.2022.3232582},
  ISSN={2327-4662},
  month={May},}@ARTICLE{9963590,
  author={Malandrino, Francesco and Chiasserini, Carla Fabiana and di Giacomo, Giuseppe},
  journal={IEEE/ACM Transactions on Networking}, 
  title={Efficient Distributed DNNs in the Mobile-Edge-Cloud Continuum}, 
  year={2023},
  volume={31},
  number={4},
  pages={1702-1716},
  abstract={In the mobile-edge-cloud continuum, a plethora of heterogeneous data sources and computation-capable nodes are available. Such nodes can cooperate to perform a distributed learning task, aided by a learning controller (often located at the network edge). The controller is required to make decisions concerning (i) data selection, i.e., which data sources to use; (ii) model selection, i.e., which machine learning model to adopt, and (iii) matching between the layers of the model and the available physical nodes. All these decisions influence each other, to a significant extent and often in counter-intuitive ways. In this paper, we formulate a problem addressing all of the above aspects and present a solution concept called RightTrain, aiming at making the aforementioned decisions in a joint manner, minimizing energy consumption subject to learning quality and latency constraints. RightTrain leverages an expanded-graph representation of the system and a delay-aware Steiner tree to obtain a provably near-optimal solution while keeping the time complexity low. Specifically, it runs in polynomial time and its decisions exhibit a competitive ratio of  $2(1+\epsilon)$ , outperforming state-of-the-art solutions by over 50%. Our approach is also validated through a real-world implementation.},
  keywords={Task analysis;Performance evaluation;Training;Data models;Servers;Network topology;IEEE transactions;Distributed machine learning;mobile-edge-cloud continuum;5G and beyond networks},
  doi={10.1109/TNET.2022.3222640},
  ISSN={1558-2566},
  month={Aug},}@ARTICLE{9802863,
  author={Tapwal, Riya and Deb, Pallav Kumar and Misra, Sudip and Pal, Surjya Kanta},
  journal={IEEE Transactions on Computers}, 
  title={Shadows: Blockchain Virtualization for Interoperable Computations in IIoT Environments}, 
  year={2023},
  volume={72},
  number={3},
  pages={868-879},
  abstract={In this work, we propose Shadows, a virtual blockchain (VC) for achieving parallel consensus and efficient management of data in industries by utilizing BC. Typically, industrial processes involve heterogeneous activities which require real-time consensus, managed execution, isolation, data sharing, accelerated computation, and efficient utilization of various computational resources such as CPU, RAM, and storage. Achieving these in real-time using a single conventional blockchain (BC) leads to the exertion of computational power. To achieve resource-efficient real-time consensus, we virtualize the nodes of the BC network and create different BC for various activities. Further, to virtualize BC and provide better access to data, we propose smart contracts liable for providing a unified view of a single BC, dynamically creating BCs, allocating resources to these, and making communication between the same. Through lab-scale experiments, we demonstrate that Shadows is capable of utilizing the resources efficiently and achieving real-time consensus. In particular, Shadows uses 18% CPU and 92% memory while reducing consensus time by 56%, compared to a single conventional BC. Shadows also accesses the data efficiently by utilizing smart contracts and dynamically balances the load by migrating the virtual nodes. Further, Shadows reduces the number of migrations to make the balance system by 67%.},
  keywords={Smart contracts;Blockchains;Security;Resource management;Industries;Virtualization;Real-time systems;Blockchain;industrial Internet of Things;osmotic computing;parallel consensus;resource allocation;smart contracts;virtualization},
  doi={10.1109/TC.2022.3184271},
  ISSN={1557-9956},
  month={March},}@INPROCEEDINGS{10419097,
  author={Lee, Craig A. and Bohn, Robert and Michel, Martial},
  booktitle={2022 Cloud Continuum}, 
  title={The IEEE 2302–2021 Standard on Intercloud Interoperability and Federation: Seamless Cloud-agnostic Interoperability Management for Resource Discovery, Access and Trust}, 
  year={2022},
  volume={},
  number={},
  pages={1-9},
  abstract={This column in Cloud Continuum is titled “Frontiers in Software, Architecture, and Standards” or “Frontiers” for short. It will cover emerging design and implementation patterns being used to lay the software, architecture, and standards groundwork for new functional capabilities in the cloud-to-edge continuum. In it, we'll use articles, interviews, and contributions from leading proponents for new cloud tools to explain how they are being developed and designed to work together and the capabilities they provide. Wherever possible, we'll focus on areas that include opportunities for open source development and community involvement in carrying out these advances.},
  keywords={Cloud computing;Software architecture;Collaboration;Interviews;Standards;Interoperability},
  doi={10.1109/CloudContinuum57429.2022.00003},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10419094,
  author={Rana, Omer and Spyridopoulos, Theodoros and Hudson, Nathaniel and Baughman, Matt and Chard, Kyle and Foster, Ian and Khan, Aftab},
  booktitle={2022 Cloud Continuum}, 
  title={Hierarchical and Decentralised Federated Learning}, 
  year={2022},
  volume={},
  number={},
  pages={1-9},
  abstract={Federated Learning (FL) is a recent approach for distributed Machine Learning (ML) where data are never communicated to a central node. Instead, an ML model (for example, a deep neural network) is initialized by a designated central (aggregation) node and shared with training nodes that have direct access to data of interest. These training nodes then perform small batches of training on their local data. Periodically, each training node submits ML model parameter/weight updates to the central node. The central node aggregates the parameters/weights to create a new global ML model that it then re-shares with the training nodes. This process can either take place indefinitely or be repeated until the ML model converges with respect to some evaluation metric (for example, mean average error, accuracy).},
  keywords={Training;Smart agriculture;Costs;Federated learning;Aggregates;Soil;Data models},
  doi={10.1109/CloudContinuum57429.2022.00008},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10419098,
  author={Jeffery, Keith and Schubert, Lutz},
  booktitle={2022 Cloud Continuum}, 
  title={In the Cognitive Cloud Continuum}, 
  year={2022},
  volume={},
  number={},
  pages={1-5},
  abstract={Modern day IT pervades all areas of our daily life-from daily work to societal tasks (community activities) to our private concerns. All of these require management of information across completely different domains of knowledge, variety of devices, locations, and timing constraints. For example, safe and effective management of natural disasters (earthquakes, volcanic eruptions, tsunamis, and flooding) has completely different requirements than managing a national economy or the profitability of a business.},
  keywords={Profitability;Disasters;Earthquakes;Tsunami;Timing;Floods;Task analysis;Compute Continuum;complete computing;Cloud computing;data management;distributed systems},
  doi={10.1109/CloudContinuum57429.2022.00005},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10419083,
  author={Yousif, Mazin},
  booktitle={2022 Cloud Continuum}, 
  title={The Network in the Continuum}, 
  year={2022},
  volume={},
  number={},
  pages={1-2},
  abstract={In the last issue, I outlined the enormous breadth of the cloud-edge continuum, in terms of archi-tecture paradigms and infrastructure, for both hardware and software. Because of this breadth, the networks that connect and integrate all the elements play a vital role.},
  keywords={Software;Hardware},
  doi={10.1109/CloudContinuum57429.2022.00004},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10419082,
  author={Ranjan, Rajiv},
  booktitle={2022 Cloud Continuum}, 
  title={Securing SDN Controllers in Internet of Things Environments}, 
  year={2022},
  volume={},
  number={},
  pages={1-8},
  abstract={The Blue Skies Research column is intended to identify the most important cutting-edge research for the edge-cloud continuum. The complexity around such research is huge as it sits at the intersection of multiple, interdependent disci-plines involving complex systems and technologies. Example research areas include Internet of Things, Big Data Analytics, Cloud Computing, and Edge Computing. We will cover one specific research topic in each issue as it relates to the theme of the issue.},
  keywords={Cloud computing;Network architecture;Control systems;Complexity theory;Internet of Things;Complex systems;Edge computing},
  doi={10.1109/CloudContinuum57429.2022.00006},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10419093,
  author={Yousif, Mazin},
  booktitle={2022 Cloud Continuum}, 
  title={The Edge, the Cloud, and the Continuum}, 
  year={2022},
  volume={},
  number={},
  pages={1-2},
  abstract={If we consider the cloud as the compute/data backend, and the edge the environment where the data sources are, we can imagine a huge space between them. That is what we refer to as the continuum, which can be single hop or multilayer multi-hop involving very diverse technologies. This is true regardless of whether the edge is big or small, is computationally-intensive or computationally-limited, is physically in close proximity to the cloud, or is really far away from a cloud-pick your other favorite char-acterizations here.},
  keywords={Image edge detection;Soft sensors;Nonhomogeneous media},
  doi={10.1109/CloudContinuum57429.2022.00001},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10419095,
  author={Weinman, Joe},
  booktitle={2022 Cloud Continuum}, 
  title={Trade-Offs Along the Cloud-Edge Continuum}, 
  year={2022},
  volume={},
  number={},
  pages={1-7},
  abstract={A range of options exist to implement today's digital architectures. Although an oversimplification, we can think of these options along a spectrum: At one extreme is a single instance “data center,” which might be an enterprise data center or a colocation facility, or perhaps even a single server or rack containing a database or application. Adjacent to that option is a set of perhaps dozens of hyperscale cloud facilities, with perhaps hundreds of thousands of servers, typically geographically distributed. As we continue through various layers of “fog,” we hit the near edge, which might include facilities in major metros, and then the far edge, which might include computing nodes located on every street corner, or spaced several per mile along a traffic corridor such as a superhighway. These then typically tie to endpoint elements, such as devices or things-for example, smart meters, irrigation sensors, smartphones, smart TVs, or connected vehicles. Sometimes individual processors will be aggregated into a system, such as an autonomous vehicle with a hundred or more micro-processors, or perhaps its entertainment system, or a network of systems, such as a factory including its robots, quality inspection systems, materials handling systems, and fire/smoke detection sensors.},
  keywords={Data centers;Smart TV;Robot sensing systems;Smart meters;Sensor systems;Servers;Smart phones},
  doi={10.1109/CloudContinuum57429.2022.00002},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10419099,
  author={Di Martino, Beniamino and Esposito, Antonio},
  booktitle={2022 Cloud Continuum}, 
  title={An Overview of Reference Architectures for Cloud Continuum Interoperability}, 
  year={2022},
  volume={},
  number={},
  pages={1-5},
  abstract={For all the technologies and paradigms that have gained success and have reached a maturity level to be potentially widely adopted worldwide, a crucial challenge has eventually arisen: Interoperability. Interoperability has often been the determinant driver for practical diffusion of successful solutions or the main cause of their eventual failure.},
  keywords={Interoperability;Standards},
  doi={10.1109/CloudContinuum57429.2022.00009},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10419096,
  author={Yousif, Mazin},
  booktitle={2022 Cloud Continuum}, 
  title={Intelligence in the Continuum}, 
  year={2022},
  volume={},
  number={},
  pages={1-2},
  abstract={Intelligence in nature is pervasive, distributed and, in some cases, cooperative, whether we are considering Einstein's development of the General Theory of Relativity, the ability of a mouse to learn a maze, or the ability of a plant to heal a wound). In computing, Artificial Intelligence (AI) is increasingly pervasive, distributed, and often, cooperative. It is an area that has been engineered for 7+ decades (and is ultimately based on the work of Alan Turing a decade before that) and, until recently, has focused on enabling systems to perform tasks, usually repetitive and routine in nature (for example robots in automobile manufacturing). Things are changing, though. AI has been making dramatic progress in generic domains such as speech recognition, visual perception, search, and language translation as well as in industry-specific applications such as manufacturing, education, and healthcare. Intelligence in IT is leveraged in many ways, such as relying on intelligent automation to optimize Infrastructure deployments, to improve the quality of testing, and to improve the effectiveness of security mechanisms.},
  keywords={Speech recognition;Wounds;Manufacturing;Artificial intelligence;Task analysis;Visual perception;Testing},
  doi={10.1109/CloudContinuum57429.2022.00007},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10152225,
  author={Sowiński, Piotr and Wasielewska-Michniewska, Katarzyna and Ganzha, Maria and Paw∤owski, Wies∤aw and Szmeja, Pawe∤ and Paprzycki, Marcin},
  booktitle={2022 IEEE 8th World Forum on Internet of Things (WF-IoT)}, 
  title={Efficient RDF Streaming for the Edge-Cloud Continuum}, 
  year={2022},
  volume={},
  number={},
  pages={1-8},
  abstract={With the ongoing, gradual shift of large-scale distributed systems towards the edge-cloud continuum, the need arises for software solutions that are universal, scalable, practical, and grounded in well-established technologies. Simultaneously, semantic technologies, especially in the streaming context, are becoming increasingly important for enabling interoperability in edge-cloud systems. However, in recent years, the field of semantic data streaming has been stagnant, and there are no available solutions that would fit those requirements. To fill this gap, in this contribution, a novel end-to-end RDF streaming approach is proposed (named Jelly). The method is simple to implement, yet very elastic, and designed to fit a wide variety of use cases. Its practical performance is evaluated in a series of experiments, including end-to-end throughput and latency measurements. It is shown that Jelly achieves vastly superior performance to the currently available approaches. The presented method makes significant progress towards enabling high-performance semantic data processing in numerous applications, including future edge-cloud systems. Moreover, this study opens up the possibility of applying and evaluating the method in real-life scenarios, which will be the focus of further research.},
  keywords={Ecosystems;Throughput;Data processing;Resource description framework;Software;Internet of Things;Interoperability;RDF;stream processing;edge-cloud continuum;Protocol Buffers;Apache Kafka;gRPC;large IoT ecosystems},
  doi={10.1109/WF-IoT54382.2022.10152225},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10152292,
  author={Brzozowski, Marcin and Langendoerfer, Peter and Casaca, Augusto and Grilo, Antonio and Diaz, Manuel and Martín, Cristian and Camacho, Jose and Landi, Giada},
  booktitle={2022 IEEE 8th World Forum on Internet of Things (WF-IoT)}, 
  title={UNITE: Integrated IoT-Edge-Cloud Continuum}, 
  year={2022},
  volume={},
  number={},
  pages={1-6},
  abstract={Although current edge and cloud systems offer amazing services that we could not even dream of a few years ago, end users cannot really benefit from them due to their high complexity: there are so many heterogeneous devices, protocols and development frameworks across the IoT-edge-cloud continuum. This complexity also prevents solving performance problems (such as server congestion or network congestion), as the main ideas only focus on a small part of the problem, e.g. how to solve a network problem without considering computing resources. This paper introduces the UNITE framework: a set of virtualization layers (computing, networking, and storage) that integrate a complete IoT-edge-cloud architecture and provides a simple interface for end users. UNITE also addresses performance issues by finding holistic solutions that look at the architecture as a whole. In addition, our framework also predicts emerging problems and proactively addresses them in advance before they occur.},
  keywords={Performance evaluation;Cloud computing;Protocols;Computer architecture;Robustness;Complexity theory;Servers;Internet of Things;Edge;Cloud;Computing;Networking},
  doi={10.1109/WF-IoT54382.2022.10152292},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10152153,
  author={Rattanatamrong, Prapaporn and Srisawat, Jarunchai and Boonchoo, Thapana and Haga, Jason},
  booktitle={2022 IEEE 8th World Forum on Internet of Things (WF-IoT)}, 
  title={Development of a Digital Twin for Smart Building over Edge-Cloud Continuum}, 
  year={2022},
  volume={},
  number={},
  pages={1-6},
  abstract={A smart building relies on an integration of physical and computational components to produce a secure, comfortable, and energy-efficient environment for its occupants. Each smart building is distinct in terms of requirements and characteristics. Hence, developing smart buildings to achieve reliability and real-time environmental adaption is a challenging task. This paper describes the development of a proof-of-concept digital twin for management and maintenance of an academic building. The physical building's real-time data is gathered from a distributed set of IoT sensors and cameras together with the facility management system's APIs into its digital twin. Then, the data is processed across both edge devices and in the cloud environment using machine learning models to generate insights required to manage daily operation of its physical components holistically. This work can help inform future efforts in creating a universal framework for digital twin design for smart building applications.},
  keywords={Smart buildings;Maintenance engineering;Sensor phenomena and characterization;Real-time systems;Sensor systems;Digital twins;Complexity theory;Digital Twin;Edge Computing;Cloud Computing;Smart Building;Computer Vision;Internet of Things (IoT)},
  doi={10.1109/WF-IoT54382.2022.10152153},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10076593,
  author={Hsieh, Chia-Ying and Venkateswaran, Praveen and Venkatasubramanian, Nalini and Hsu, Cheng-Hsin},
  booktitle={2022 18th International Conference on Mobility, Sensing and Networking (MSN)}, 
  title={T2C: A Multi-User System for Deploying DNNs in a Thing-to-Cloud Continuum}, 
  year={2022},
  volume={},
  number={},
  pages={255-262},
  abstract={The importance of IoT analytics in smart deploy-ments has resulted in an increased use of powerful Deep Neural Network (DNN) models to extract insights from the growing amount of IoT sensor data. Traditional approaches that entirely offload computation and model deployment to cloud servers have been shown to be inefficient due to network congestion and latency concerns. However, with the improved capabilities of IoT devices, it has now become possible to distribute and host DNNs across IoT devices, edge servers and the cloud. In this paper, we propose a multi-user system, called T2C, to dynamically choose, deploy, monitor and control DNN-driven IoT analytics in a thing-to-cloud continuum. T2C leverages strategies such as multi-task learning, hitchhiking, early exit, and dynamic reconfiguration, to maximize the number of served user requests while simultaneously satisfying accuracy and latency requirements. We propose a suite of deployment planning and reconfiguration algorithms to dynamically deploy and migrate DNN layers between IoT devices, edge servers, and the cloud. We implement T2C in a prototype testbed and show that our system: (i) achieves 6.8X throughput boost compared to baseline algorithms in the planning phase, and (ii) improves the satisfied ratio by up to 35% in the operation and reconfiguration phase.},
  keywords={Deep learning;Cloud computing;Runtime;Heuristic algorithms;Prototypes;Multitasking;Throughput;multi-task learning;early exit;edge computing;distributed deep learning},
  doi={10.1109/MSN57253.2022.00052},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10072488,
  author={Singh, Arun Kumar and Kumar, Anoop},
  booktitle={2022 5th International Conference on Contemporary Computing and Informatics (IC3I)}, 
  title={Task Scheduling and Load Balancing for Minimization of Response Time in IoT Assisted Cloud Environments}, 
  year={2022},
  volume={},
  number={},
  pages={144-148},
  abstract={The Internet of Things (IoT) necessitates a new processing paradigm that incorporates cloud scalability while reducing network latency by utilising resources closer to the network edge. On the one hand, it’s difficult to achieve such flexibility within the edge-to-cloud continuum, which consists of a distributed networked ecosystem of heterogeneous computing resources. IoT traffic dynamics, on the other hand, and the growing need for low-latency services necessitate decreasing reaction time and balancing service location. For cost-effective system administration and operations, fog computing load-balancing will become a cornerstone. Though virtualization attempts to instantaneously balance the load of the overall network, there’s still the possibility of capacity excessive usage or under development. Heavily loaded systems degrade efficiency, while undercharged systems use bandwidth inefficiently. Because of inadequate load distribution, overburdened systems emit additional energy, driving up the cost of coolers as well as adding significantly to the warming of the planet. Throughout most situations, cooling towers consume higher electricity than core IT technology. Despite the benefits of cloud computing as a distributed pool of resources and services, certain new IoT applications are not cloud-ready. Wind farms and smart traffic light systems, for example, have unique characteristics and requirements “(e.g., large-scale, geo-distribution) (e.g., very low and predictable latency)”. This research paper has considered secondary method of data collection to gather relevant and statistical data related to research topic.},
  keywords={Cloud computing;Costs;Processor scheduling;Scalability;Wind farms;Load management;Internet of Things;Load balancing;cloud computing;“Internet of Things or IoT”;Technology;Virtual Machines},
  doi={10.1109/IC3I56241.2022.10072488},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10061783,
  author={Filho, Roberto Rodrigues and Bittencourt, Luiz F. and Porter, Barry and Costa, Fábio M.},
  booktitle={2022 IEEE/ACM 15th International Conference on Utility and Cloud Computing (UCC)}, 
  title={Exploiting the Potential of the Edge-Cloud Continuum with Self-distributing Systems}, 
  year={2022},
  volume={},
  number={},
  pages={255-260},
  abstract={The Edge-Cloud Continuum offers a wide range of adaptive deployment settings for modern applications. However, in order to exploit the full potential of the edge-cloud infrastructure and platforms, applications have to be carefully crafted to be stateless and self-contained in small services or functions, i.e., the opposite of the classic stateful monolithic applications. In this paper, we explore an alternative approach that allows stateful single applications to also exploit the full potential of the edge-cloud continuum. We explore the concept of Self-distributing Systems(SDS) as a general approach for code offloading and as an elastic application-level mechanism for performance scale-out on the edge-cloud continuum. Our preliminary results indicate that SDS enables enough flexibility for applications to fully explore the edge-cloud resource mixture. Particularly, we describe our state management strategies for stateful code mobility; explore SDS as a general mechanism to exploit horizontal scaling on the cloud; and examine SDS as a general code offloading mechanism to move code from edge to cloud, showing the scenarios where our approach enables applications to positively exploit the edgecloud continuum for better performance.},
  keywords={Cloud computing;Codes;self-distributing systems;state management;edge-cloud continuum},
  doi={10.1109/UCC56403.2022.00046},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10061786,
  author={Raith, Philipp and Rausch, Thomas and Dustdar, Schahram and Rossi, Fabiana and Cardellini, Valeria and Ranjan, Rajiv},
  booktitle={2022 IEEE/ACM 15th International Conference on Utility and Cloud Computing (UCC)}, 
  title={Mobility-Aware Serverless Function Adaptations Across the Edge-Cloud Continuum}, 
  year={2022},
  volume={},
  number={},
  pages={123-132},
  abstract={Serverless functions have emerged as a useful abstraction to manage the complexity of distributed and heterogeneous edge-cloud infrastructure. Current cloud-centric orchestration services and serverless platforms are not suitable for the edge-cloud continuum due to their mobility-unawareness. In this paper, we present a mobility-aware framework for edgecloud systems, where the operational mechanisms of placement, scaling, and routing of serverless functions work in tandem. To that end, we formulate the concept of pressure that captures complex system behavior in a single metric. The pressure-based framework handles geo-distributed workload and user mobility by reducing overall function latency and increasing data throughput while efficiently using edge resources. Our contributions include a novel framework revolving around pressure and a realworld proof of concept evaluation. Our approach combines the benefits of a centralized control-plane with a decentralized dataplane. The results show the efficacy of the platform to address operational goals and make effective and deterministic tradeoffs between system utilization and application performance. The novel concept of pressure shows great extensibility and builds the base for a plethora of future works.},
  keywords={Measurement;Costs;System performance;Computational modeling;Serverless computing;Throughput;Routing;Edge Cloud Continuum;Serverless Computing;Function as a Service;Edge Intelligence},
  doi={10.1109/UCC56403.2022.00023},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10061781,
  author={Song, Hui and Soylu, Ahmet and Roman, Dumitru},
  booktitle={2022 IEEE/ACM 15th International Conference on Utility and Cloud Computing (UCC)}, 
  title={Towards Cognitive Self-Management of IoT-Edge-Cloud Continuum based on User Intents}, 
  year={2022},
  volume={},
  number={},
  pages={1-4},
  abstract={Elasticity of the computing continuum with on demand availability allows for automated provisioning and release of computing resources as needed; however, this self management capability is severely limited due to the lack of knowledge on historical and timely resource utilisation and means for stakeholders to express their needs in a high-level manner. In this paper, we introduce and discuss a new concept – intent-based cognitive continuum for sustainable elasticity.},
  keywords={Cloud computing;Elasticity;Stakeholders;Resource management;Computing continuum;intent-based computing},
  doi={10.1109/UCC56403.2022.00055},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10061789,
  author={Truong, Hong-Linh and Magoutis, Kostas},
  booktitle={2022 IEEE/ACM 15th International Conference on Utility and Cloud Computing (UCC)}, 
  title={Robustness via Elasticity Accelerators for the IoT-Edge-Cloud Continuum}, 
  year={2022},
  volume={},
  number={},
  pages={291-296},
  abstract={This paper presents a novel framework to enhance programmability of the IoT-edge-cloud continuum and to accommodate rapid change through software composition and elastic adaptation using appropriate reusable runtime components, techniques, and languages (which we collectively term Accelerators) to optimize resources and services. We particularly pinpoint elasticity as a driver for increased robustness, an ability we abbreviate as $\mathrm{R}_{\mathrm{V}}$E. $\mathrm{R}_{\mathrm{V}}$E Accelerators aim at enabling end-to-end programming, configuration, monitoring, and optimization in the IoT-edge-cloud continuum for emerging swarm applications and services, with the ability to coordinate domain-specific elasticity capabilities in a cross-layered manner. $\mathrm{R}_{\mathrm{V}}\mathrm{E}$ Accelerators will enable developers to easily program adaptive edge-cloud functionality through different layers, while cloud and edge solution providers can coordinate policies across layers to support robust, resilient systems at low effort and cost for their customers.},
  keywords={Cloud computing;Cross layer design;Runtime;Elasticity;Programming;Robustness;Software;end-to-end;elasticity;resilience;edge computing;cloud computing},
  doi={10.1109/UCC56403.2022.00052},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10062523,
  author={Zhang, Jiaqiang and Keramat, Farhad and Yu, Xianjia and Hernández, Daniel Montero and Queralta, Jorge Peña and Westerlund, Tomi},
  booktitle={2022 Seventh International Conference on Fog and Mobile Edge Computing (FMEC)}, 
  title={Distributed Robotic Systems in the Edge-Cloud Continuum with ROS 2: a Review on Novel Architectures and Technology Readiness}, 
  year={2022},
  volume={},
  number={},
  pages={1-8},
  abstract={Robotic systems are more connected, networked, and distributed than ever. New architectures that comply with the de facto robotics middleware standard, ROS 2, have recently emerged to fill the gap in terms of hybrid systems deployed from edge to cloud. This paper reviews new architectures and technologies that enable containerized robotic applications to seamlessly run at the edge or in the cloud. We also overview systems that include solutions from extension to ROS 2 tooling to the integration of Kubernetes and ROS 2. Another important trend is robot learning, and how new simulators and cloud simulations are enabling, e.g., large-scale reinforcement learning or distributed federated learning solutions. This has also enabled deeper integration of continuous interaction and continuous deployment (CI/CD) pipelines for robotic systems development, going beyond standard software unit tests with simulated tests to build and validate code automatically. We discuss the current technology readiness and list the potential new application scenarios that are becoming available. Finally, we discuss the current challenges in distributed robotic systems and list open research questions in the field.},
  keywords={Multi-access edge computing;Federated learning;Pipelines;Computer architecture;Reinforcement learning;Market research;Robot learning;Robotics;Distributed Robotic Systems;Edge-Cloud Continuum;Cloud robotics;Edge computing;ROS 2;Containerization;Computational offloading},
  doi={10.1109/FMEC57183.2022.10062523},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10062849,
  author={Stavrinides, Georgios L. and Karatza, Helen D.},
  booktitle={2022 Seventh International Conference on Fog and Mobile Edge Computing (FMEC)}, 
  title={Resource Allocation and Scheduling of Real-Time Workflow Applications in an IoT-Fog-Cloud Environment}, 
  year={2022},
  volume={},
  number={},
  pages={1-8},
  abstract={The explosive growth of the Internet of Things (IoT) has led to the emergence of the IoT-fog-cloud continuum, in an attempt to facilitate the real-time processing of IoT data. In such multi-tier environments, it is crucial to adopt an efficient resource allocation and scheduling scheme, in order to provide effective load balancing and timeliness for the real-time workload. A load balancing approach that has been proven to be efficient and effective in traditional distributed environments, is the power of two choices – or $d$ choices, in its general form. Only recently has this technique been examined in multi-tier environments, without considering, however, important aspects of such frameworks. To this end, in this paper we propose and investigate three resource allocation and scheduling heuristics for real-time workflow jobs in an IoT-fog-cloud environment. The first strategy, performs exhaustive search at each scheduling step in order to find the most suitable resource in the fog and cloud layers for the workload assignment. On the other hand, the two other policies adopt the power of two choices approach. The simulation results shed light on interesting insights regarding the performance and applicability of each method.},
  keywords={Cloud computing;Multi-access edge computing;Processor scheduling;Simulation;Load management;Real-time systems;Explosives;power of two choices;resource allocation;scheduling;fog computing;cloud computing;real-time workflows},
  doi={10.1109/FMEC57183.2022.10062849},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10063372,
  author={Nastic, Stefan and Raith, Philipp and Furutanpey, Alireza and Pusztai, Thomas and Dustdar, Schahram},
  booktitle={2022 IEEE 4th International Conference on Cognitive Machine Intelligence (CogMI)}, 
  title={A Serverless Computing Fabric for Edge & Cloud}, 
  year={2022},
  volume={},
  number={},
  pages={1-12},
  abstract={Serverless computing has been establishing itself as a compelling paradigm for the development and of modern cloud-native applications. Serverless represents the next step in the evolution of cloud programming models, services and platforms, which is especially appealing due to its low management overhead, easy deployment, scale-to-zero and the promise of optimized costs. Recently, due to the advantages it offers, the serverless paradigm has been growing beyond traditional clouds, making its way to the Edge. The natural evolutionary step for serverless computing is to unify the Edge and the Cloud into what we refer to as Edge-Cloud Continuum. In this paper, we outline our vision of the Serverless Computing Fabric (SCF) for the Edge-Cloud continuum. We introduce the reference architecture for the SCF and show how it unlocks the full potential of the Edge-Cloud continuum. We also discuss main opportunities and challenges, which need to be overcome in order to achieve the vision of the Serverless Computing Fabric. Finally, we introduce key design principles together with core enabling runtime mechanisms, which are intended to serve as a research road map towards the Serverless Computing Fabric for Edge-Cloud continuum.},
  keywords={Runtime;Costs;Roads;Serverless computing;Computer architecture;Programming;Reliability engineering;Serverless Computing;Cloud Computing;Edge Computing;Reliability Engineering;Service Level Objectives},
  doi={10.1109/CogMI56440.2022.00011},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10051062,
  author={Tsolkas, Dimitris and Charsmiadis, Anastastios-Stavros and Xenakis, Dionysis and Merakos, Lazaros},
  booktitle={2022 IEEE Conference on Standards for Communications and Networking (CSCN)}, 
  title={Service and network function placement in the edge-cloud continuum}, 
  year={2022},
  volume={},
  number={},
  pages={188-193},
  abstract={The virtualization and containerization technologies have paved the way towards a flexible and fully programmable service provisioning chain over mobile telecommunication infrastructures. On top of those technologies the network slicing concept has emerged; a concept that enables the installation and migration of service and network functions on a compute fabric that spans from the central cloud to distributed far-edge hosts. In this context, the efficient placement of service and network functions in the hosts of the continuum is an open and challenging problem. We formulate this problem as a scheduling process and we analyze its optimal performance through the integer linear programming toolkit. The study revealed interesting insights regarding the impact of sequence constraints (i.e., some functions should be allocated according to a specific order) and host-continuity constraints (i.e., some functions should be allocated in the same cloud host with others) to the overall efficiency of the scheduling.},
  keywords={Knowledge engineering;Cloud computing;Processor scheduling;Network slicing;Integer linear programming;Linear programming;Fabrics;Network function placement;Network slicing;edge-cloud continuum;Integer linear programming},
  doi={10.1109/CSCN57023.2022.10051062},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10000936,
  author={Ali, Soukaina Ouledsidi and Elbiaze, Halima and Glitho, Roch and Ajib, Wessam},
  booktitle={GLOBECOM 2022 - 2022 IEEE Global Communications Conference}, 
  title={CaMP-INC: Components-aware Microservices Placement for In-Network Computing Cloud-Edge Continuum}, 
  year={2022},
  volume={},
  number={},
  pages={2116-2121},
  abstract={Microservices are a promising technology for future networks, and many research efforts have been devoted to optimally placing microservices in cloud data centers. However, microservices deployment in edge and in-network devices is more expensive than the cloud. Additionally, several works do not consider the main requirements of microservice architecture, such as service registry, failure detection, and each microservice's specific database. This paper investigates the problem of placing components (i.e. microservices and their corresponding databases) while considering physical nodes' failure and the distance to service registries. We propose a Components-aware Microservices Placement for In-Network Computing Cloud-Edge Continuum (CaMP-INC). We formulate an Integer Linear Programming (ILP) problem with the objective of cost minimization. Due to the problem's $\mathcal{NP}$-hardness, we propose a heuristic solution. Numerical results demonstrate that our proposed solution CaMP-INC reduces the total cost by 15.8% on average and has a superior performance in terms of latency minimization compared to benchmarks.},
  keywords={Costs;Databases;Image edge detection;Microservice architectures;Computer architecture;Integer linear programming;Minimization;Microservices placement;Microservice architecture;In-Network Computing;Cloud-Edge Continuum},
  doi={10.1109/GLOBECOM48099.2022.10000936},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{9983733,
  author={Kjorveziroski, Vojdan and Filiposka, Sonja and Mishev, Anastas},
  booktitle={2022 30th Telecommunications Forum (TELFOR)}, 
  title={Evaluating WebAssembly for Orchestrated Deployment of Serverless Functions}, 
  year={2022},
  volume={},
  number={},
  pages={1-4},
  abstract={Serverless computing has made a significant impact in the cloud computing landscape, and has even been extended beyond the cloud, up to the edge of the network. Existing serverless platforms which use containers and micro virtual machines as function runtimes incur a significant startup latency, hindering the performance and scalability of the executed functions. One potential solution to this problem is the use of WebAssembly. In this paper we discuss recent developments which allow WebAssembly to be used for serverside applications, as well as serverless functions, and evaluate potential orchestration options with the end goal of integrating WebAssembly with existing cloud and edge infrastructure. We conclude that while WebAssembly is a solution to the cold start problem, further work is needed in this area. To realize the endgoal of seamless and user-friendly serverless platforms that can be deployed across the edge-cloud continuum and can dynamically adapt to compute and latency requirements, WebAssembly should not be seen as the exclusive technology, and instead multiple runtime environments should be supported in addition to WebAssembly.},
  keywords={Runtime environment;Scalability;Serverless computing;Containers;Virtual machining;Telecommunications;WebAssembly;serverless computing;function as a service;cloud computing;edge computing;internet of things},
  doi={10.1109/TELFOR56187.2022.9983733},
  ISSN={},
  month={Nov},}@ARTICLE{9984641,
  author={Moreschini, Sergio and Pecorelli, Fabiano and Li, Xiaozhou and Naz, Sonia and Hästbacka, David and Taibi, Davide},
  journal={IEEE Access}, 
  title={Cloud Continuum: The Definition}, 
  year={2022},
  volume={10},
  number={},
  pages={131876-131886},
  abstract={The cloud continuum concept has drawn increasing attention from practitioners, academics, and funding agencies and been adopted progressively. However, the concept remains mired in various definitions with different studies providing contrasting descriptions. Therefore, to understand the concept of cloud continuum and to provide its definition, in this work we conduct a systematic mapping study of the literature investigating the different definitions, how they evolved, and where does the cloud continue. The main outcome of this work is a complete definition that merges all the common aspects of cloud continuum, which enables practitioners and researchers to better understand what cloud continuum is.},
  keywords={Cloud computing;Resource management;Edge computing;Data mining;Edge computing;Systematics;Cloud continuum;edge;Fog},
  doi={10.1109/ACCESS.2022.3229185},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{9927824,
  author={Marozzo, Fabrizio and Orsino, Alessio and Talia, Domenico and Trunfio, Paolo},
  booktitle={2022 IEEE Intl Conf on Dependable, Autonomic and Secure Computing, Intl Conf on Pervasive Intelligence and Computing, Intl Conf on Cloud and Big Data Computing, Intl Conf on Cyber Science and Technology Congress (DASC/PiCom/CBDCom/CyberSciTech)}, 
  title={Edge Computing Solutions for Distributed Machine Learning}, 
  year={2022},
  volume={},
  number={},
  pages={1-8},
  abstract={The rapid spread of the Internet of Things (IoT), with billions of connected devices, has generated huge amounts of data and asks for decentralized solutions for machine learning. However, performing complex learning tasks at the edge of the network is posing great challenges in terms of efficient management of data storing, transfer, and analysis. For these reasons, a lot of research and development effort is devoted to adapt different machine learning algorithms so that cooperative training and inference on local data occur directly at the edge of the network. This scenario represents a major challenge today due to the limited capacities of edge devices, the different technologies with which these devices work and communicate, and the lack of common software stacks to easily manage them. In this paper, we analyze distributed machine learning algorithms and how they should be adapted to run at the network edge and, if needed, cooperate with the cloud to ensure low latency, energy savings, privacy preserving and scalability. In particular, we briefly discuss how the main machine learning algorithms have been adapted to work in traditional distributed platforms (such as clusters, clouds, and HPC systems) and the main research work that has led these algorithms to run on resource-constrained edge devices. Then, a layered approach is introduced and discussed for adapting machine learning algorithms on edge-cloud architectures. Finally, we conclude the paper by describing some application scenarios that can benefit from this approach.},
  keywords={Performance evaluation;Training;Cloud computing;Machine learning algorithms;Machine learning;Big Data;Internet of Things;Machine learning;distributed machine learning;Internet of Things;edge computing;cloud computing;edge-cloud continuum},
  doi={10.1109/DASC/PiCom/CBDCom/Cy55231.2022.9927824},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{9927883,
  author={Carnevale, Lorenzo and Ortis, Alessandro and Fortino, Giancarlo and Battiato, Sebastiano and Villari, Massimo},
  booktitle={2022 IEEE Intl Conf on Dependable, Autonomic and Secure Computing, Intl Conf on Pervasive Intelligence and Computing, Intl Conf on Cloud and Big Data Computing, Intl Conf on Cyber Science and Technology Congress (DASC/PiCom/CBDCom/CyberSciTech)}, 
  title={From Cloud-Edge to Edge-Edge Continuum: the Swarm-Based Edge Computing Systems}, 
  year={2022},
  volume={},
  number={},
  pages={1-6},
  abstract={Modern cloud-edge-device computational platforms does not match the needs of artificial intelligence at the edge of the network. Indeed, the lack of computing power allows that only some AI processes can be performed on edge devices, having also to consider their constrained energy capacity. Moreover, the lack of computing continuum between nodes of the same layer, i.e., edge-to-edge, allows to only operate independently within the layer by sensing the environment where nodes stay. In this paper, we propose a lightweight framework for collaborative nodes with decentralized edge intelligence. Organized like a swarm, the groups of nodes emphasize the edge-to-edge continuum of the device-edge-cloud paradigm. This supports a paradigm shift from programming environments for individual devices to dynamic and cooperating groups of nodes. The nodes’ coordination relays on green overlay and offloading mechanisms. Innovative mesh architectures with mixed topologies allow building overlays for having swarm coordination. Tasks offloading exploits the overlays to balance the swarm in near-real-time, according to forecasted energy consumption. Stemming from the proposed reference architecture, we also discuss a series of open challenges, which we believe represent relevant research directions in the nearest future.},
  keywords={Shape;Architecture;Computer architecture;Topology;Sensors;Artificial intelligence;Task analysis;Cloud-Edge Continuum;Swarm Computing;Distributed Intelligence;Offloading;Overlay Network;Energy-Aware},
  doi={10.1109/DASC/PiCom/CBDCom/Cy55231.2022.9927883},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{9927926,
  author={Sicari, Christian and Carnevale, Lorenzo and Galletta, Antonino and Villari, Massimo},
  booktitle={2022 IEEE Intl Conf on Dependable, Autonomic and Secure Computing, Intl Conf on Pervasive Intelligence and Computing, Intl Conf on Cloud and Big Data Computing, Intl Conf on Cyber Science and Technology Congress (DASC/PiCom/CBDCom/CyberSciTech)}, 
  title={OpenWolf: A Serverless Workflow Engine for Native Cloud-Edge Continuum}, 
  year={2022},
  volume={},
  number={},
  pages={1-8},
  abstract={Nowadays, Serverless computing is emerging as one of the most used Cloud services. In particular, the Function as Service (FaaS) is bringing to Cloud consumers, developers, and devops many advantages in terms of service costs, speed of development, and ease of deployment. In fact, it stands to be a key technology for enabling the Cloud-Edge Continuum. Regardless of these features, it is still not possible to build FaaS native applications without a Cloud broker that coordinates the functions. Therefore, FaaS usage is limited to very simple and specific jobs. In this work, we brush up on the concept of Scientific Workflow using the FaaS paradigm, in order to realize full Native Serverless Workflows-based applications. We define a custom Workflow Manifest DSL used to describe function interactions, then we describe the implementation of an agent able to deploy architecture-independent functions and coordinate them according to the Manifest. Finally, federating the Cloud-Fog-Edge tiers in a single Continuum environment, we allow functions to take advantage of the Continuum tier’s characteristics where they are deployed. This project is called OpenWolf, it’s repository is published on GitHub, under GNU General Public License v3.0.},
  keywords={Costs;Brushes;Serverless computing;Licenses;Big Data;DSL;Engines;Workflow;Serverless;Cloud-Edge Continuum;FaaS Composition;FaaS},
  doi={10.1109/DASC/PiCom/CBDCom/Cy55231.2022.9927926},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{9927899,
  author={Penzotti, Gabriele and Tarasconi, Davide and Caselli, Stefano and Amoretti, Michele},
  booktitle={2022 IEEE Intl Conf on Dependable, Autonomic and Secure Computing, Intl Conf on Pervasive Intelligence and Computing, Intl Conf on Cloud and Big Data Computing, Intl Conf on Cyber Science and Technology Congress (DASC/PiCom/CBDCom/CyberSciTech)}, 
  title={Seamless Sensor Data Acquisition for the Edge-to-Cloud Continuum}, 
  year={2022},
  volume={},
  number={},
  pages={1-8},
  abstract={Modern computing is a continuum that runs from individual terminals and specialized embedded devices to the Cloud, passing through gateways and edge/fog computing nodes.A major challenge is the integration with the Internet of Things (IoT), especially with respect to sensor data acquisition, in an edge-to-cloud perspective. Despite novel approaches leveraging widely accepted standards have emerged for representing IoT objects and data, effective application-layer protocols for sensor data acquisition along the path from the edge to the cloud are missing. In this work, we propose SEAMDAP, an application-layer protocol enabling seamless sensor data acquisition for the edge-to-cloud continuum, based on standards for entity representations. We report the quantitative evaluation of a SEAMDAP-based system implementation, comprising an edge node and different IoT systems. The system was deployed in 2020 and thereafter has been supporting scalable sensor/satellite-driven services for wide-area Smart Farming applications.},
  keywords={Smart agriculture;Cloud computing;Protocols;Federated learning;Data acquisition;Logic gates;Internet of Things;Edge-to-Cloud;IoT;Sensor Data Acquisition;SenML;Thing Description},
  doi={10.1109/DASC/PiCom/CBDCom/Cy55231.2022.9927899},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{9973109,
  author={Nguyen, Tuan Anh and Min, Dugki and Choi, Eunmi and Fe, Iure and Silva, Francisco Airton},
  booktitle={2022 IEEE Cloud Summit}, 
  title={Survivability and Resiliency Modeling and Analysis of an Internet of Industrial Things using Hierarchical Models}, 
  year={2022},
  volume={},
  number={},
  pages={118-123},
  abstract={In Industry 4.0, the emergence of the Internet of industrial things (IoIT) has been a mainstream computing infrastructure for smart factories. However, IoITs show a multitude of inherent weaknesses which may restrict IoITs from fulfilling implementation expectations due to the con-figuration of the Cloud-Edge continuum. Under the needs of high-level production chain business continuity, an IoIT may be influenced by parametric or structural changes on one hand, but the system may also fail on the other. These possible events may be quantified using two metrics: survivability and resilience. This work proposes to model and evaluate a specific IoIT for survivability and resiliency quantification using a hierarchical model. The system model consists of three layers: (i) reliability block diagram (RBD) at the top level to capture the overall IoIT architecture, (ii) fault tree (FT) at the middle level to capture the configurations of subsystems, and (iii) continuous-time Markov chain (CTMC) models at the bottom level to represent the operational states of the underlying components and devices. The study can assist system managers in ensuring the maximum level of survivability and resiliency of industrial processes in smart factories by preserving operating circumstances and system configurations.},
  keywords={Measurement;Analytical models;Cloud computing;Production;Markov processes;Reliability engineering;Data models;Internet of Industrial Things;Network Survivability;Resiliency;Hierarchical Models},
  doi={10.1109/CloudSummit54781.2022.00024},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{9952940,
  author={Kim, Taeyun and Oh, Seoyul and Cha, Inho and Lee, Seunghyun and Ko, Haneul and Pack, Sangheon and Han, Jinyoung},
  booktitle={2022 13th International Conference on Information and Communication Technology Convergence (ICTC)}, 
  title={Holistic Orchestration for Edge-Native Applications: A Review}, 
  year={2022},
  volume={},
  number={},
  pages={771-774},
  abstract={Edge computing supports a wide variety of low latency applications by bringing the capabilities of the cloud close to the end-user. Due to the properties of edge computing, such as limited coverage, it is crucial to develop edge-native technologies based on the edge-cloud continuum rather than on-premise technologies assuming edge standalone environments. In this article, we review standardization activities and survey software platforms for edge-native. We also identify open issues for orchestration technologies of edge-native.},
  keywords={Market research;Software;Information and communication technology;Security;Resource management;Low latency communication;Standards;Edge-native;Edge computing;Edge orchestration},
  doi={10.1109/ICTC55196.2022.9952940},
  ISSN={2162-1241},
  month={Oct},}@ARTICLE{9950755,
  author={Verhelst, Marian and Shi, Man and Mei, Linyan},
  journal={IEEE Solid-State Circuits Magazine}, 
  title={ML Processors Are Going Multi-Core: A performance dream or a scheduling nightmare?}, 
  year={2022},
  volume={14},
  number={4},
  pages={18-27},
  abstract={Applications of machine learning (ML) increasingly penetrate into our daily routines, our work, and our living environments. In this way, more complex machine intelligence algorithms fundamentally change and enhance the way we live, work, and interact. However, the real-time deployment of these algorithms toward the dreams of smart spaces, digital twins, the metaverse, or personalized health care requires a powerful compute continuum from cloud to (extreme) edge, capable of efficiently executing the compute-hungry ML workloads, such as deep neural networks (NNs). To enable the required real-time responsiveness at affordable energy or power budgets, many ML-optimized custom processors (also called accelerators) have been presented over the past decade, as depicted in Figure 1.},
  keywords={Machine learning;Real-time systems;Smart spaces;Program processors;Metaverse;Medical services;Digital twins;Deep learning;Artificial neural networks},
  doi={10.1109/MSSC.2022.3201783},
  ISSN={1943-0590},
  month={Fall},}@ARTICLE{9945851,
  author={Bacchiani, Lorenzo and De Palma, Giuseppe and Sciullo, Luca and Bravetti, Mario and Di Felice, Marco and Gabbrielli, Maurizio and Zavattaro, Gianluigi and Della Penna, Roberto},
  journal={IEEE Internet of Things Magazine}, 
  title={Low-Latency Anomaly Detection on the Edge-Cloud Continuum for Industry 4.0 Applications: the SEAWALL Case Study}, 
  year={2022},
  volume={5},
  number={3},
  pages={32-37},
  abstract={Several emerging Industry 4.0 applications related to the monitoring and fault diagnostic of critical equipment introduce strict bounds on the latency of the data processing. Edge computing has emerged as a viable approach to mitigate the latency by offloading tasks to nodes nearby the data sources; at the same time, few industrial case studies have been reported so far. In this paper, we describe the design, implementation and evaluation of the SEAWALL platform for the heterogeneous data acquisition and low-latency processing in Industry 4.0 scenarios. The framework has been developed within the homonymous project founded by the Italian BIREX industrial consortium and involving both academic and industrial partners. The proposed framework supports data collection from heterogeneous production line machines mapped to different IoT protocols. In addition, it enables the seamless orchestration of workloads in the edge-cloud continuum so that the latency of the alerting service is minimized requirement of the processing task is continuously met, while taking into account the constrained resources of the edge servers. We evaluate the SEAWALL framework in a small-case industrial testbed and quantify the performance gain provided by the dynamic workload allocation on the continuum.},
  keywords={Protocols;Image edge detection;Soft sensors;Production;Performance gain;Fourth Industrial Revolution;Servers},
  doi={10.1109/IOTM.001.2200120},
  ISSN={2576-3199},
  month={Sep.},}@INPROCEEDINGS{9936953,
  author={Kalinagac, Onur and Gür, Gürkan and Alagöz, Fatih},
  booktitle={2022 Global Information Infrastructure and Networking Symposium (GIIS)}, 
  title={Priority-Driven Task Processing in UAV-Assisted Software-Defined Edge Networks}, 
  year={2022},
  volume={},
  number={},
  pages={78-84},
  abstract={For providing wireless connectivity and facilitating a capacity boost under transient high service load situations a substitute or auxiliary fast-deployable network is instrumental. Unmanned Aerial Vehicle (UAV) networks are well suited for such needs owing to their high mobility and agility. This paper considers a software-defined edge network consisting of UAVs equipped with wireless access points which serve mobile users with latency-sensitive workload in an edge-to-cloud continuum setting. It investigates the task offloading paradigm to provide prioritized services via this on-demand aerial network. Accordingly a task processing optimization model is defined to minimize the overall penalty calculated based on priority-weighted delay values against a priori defined task deadlines. Since the defined assignment problem is NP-hard tailored heuristic models are proposed and evaluated to study how the system performs under different operating conditions},
  keywords={Instruments;Emulation;Wireless access points;Routing;Autonomous aerial vehicles;Mathematical models;Delays},
  doi={10.1109/GIIS56506.2022.9936953},
  ISSN={2150-329X},
  month={Sep.},}@INPROCEEDINGS{9922561,
  author={Souza, Arthur and Cacho, Nélio and Batista, Thais},
  booktitle={2022 IEEE International Smart Cities Conference (ISC2)}, 
  title={Fogmotic: Applying Osmotic Data Services to improve Database Operations on SmartCity Environments}, 
  year={2022},
  volume={},
  number={},
  pages={1-7},
  abstract={The increase in the computing capabilities of Edge devices made it possible to distribute the processing contracted in the Cloud, leveraging the emergence of Edge Computing and Fog Computing. Fog's improved processing of data obtained by Edge quickly progressed from simple cleaning and categorization to more refined and contextually related information. Thus, there is a growing need for persistent storage at the Fog/Edge level, especially in facing the scenarios present in Osmotic Computing. With this context in mind, our work presents a solution for data persistence between the various levels of Edge/Fog/Cloud. Going further, we introduce Fogmotic, a Database as a Service platform that focuses on distribution, synchronization, reliability, efficiency, and data migration at the Edge/Fog/Cloud levels. Finally, we present an experimental evaluation of the reading, writing, and sync rate performance obtained by Fogmotic.},
  keywords={Databases;Smart cities;Computational modeling;Memory;Writing;Containers;Data models;Data Distribution;Fog Computing;Osmotic Computing},
  doi={10.1109/ISC255366.2022.9922561},
  ISSN={2687-8860},
  month={Sep.},}@INPROCEEDINGS{9912640,
  author={Donta, Praveen Kumar and Dustdar, Schahram},
  booktitle={2022 IEEE International Conference on Service-Oriented System Engineering (SOSE)}, 
  title={The Promising Role of Representation Learning for Distributed Computing Continuum Systems}, 
  year={2022},
  volume={},
  number={},
  pages={126-132},
  abstract={The distributed computing continuum systems (DCCS) and representation learning (ReL) are two diverse computer science technologies with their use cases, applications, and benefits. The DCCS helps increase flexibility with improved performance of hybrid IoT-Edge-Cloud infrastructures. In contrast, representation learning extracts the features (meaningful information) and underlying explanatory factors from the given datasets. With these benefits, using ReL for DCCS to improve its performance by monitoring the devices will increase the utilization efficiency, zero downtime, etc. In this context, this paper discusses the promising role of ReL for DCCS in terms of different aspects, including device condition monitoring, predictions, management of the systems, etc. This paper also provides a list of ReL algorithms and their pitfalls which helps DCCS by considering various constraints. In addition, this paper list different challenges imposed on ReL to analyze DCCS data. It also provides future research directions to make the systems autonomous, performing multiple tasks simultaneously with the help of other AI/ML approaches.},
  keywords={Representation learning;Performance evaluation;Service-oriented systems engineering;Prediction algorithms;Feature extraction;Data mining;Distributed computing;Representation learning;Distributed systems;Compute continuum;Causal inference},
  doi={10.1109/SOSE55356.2022.00021},
  ISSN={2642-6587},
  month={Aug},}@INPROCEEDINGS{9912267,
  author={Rosa, Lorenzo and Garbugli, Andrea},
  booktitle={2022 IEEE 42nd International Conference on Distributed Computing Systems (ICDCS)}, 
  title={Poster: INSANE – A Uniform Middleware API for Differentiated Quality using Heterogeneous Acceleration Techniques at the Network Edge}, 
  year={2022},
  volume={},
  number={},
  pages={1282-1283},
  abstract={Next-generation AI applications benefit from executing close to the network edge to better exploit co-locality to datasources and controlled actuators, and to meet stringent latency requirements. In the edge-enabled cloud continuum, time and safety-critical traffic coexists with best-effort flows, resulting in heterogeneous requirements that current networking middleware and frameworks struggle to support. This paper proposes INSANE, INtegrated Selective Acceleration at the Network Edge, the first edge-oriented middleware that integrates different network acceleration techniques (XDP, DPDK, RDMA, and TSN) within the same data distribution service. INSANE offers a uniform and simple interface, useful to support common data distribution patterns, that allow developers to exploit at runtime the most suitable network technology available in the dynamically determined deployment environment.},
  keywords={Actuators;Runtime;Middleware;Distributed computing;Artificial intelligence;Next generation networking;edge computing;data distribution;network acceleration;kernel-bypassing;TSN;RDMA;DPDK;XDP},
  doi={10.1109/ICDCS54860.2022.00134},
  ISSN={2575-8411},
  month={July},}@INPROCEEDINGS{9910499,
  author={Catalfamo, Alessio and Celesti, Antonio and Fazio, Maria and Villari, Massimo},
  booktitle={2022 9th International Conference on Future Internet of Things and Cloud (FiCloud)}, 
  title={A Homomorphic Encryption Service to Secure Data Processing in a Cloud/Edge Continuum Context}, 
  year={2022},
  volume={},
  number={},
  pages={55-61},
  abstract={For years, one of the major issues against the adoption of Cloud computing has been security. Typically, with traditional symmetric and asymmetric encryption schemes, data can be encrypted and sent into Cloud data centers, but this approach presents a great weakness: data must be transferred to the client-side to be deciphered and then processed. Nevertheless, such an approach is not feasible for a large amount of data. In this paper, we address such an issue through the adoption of homomorphic encryption in a Cloud/Edge continuum environment. Specifically, pieces of data are encrypted in the Edge and transferred into the Cloud for storage and processing without the need to decode them. Experiments performed on different homomorphic encryption schemes in a Cloud/Edge testbed highlight the goodness of our approach.},
  keywords={Cloud computing;Data centers;Data processing;Internet of Things;Homomorphic encryption;Cloud computing;Edge computing;security;homomorphic encryption},
  doi={10.1109/FiCloud57274.2022.00015},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{9885760,
  author={De Palma, Giuseppe and Giallorenzo, Saverio and Mauro, Jacopo and Trentin, Matteo and Zavattaro, Gianluigi},
  booktitle={2022 IEEE International Conference on Web Services (ICWS)}, 
  title={A Declarative Approach to Topology-Aware Serverless Function-Execution Scheduling}, 
  year={2022},
  volume={},
  number={},
  pages={337-342},
  abstract={State-of-the-art serverless platforms use hard-coded scheduling policies that are unaware of the possible topological constraints of functions. Considering these constraints when scheduling functions leads to sensible performance improvements, e.g., minimising loading times or data-access latencies. This issue becomes more pressing when considered in the emerging multi-cloud and edge-cloud-continuum systems, where only specific nodes can access specialised, local resources. To address this problem, we present a declarative language for defining serverless scheduling policies to express constraints on topologies of schedulers and execution nodes. We implement our approach as an extension of the OpenWhisk platform.},
  keywords={Web services;Semantics;Loading;Prototypes;Pressing;Writing;Topology;Serverless;Function Execution Scheduling;Topology aware;Optimisation},
  doi={10.1109/ICWS55610.2022.00056},
  ISSN={},
  month={July},}@INPROCEEDINGS{9872789,
  author={Tzanis, Nikolaos and Brodimas, Dimitrios and Plakas, Konstantinos and Birbas, Michael and Birbas, Alexios},
  booktitle={2022 International Conference on Electrical, Computer and Energy Technologies (ICECET)}, 
  title={Optimal Relocation of Virtualized PDC in Edge-Cloud Architectures under Dynamic Latency Conditions}, 
  year={2022},
  volume={},
  number={},
  pages={1-6},
  abstract={The increasing penetration of Phasor Measurement Units (PMUs) in the power grid, combined with the advancements in the communication technologies and the cloud-edge continuum, enable the deployment of sophisticated and demanding synchrophasor-based applications. In synchrophasor networks, Phasor Data Concentrators (PDCs) are responsible for the collection, aggregation and time synchronization of PMU datasets and their transmission to the target applications according to specific latency constraints. PMU to PDC latency will be continuously impacted by the deployment of new applications, prone to violations of network related key performance indicators (KPIs). In this work, we present a cloud-edge architecture, which facilitates the continuous monitoring of the target application’s performance (Level of measurements Completeness - LoC) and provides an optimal PDC relocation solution through a binary integer linear programming algorithm. PDC relocation becomes feasible by the monitoring of the communication latency at points of interest and by the employment of virtual PDC instances at various nodes.},
  keywords={Wireless communication;Cloud computing;Power system dynamics;Computer architecture;Phasor measurement units;Power grids;Synchronization;synchrophasor networks;edge-cloud computing;optimization of PDC placement;Network Function Virtualization},
  doi={10.1109/ICECET55527.2022.9872789},
  ISSN={},
  month={July},}@ARTICLE{9878326,
  author={Bhutto, Adil Bin and Vu, Xuan Son and Elmroth, Erik and Tay, Wee Peng and Bhuyan, Monowar},
  journal={IEEE Access}, 
  title={Reinforced Transformer Learning for VSI-DDoS Detection in Edge Clouds}, 
  year={2022},
  volume={10},
  number={},
  pages={94677-94690},
  abstract={Edge-driven software applications often deployed as online services in the cloud-to-edge continuum lack significant protection for services and infrastructures against emerging cyberattacks. Very-Short Intermittent Distributed Denial of Service (VSI-DDoS) attack is one of the biggest factors for diminishing the Quality of Services (QoS) and Quality of Experiences (QoE) for users on edge. Unlike conventional DDoS attacks, these attacks live for a very short time (on the order of a few milliseconds) in the traffic to deceive users with a legitimate service experience. To provide protection, we propose a novel and efficient approach for detecting VSI-DDoS attacks using reinforced transformer learning that mitigates the tail latency and service availability problems in edge clouds. In the presence of attacks, the users’ demand for availing ultra-low latency and high throughput services deployed on the edge, can never be met. Moreover, these attacks send very-short intermittent requests towards the target services that enforce longer delays in users’ responses. The assimilation of transformer with deep reinforcement learning accelerates detection performance under adverse conditions by adapting the dynamic and the most discernible patterns of attacks (e.g., multiplicative temporal dependency, attack dynamism). The extensive experiments with testbed and benchmark datasets demonstrate that the proposed approach is suitable, effective, and efficient for detecting VSI-DDoS attacks in edge clouds. The results outperform state-of-the-art methods with  $0.9\%-3.2\%$  higher accuracy in both datasets.},
  keywords={Transformers;Image edge detection;Quality of service;Denial-of-service attack;Cloud computing;Computer crime;Throughput;Reinforcement learning;Reinforced transformer learning;VSI-DDoS;edge clouds;QoS/QoE;cloud applications},
  doi={10.1109/ACCESS.2022.3204812},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{9868927,
  author={Barsellotti, Luca and Alhamed, Faris and Vegas Olmos, Juan Jose and Paolucci, Francesco and Castoldi, Piero and Cugini, Filippo},
  booktitle={2022 International Conference on Computer Communications and Networks (ICCCN)}, 
  title={Introducing Data Processing Units (DPU) at the Edge [Invited]}, 
  year={2022},
  volume={},
  number={},
  pages={1-6},
  abstract={The recent availability of smart network interface cards (smart NICs) and Data Processing units (DPUs) providing hardware-accelerated networking and computing functionalities is opening the way towards new applications and use cases beyond the traditional data center scenarios. In this paper, three different use cases for edge scenarios that leverage on the innovative programmability enabled by DPUs are presented and discussed. The first use case focuses on a pervasive monitoring infrastructure to support accurate and decentralized network awareness for low-latency 5G services. The second one focuses on the implementation of power-efficient edge-to-cloud continuum. The third use case refers to effective network security functions at the DPU.},
  keywords={5G mobile communication;Computational modeling;Image edge detection;Network intrusion detection;Network security;Data processing;Fabrics;P4;smart NIC;in-network functions;DPU;telemetry;security;programmability;programmable data plane},
  doi={10.1109/ICCCN54977.2022.9868927},
  ISSN={2637-9430},
  month={July},}@INPROCEEDINGS{9860303,
  author={Karlstetter, Roman and Widhopf-Fenk, Robert and Schulz, Martin},
  booktitle={2022 IEEE International Conference on Edge Computing and Communications (EDGE)}, 
  title={Querying Distributed Sensor Streams in the Edge-to-Cloud Continuum}, 
  year={2022},
  volume={},
  number={},
  pages={192-197},
  abstract={Sensor data is of crucial importance in many IoT scenarios. It is used for online monitoring as well as long term data analytics, enabling countless use cases from damage prevention to predictive maintenance. Multivariate sensor time series data is acquired and initially stored close to the sensor, at the edge. It is also beneficial to summarize this data in windowed aggregations at different resolutions. A subset of the resulting aggregation hierarchy is typically sent to a cloud infrastructure, often via intermittent or low bandwidth connections. Consequently, different views on the data exist on different nodes in the edge-to-cloud continuum. However, when querying this data, users are interested in a fast response and a complete, unified view on the data, regardless of which part in the infrastructure continuum they send the query to and where the data is physically stored. In this paper, we present a loosely coupled approach that enables fast range queries on a distributed and hierarchical sensor database. Our system only assumes the possibility of fast local range queries on a hierarchical sensor database. It does not require any shared state between nodes and thus degrades gracefully in case certain parts of the hierarchy are unreachable. We show that our system is suitable for driving interactive data exploration sessions on terabytes of data while unifying the different views on the data. Thus, our system can improve the data analysis experience in many geo-distributed scenarios.},
  keywords={Cloud computing;Data analysis;Time series analysis;Distributed databases;Memory;Bandwidth;Data communication;edge;cloud;multivariate sensor data stream;distributed query},
  doi={10.1109/EDGE55608.2022.00035},
  ISSN={2767-9918},
  month={July},}@INPROCEEDINGS{9860835,
  author={Sheshadri, K R and Lakshmi, J},
  booktitle={2022 IEEE 15th International Conference on Cloud Computing (CLOUD)}, 
  title={QoS aware FaaS for Heterogeneous Edge-Cloud continuum}, 
  year={2022},
  volume={},
  number={},
  pages={70-80},
  abstract={Function as a Service (FaaS) is one of the widely used serverless computing service offerings to build and deploy applications on the Cloud. The platform is popular for its "pay-as-you-go" billing model, microservice-based design, event-driven executions, and autonomous scaling. Although it has its firm roots in Cloud computing service offerings, it is considerably explored in the Edge computing layer. The efficient resource management of FaaS is attractive to Edge computing because of the limited nature of resources. Existing literature on Edge-Cloud FaaS platforms orchestrates compute workloads based on factors such as data locality, resource availability, network costs, and bandwidth. However, the state-of-the-art platforms lack a comprehensive way to address the challenges of managing heterogeneous resources in the FaaS platform. The resource specification in a heterogeneous setting, lack of Quality of Service (QoS) driven resource provisioning, and function deployment exacerbate the problem of resource selection, and function deployment in FaaS platforms with a heterogeneous resource pool. To address these gaps, the current work presents a novel heterogeneous FaaS platform that deduces function resource specification using Machine Learning (ML) methods, performs smart function placement on Edge/Cloud based on a user-specified QoS requirement, and exploit data locality by caching appropriate data for function executions. Experimental results based on real-world workloads on a video surveillance application show that the proposed platform brings efficient resource utilization and cost savings at the Cloud by reducing the resource usage by up to 30%, while improving the performance of function executions by up to 25% at Edge and Cloud.},
  keywords={Cloud computing;Costs;Computational modeling;Serverless computing;Microservice architectures;FAA;Quality of service;FaaS;Function as a Service;serverless computing;Quality of Service;QoS;Edge Cloud;Edge Cloud FaaS;Edge Cloud continuum;Heterogeneous FaaS platforms;Heterogeneous Edge Cloud platforms;QoS aware FaaS for Heterogeneous Edge Cloud continuum},
  doi={10.1109/CLOUD55607.2022.00023},
  ISSN={2159-6190},
  month={July},}@INPROCEEDINGS{9860391,
  author={Liu, Hongyun and Xin, Ruyue and Chen, Peng and Zhao, Zhiming},
  booktitle={2022 IEEE 15th International Conference on Cloud Computing (CLOUD)}, 
  title={Multi-Objective Robust Workflow Offloading in Edge-to-Cloud Continuum}, 
  year={2022},
  volume={},
  number={},
  pages={469-478},
  abstract={Workflow offloading in the edge-to-cloud continuum copes with an extended calculation network among edge devices and cloud platforms. With the growing significance of edge and cloud technologies, workflow offloading among these environments has been investigated in recent years. However, the dynamics of offloading optimization objectives, i.e., latency, resource utilization rate, and energy consumption among the edge and cloud sides, have hardly been researched. Consequently, the Quality of Service(QoS) and offloading performance also experience uncertain deviation. In this work, we propose a multi-objective robust offloading algorithm to address this issue, dealing with dynamics and multi-objective optimization. The workflow request model in this work is modeled as Directed Acyclic Graph(DAG). An LSTM-based sequence-to-sequence neural network learns the offloading policy. We then conduct comprehensive implementations to validate the robustness of our algorithm. As a result, our algorithm achieves better offloading performance regarding each objective and faster adaptation to newly changed environments than fine-tuned typical single-objective RL-based offloading methods.},
  keywords={Training;Cloud computing;Adaptation models;Energy consumption;Heuristic algorithms;Neural networks;Dynamic scheduling;offloading;Meta-Learning;Reinforcement Learning;robustness;multi-objective learning;LSTM},
  doi={10.1109/CLOUD55607.2022.00070},
  ISSN={2159-6190},
  month={July},}@INPROCEEDINGS{9860412,
  author={Souza, Arthur and Cacho, Nélio and Batista, Thais and Ranjan, Rajiv},
  booktitle={2022 IEEE 15th International Conference on Cloud Computing (CLOUD)}, 
  title={SAPPARCHI: an Osmotic Platform to Execute Scalable Applications on Smart City Environments}, 
  year={2022},
  volume={},
  number={},
  pages={289-298},
  abstract={In the Smart Cities context, a plethora of Middle-ware Platforms had been proposed to support applications execution and data processing. Despite all the progress already made, the vast majority of solutions have not met the requirements of Applications’ Runtime, Development, and Deployment when related to Scalability. Some studies point out that just 1 of 97 (1%) reported platforms reach this all this set of requirements at same time. This small number of platforms may be explained by some reasons: i) Big Data: The huge amount of processed and stored data with various data sources and data types, ii) Multi-domains: many domains involved (Economy, Traffic, Health, Security, Agronomy, etc.), iii) Multiple processing methods like Data Flow, Batch Processing, Services, and Microservices, and 4) High Distributed Degree: The use of multiple IoT and BigData tools combined with execution at various computational levels (Edge, Fog, Cloud) leads applications to present a high level of distribution. Aware of those great challenges, we propose Sapparchi, an integrated architectural model for Smart Cities applications that defines multi-processing levels (Edge, Fog, and Cloud). Also, it presents the Sapparchi middleware platform for developing, deploying, and running applications in the smart city environment with an osmotic multi-processing approach that scales applications from Cloud to Edge. Finally, an experimental evaluation exposes the main advantages of adopting Sapparchi.},
  keywords={Cloud computing;Runtime;Smart cities;Scalability;Computational modeling;Soft sensors;Distributed databases;osmotic computing;serverless;microservice;scalability},
  doi={10.1109/CLOUD55607.2022.00051},
  ISSN={2159-6190},
  month={July},}@INPROCEEDINGS{9860308,
  author={Anisetti, Marco and Berto, Filippo and Banzi, Massimo},
  booktitle={2022 IEEE World Congress on Services (SERVICES)}, 
  title={Orchestration of data-intensive pipeline in 5G-enabled Edge Continuum}, 
  year={2022},
  volume={},
  number={},
  pages={2-10},
  abstract={Nowadays there is an increasing trend in the volume and velocity of data, typically consumed by data-intensive AI/ML-based services, requiring a larger diffusion of more effective Edge computing approaches. In addition, we are experiencing an increment of critical applications using an increasing volume of sensitive data and requiring advanced security and privacy protections. 5G Edge technology can foster a more diffused Edge computing adoption but several challenges in terms of interoperability. Handling data-intensive pipelines on the 5Genabled Edge continuum, considering specific QoS requirements including security and privacy, is still in its infancy. In this paper, we propose an initial solution for deploying a data-intensive pipeline in a 5G-enabled Edge continuum satisfying specific QoS requirements. Our approach is based on a QoS-aware meta orchestration modeling of a given pipeline and an orchestration builder generating deployable Edge-specific orchestrations. In this paper, we also present an initial walkthrough scenario in the context of a wet lab analysis pipeline to be deployed on the 5G-enabled Edge continuum.},
  keywords={Data privacy;5G mobile communication;Pipelines;Quality of service;Market research;Security;Interoperability;5G;Edge;QoS;data-intensive pipeline;Orchestration;Cloud},
  doi={10.1109/SERVICES55459.2022.00025},
  ISSN={2642-939X},
  month={July},}@INPROCEEDINGS{9854211,
  author={Miñón, Raúl and Díaz-de-Arcaya, Josu and Torre-Bastida, Ana I. and Zarate, Gorka and Moreno-Fernandez-de-Leceta, Aitor},
  booktitle={2022 7th International Conference on Smart and Sustainable Technologies (SpliTech)}, 
  title={MLPacker: A Unified Software Tool for Packaging and Deploying Atomic and Distributed Analytic Pipelines}, 
  year={2022},
  volume={},
  number={},
  pages={1-6},
  abstract={In the last years, MLOps (Machine Learning Operations) paradigm is attracting the attention from the community, extrapolating the DevOps (Development and Operations) paradigm to the artificial intelligence (AI) development life-cycle. In this area, some challenges must be addressed to successfully deliver solutions since there are specific nuances when dealing with AI operationalization such as the model packaging or monitoring. Fortunately, interesting and helpful approaches, both from the research community and industry have emerged. However, further research is still necessary to fulfil key gaps. This paper presents a tool, MLPacker, for addressing some of them. Concretely, this tool provides mechanisms to package and deploy analytic pipelines both in REST APIs and in streaming mode. In addition, the analytic pipelines can be deployed atomically (i.e., the whole pipeline in the same machine) or in a distributed fashion (i.e., deploying each stage of the pipeline in distinct machines). In this way, users can take advantage from the cloud continuum paradigm considering edge-fog-cloud computing layers. Finally, the tool is decoupled from the training stage to avoid data scientists the integration of blocks of code in their experiments for the operationalization. Besides the package mode (REST API or streaming), the tool can be configured to perform the deployments in local or in remote machines and by using or not containers. For this aim, this paper describes the gaps this tool addresses, the detailed components and flows supported, as well as an scenario with three different case studies to better explain the research conducted.},
  keywords={Training;Industries;Codes;Atomic layer deposition;Pipelines;Machine learning;Packaging;MLOps;AI life-cycle;packaging;deploying;analytic pipeline},
  doi={10.23919/SpliTech55088.2022.9854211},
  ISSN={},
  month={July},}@ARTICLE{9857807,
  author={Wang, Lianhai and Li, Yannan and Yu, Qiming and Yu, Yong},
  journal={IEEE Wireless Communications}, 
  title={Outsourced Data Integrity Checking with Practical Key Update in Edge-Cloud Resilient Networks}, 
  year={2022},
  volume={29},
  number={3},
  pages={56-62},
  abstract={The edge-cloud continuum is an advanced paradigm for cloud computing, which brings data storage and compute power closer to users or devices, and as a result, eliminates lag time and saves bandwidth. However, this new paradigm is harsh for secure storage and computation due to the separation of data ownership and control. Data security, especially outsourced data integrity in the edge-cloud resilient network, becomes one of the most fundamental challenges. To check the outsourced data integrity and address the efficient key update issue in this scenario, in this article, we propose a framework of outsourced data integrity checking with a practical key update in the edge-cloud resilient network. We first review the existing outsourced data integrity checking algorithms and then put forward a potential solution to achieving outsourced data integrity checking with a practical key update, which is composed of three phases, namely key request and update, local data upload, and outsourced data integrity auditing. We implement a prototype system for our proposal as well, which demonstrates its practicality.},
  keywords={Cloud computing;Protocols;Data integrity;Data security;Prototypes;Memory;Data models;Outsourcing;Energy storage},
  doi={10.1109/MWC.002.2100597},
  ISSN={1558-0687},
  month={June},}@INPROCEEDINGS{9838647,
  author={Sartzetakis, Ippokratis and Soumplis, Polyzois and Pantazopoulos, Panagiotis and Katsaros, Konstantinos V. and Sourlas, Vasilis and Varvarigos, Emmanouel Manos},
  booktitle={ICC 2022 - IEEE International Conference on Communications}, 
  title={Resource Allocation for Distributed Machine Learning at the Edge-Cloud Continuum}, 
  year={2022},
  volume={},
  number={},
  pages={5017-5022},
  abstract={Edge computing has emerged as a paradigm for local computing/processing tasks, reducing the distances over which data transfers are made. Thus, an opportunity is presented for data transfer-intensive, distributed machine learning. In this paper we develop a solution for serving distributed Machine Learning (ML) training jobs at the edge– cloud continuum. We model the specific requirements of each ML job, and the features of the edge and cloud resources. Next, we develop an Integer Linear Programming algorithm to perform the resource allocation. We examine different scenarios (different processing and bandwidth costs) and quantify tradeoffs related to performance and cost of edge/cloud bandwidth and processing resources. Our simulations indicate that even though there are many parameters that determine the allocation, the processing costs seem to play on average the most important role. The cloud b/w costs can be significant in certain scenarios. Finally, in certain examined cases, significant monetary benefits can be achieved through the collaboration of both edge and cloud resources when compared to using exclusively edge or cloud resources.},
  keywords={Training;Costs;Machine learning algorithms;Computational modeling;Machine learning;Bandwidth;Integer linear programming;cloud computing;distributed machine learning;edge-cloud continuum;edge computing;resource allocation},
  doi={10.1109/ICC45855.2022.9838647},
  ISSN={1938-1883},
  month={May},}@INPROCEEDINGS{9839193,
  author={Garbugli, Andrea and Rosa, Lorenzo and Foschini, Luca and Corradi, Antonio and Bellavista, Paolo},
  booktitle={ICC 2022 - IEEE International Conference on Communications}, 
  title={A Framework for TSN-enabled Virtual Environments for Ultra-Low Latency 5G Scenarios}, 
  year={2022},
  volume={},
  number={},
  pages={5023-5028},
  abstract={The recent trend of moving cloud computing capabilities to the edge of the network is reshaping the way applications and their middleware supports are designed, deployed, and operated. This new model envisions a continuum of virtual resources between the traditional cloud and the network edge, which is potentially more suitable to meet the heterogeneous Quality of Service (QoS) requirements of the supported application domains. Yet, mission-critical applications such as those in manufacturing, automation, or automotive, still rely on communication standards like the Time-Sensitive Networking (TSN) protocol and 5G to ensure a deterministic network behavior: in this context, virtualization might introduce unacceptable network perturbations. In this paper, we demonstrate that latency-sensitive applications can execute in virtual machines without disruptions to their network operations. We propose a novel approach to support the TSN protocol in virtual machines through a precise clock synchronization method and we implement it in integration with state-of-the-art and highly-efficient network virtualization techniques. Our experimental results show that it is possible to achieve deterministic and ultra-low latency end-to-end communication in the cloud continuum, for example providing a guaranteed sub-millisecond latency between remote virtual machines.},
  keywords={Cloud computing;Protocols;5G mobile communication;Perturbation methods;Mission critical systems;Quality of service;Virtual machining;time-sensitive networking;cloud continuum;network virtualization;ultra-low latency},
  doi={10.1109/ICC45855.2022.9839193},
  ISSN={1938-1883},
  month={May},}@INPROCEEDINGS{9838383,
  author={Costa, Marcus Vinícius Souza and Souza, Vitor Barbosa and Masip-Bruin, Xavi},
  booktitle={ICC 2022 - IEEE International Conference on Communications}, 
  title={Enhanced rank-based model for selecting controllers in dynamic and heterogeneous fog environments}, 
  year={2022},
  volume={},
  number={},
  pages={5688-5693},
  abstract={Fog computing is a recent paradigm leveraging available resources at the edge of the network intended to extend the traditional cloud model towards the novel cloud continuum computing model. Recognized the unstoppable growth of highly dynamic and heterogeneous edge devices, as well as the pop up of a large set of diverse and ever more demanding services, the selection of those edge resources best meeting service requirements while also matching the expected QoS guarantees is, with no doubt, a challenging task. This paper presents a rank-based model aimed at both evaluating edge nodes’ characteristics and selecting nodes best performing the controller role, whilst simultaneously satisfying the required QoS constraints, coining the so-called Control-as-a-Service concept. To that end, a yet simple prediction strategy, based on Dynamic Branch Prediction is introduced to avoid unnecessary controller exchanges and QoS degradation. In the performed experiments, the proposed method yielded a reduction in the number of exchanges when compared to a solution with no prediction, under different scenarios. Comparing distinct selection strategies, the proposed model presented an improvement in controller availability as well as in relevant controllers’ characteristics, such as battery and memory capacity.},
  keywords={Degradation;Protocols;Computational modeling;Employment;Quality of service;Predictive models;Dynamic scheduling;Fog computing;Dynamic controller selection;Control-as-a-Service},
  doi={10.1109/ICC45855.2022.9838383},
  ISSN={1938-1883},
  month={May},}@INPROCEEDINGS{9842714,
  author={Spătaru, Adrian and Iuhasz, Gabriel and Panica, Silviu},
  booktitle={2022 IEEE 46th Annual Computers, Software, and Applications Conference (COMPSAC)}, 
  title={TUFA: A TOSCA extension for the specification of accelerator-aware applications in the Cloud Continuum}, 
  year={2022},
  volume={},
  number={},
  pages={1178-1183},
  abstract={A Distributed Application Topology is a valuable commodity built on the strength of a long and iterative design process. A topology is generally refined over time, other topologies can use it as a component, and the community may share it. To reproduce a deployment, several properties must be recorded such as data origin, processing steps, configuration settings, and hardware requirements. This paper presents an extension to the TOSCA specification that allows for the definition of accelerator-aware services that can span from Cloud to Edge. Additionally, we introduce the concept of Abstract Applications that contain at least one abstract service definition. The process of Service Optimization replaces the abstract sertvices, creating an explicit topology deployable under hybrid deployment models (Virtual Machines, Containers, HPC) residing on the Cloud Continuum spectrum.},
  keywords={Cloud computing;Computational modeling;Serverless computing;Hardware;Virtual machining;Libraries;Topology;application specification;service optimization;cloud continuum},
  doi={10.1109/COMPSAC54236.2022.00185},
  ISSN={0730-3157},
  month={June},}@INPROCEEDINGS{9842670,
  author={Grigoropoulos, Nasos and Lalis, Spyros},
  booktitle={2022 IEEE 46th Annual Computers, Software, and Applications Conference (COMPSAC)}, 
  title={Fractus: Orchestration of Distributed Applications in the Drone-Edge-Cloud Continuum}, 
  year={2022},
  volume={},
  number={},
  pages={838-848},
  abstract={Next-generation drone applications will be distributed, including tasks that need to run at the edge or in the cloud and interact with the drone in a smooth way. In this paper, we propose Fractus, an orchestration framework for the automated deployment of such applications in the drone-edge-cloud continuum. Fractus provides users with abstractions for describing the application's placement and communication requirements, allocates resources in a mission-aware fashion by considering the drone operation area, establishes and maintains connectivity between components by transparently leveraging different networking capabilities, and tackles safety and privacy issues via policy-based access to mobility and sensor resources. We present the design of Fractus and discuss an implementation based on mature software deployment technology. Further, we evaluate the resource requirements of our implementation, showing that it introduces an acceptable overhead, and illustrate its functionality via real field tests and a simulation setup.},
  keywords={Privacy;Cloud computing;Codes;Conferences;Computational modeling;Software;Safety;orchestration;drone applications;edge computing},
  doi={10.1109/COMPSAC54236.2022.00134},
  ISSN={0730-3157},
  month={June},}@INPROCEEDINGS{9830167,
  author={Montpetit, Marie-José},
  booktitle={2022 1st International Conference on 6G Networking (6GNet)}, 
  title={The Network as a Computer Board: Architecture Concepts for In-Network Computing in the 6G Era}, 
  year={2022},
  volume={},
  number={},
  pages={1-5},
  abstract={Because of the increasing melding of Internet and computing in the core-edge continuum and in the Internet of Things networks are becoming much more computer-like with distributed functionalities. This architecture will have broad impact in 6G as the network can be programmed to enable new services and support high performance applications.},
  keywords={6G mobile communication;Technological innovation;Protocols;Computer network reliability;Operating systems;Computer architecture;Programming;In-network computing;edge-cloud continuum;intelligent networks;Internet of things},
  doi={10.1109/6GNet54646.2022.9830167},
  ISSN={},
  month={July},}@INPROCEEDINGS{9825999,
  author={Sicari, Christian and Catalfamo, Alessio and Galletta, Antonino and Villari, Massimo},
  booktitle={2022 22nd IEEE International Symposium on Cluster, Cloud and Internet Computing (CCGrid)}, 
  title={A Distributed Peer to Peer Identity and Access Management for the Osmotic Computing}, 
  year={2022},
  volume={},
  number={},
  pages={775-781},
  abstract={Nowadays Osmotic Computing is emerging as one of the paradigms used to guarantee the Cloud Continuum, and this popularity is strictly related to the capacity to embrace inside it some hot topics like containers, microservices, orchestration and Function as a Service (FaaS). The Osmotic principle is quite simple, it aims to create a federated heterogeneous infrastructure, where an application's components can smoothly move following a concentration rule. In this work, we aim to solve two big constraints of Osmotic Computing related to the incapacity to manage dynamic access rules for accessing the applications inside the Osmotic Infrastructure and the incapacity to keep alive and secure the access to these applications even in presence of network disconnections. For overcoming these limits we designed and implemented a new Osmotic component, that acts as an eventually consistent distributed peer to peer access management system. This new component is used to keep a local Identity and Access Manager (IAM) that permits at any time to access the resource available in an Osmotic node and to update the access rules that allow or deny access to hosted applications. This component has been already integrated inside a Kubernetes based Osmotic Infrastructure and we presented two typical use cases where it can be exploited.},
  keywords={Cloud computing;Urban areas;Microservice architectures;FAA;Containers;Peer-to-peer computing;osmotic computing;security;identity and access control;smart city},
  doi={10.1109/CCGrid54584.2022.00091},
  ISSN={},
  month={May},}@INPROCEEDINGS{9826058,
  author={Ayed, Dhouha and Dragan, Paul-Andrei and Félix, Edith and Mann, Zoltán Adám and Salant, Eliot and Seidl, Robert and Sidiropoulos, Anestis and Taylor, Steve and Vitorino, Ricardo},
  booktitle={2022 22nd IEEE International Symposium on Cluster, Cloud and Internet Computing (CCGrid)}, 
  title={Protecting sensitive data in the cloud-to-edge continuum: The FogProtect approach}, 
  year={2022},
  volume={},
  number={},
  pages={279-288},
  abstract={Data produced by end devices like smartphones, sensors or IoT devices can be stored and processed across a continuum of compute resources, from end devices via fog nodes to the cloud, enabling reduced latency, increased processing speed and energy savings. However, the data may be sensitive (e.g., personal data or confidential commercially sensitive information), with regulatory or other requirements for its protection. Protecting sensitive data in the dynamic, heterogeneous, and decentralized cloud-to-edge continuum is very challenging. This paper describes a solution: FogProtect, an integrated set of four technologies to protect data in the cloud-to-edge continuum. Fog-Protect addresses four concerns: (i) control and enforcement of distributed data access and usage; (ii) management of distributed data protection policies; (iii) risk assessment for data assets in the cloud-to-edge continuum; (iv) automated optimisation and adaptation to address identified risks. FogProtect operates dynamically, reacting to system changes or detected vulnerabilities to keep the data secure across the cloud- to-edge continuum. This paper describes an overview of the FogProtect concept, discusses each of the four approaches, and illustrates their usage for the protection of data in three real-world use cases.},
  keywords={Cloud computing;Smart cities;Data protection;Distributed databases;Organizations;Production facilities;Sensors;fog computing;edge computing;data protection;security;privacy},
  doi={10.1109/CCGrid54584.2022.00037},
  ISSN={},
  month={May},}@INPROCEEDINGS{9825937,
  author={Tanaka, Ryan and Papadimitriou, George and Viswanath, Sai Charan and Wang, Cong and Lyons, Eric and Thareja, Komal and Qu, Chengyi and Esquivel, Alicia and Deelman, Ewa and Mandal, Anirban and Calyam, Prasad and Zink, Michael},
  booktitle={2022 22nd IEEE International Symposium on Cluster, Cloud and Internet Computing (CCGrid)}, 
  title={Automating Edge-to-cloud Workflows for Science: Traversing the Edge-to-cloud Continuum with Pegasus}, 
  year={2022},
  volume={},
  number={},
  pages={826-833},
  abstract={In this paper, we describe how we extended the Pegasus Workflow Management System to support edge-to-cloud workflows in an automated fashion. We discuss how Pegasus and HTCondor (its job scheduler) work together to enable this automation. We use HTCondor to form heterogeneous pools of compute resources and Pegasus to plan the workflow onto these resources and manage containers and data movement for executing workflows in hybrid edge-cloud environments. We then show how Pegasus can be used to evaluate the execution of workflows running on edge only, cloud only, and edge-cloud hybrid environments. Using the Chameleon Cloud testbed to set up and configure an edge-cloud environment, we use Pegasus to benchmark the executions of one synthetic workflow and two production workflows: CASA-Wind and the Ocean Observatories Initiative Orcasound workflow, all of which derive their data from edge devices. We present the performance impact on workflow runs of job and data placement strategies employed by Pegasus when configured to run in the above three execution environments. Results show that the synthetic workflow performs best in an edge only environment, while the CASA - Wind and Orcasound workflows see significant improvements in overall makespan when run in a cloud only environment. The results demonstrate that Pegasus can be used to automate edge-to-cloud science workflows and the workflow provenance data collection capabilities of the Pegasus monitoring daemon enable computer scientists to conduct edge-to-cloud research.},
  keywords={Performance evaluation;Cloud computing;Observatories;Oceans;Production;Data collection;Containers;Pegasus;edge computing;workflows;workflow management systems;clouds;distributed systems},
  doi={10.1109/CCGrid54584.2022.00098},
  ISSN={},
  month={May},}@INPROCEEDINGS{9816988,
  author={Sousa, Rita and Nogueira, Luis and Rodrigues, Fátima and Pinho, Luis Miguel},
  booktitle={2022 IEEE 5th International Conference on Industrial Cyber-Physical Systems (ICPS)}, 
  title={Global Resource Management in the ELASTIC Architecture}, 
  year={2022},
  volume={},
  number={},
  pages={01-06},
  abstract={Smart systems increasingly demand the processing of a massive amount of data generated by heterogeneous and distributed data sources. Due to the inherent cyber-physical nature of these systems, many applications require that this processing respects a set of non-functional requirements (such as timeliness, or energy-efficiency). To cope with this challenge, edge-cloud architectures need to provide flexible mechanisms to support varying processing needs, whilst guaranteeing the minimum level of quality of service required by these smart applications. This paper addresses this challenge in the context of the ELASTIC software architecture, which has been developed integrating responsive data-in-motion (edge computing) and latent data-at-rest analytics (cloud computing) into a single solution, satisfying extreme-scale analytics' performance requirements. The paper focuses on how the architecture fulfils the non-functional properties inherited from the applications, namely real-time and energy-efficiency, whilst ensuring the performance of the software architecture.},
  keywords={Software architecture;Soft sensors;Distributed databases;Computer architecture;Quality of service;Cyber-physical systems;Energy efficiency;Non-Functional Requirements;Quality of Service;Edge-Cloud Compute Continuum;Elasticity},
  doi={10.1109/ICPS51978.2022.9816988},
  ISSN={},
  month={May},}@INPROCEEDINGS{9812698,
  author={Das, Arun and Roopaei, Mehdi and Jamshidi, Mo and Najafirad, Peyman},
  booktitle={2022 17th Annual System of Systems Engineering Conference (SOSE)}, 
  title={Distributed AI-Driven Search Engine on Visual Internet-of-Things for Event Discovery in the Cloud}, 
  year={2022},
  volume={},
  number={},
  pages={514-521},
  abstract={Millions of connected devices like connected cameras and streaming videos are introduced to smart cities every year, which are valuable source of information. However, such rich source of information is mostly left untapped. Thus, in this paper, we propose distributed deep neural networks (DNNs) over edge visual Internet of Things (VIoT) devices for parallel, real-time video scene parsing and indexing in conjunction with BigQuery retrieval on stored data in the cloud. The IoT video streams parsed into adaptive meta-data of person, attributes, actions, object, and relations using pre-trained DNNs. The meta-data cached at the edge-cloud for real-time analytics and also continuously transferred to the cloud for data fusion and BigQuery batch processing. The proposed distributed deep learning search platform bridges the gap between edge-to-cloud continuum computation by utilizing state-of-the-art distributed deep learning and BigQuery search algorithms for the geo-distributed Visual Internet of Things (VIoT). We show that our proposed system supports real-time event-driven computing at 122 milliseconds on virtual IoT devices in parallel, and as low as 2.4 seconds batch query response time on multi-table JOIN and GROUP-BY aggregation.},
  keywords={Deep learning;Visualization;Cloud computing;Smart cities;Image edge detection;Metadata;Cameras;Adaptive metadata;cyber-physical hunting;deep neural networks;distributed AI-analytics;edge-to-cloud analytics;hierarchical re-identification;smart city;video analytics.},
  doi={10.1109/SOSE55472.2022.9812698},
  ISSN={},
  month={June},}@INPROCEEDINGS{9799194,
  author={Smith, Christopher Peter and Jindal, Anshul and Chadha, Mohak and Gerndt, Michael and Benedict, Shajulin},
  booktitle={2022 IEEE 6th International Conference on Fog and Edge Computing (ICFEC)}, 
  title={FaDO: FaaS Functions and Data Orchestrator for Multiple Serverless Edge-Cloud Clusters}, 
  year={2022},
  volume={},
  number={},
  pages={17-25},
  abstract={Function-as-a-Service (FaaS) is an attractive cloud computing model that simplifies application development and deployment. However, current serverless compute platforms do not consider data placement when scheduling functions. With the growing demand for edge-cloud continuum, multi-cloud, and multi-serverless applications, this flaw means serverless technologies are still ill-suited to latency-sensitive operations like media streaming. This work proposes a solution by presenting a tool called FaDO: FaaS Functions and Data Orchestrator, designed to allow data-aware functions scheduling across multi-serverless compute clusters present at different locations, such as at the edge and in the cloud. FaDO works through header-based HTTP reverse proxying and uses three load-balancing algorithms: 1) The Least Connections, 2) Round Robin, and 3) Random for load balancing the invocations of the function across the suitable serverless compute clusters based on the set storage policies. FaDO further provides users with an abstraction of the serverless compute cluster’s storage, allowing users to interact with data across different storage services through a unified interface. In addition, users can configure automatic and policy-aware granular data replications, causing FaDO to spread data across the clusters while respecting location constraints. Load testing results show that it is capable of load balancing high-throughput workloads, placing functions near their data without contributing any significant performance overhead.},
  keywords={Measurement;Cloud computing;Processor scheduling;FAA;Streaming media;Load management;Scheduling;serverless;function-as-a-service;data-aware;multi-cloud;orchestration;edge-computing},
  doi={10.1109/ICFEC54809.2022.00010},
  ISSN={},
  month={May},}@ARTICLE{9770777,
  author={Garbugli, Andrea and Sabbioni, Andrea and Corradi, Antonio and Bellavista, Paolo},
  journal={IEEE Access}, 
  title={TEMPOS: QoS Management Middleware for Edge Cloud Computing FaaS in the Internet of Things}, 
  year={2022},
  volume={10},
  number={},
  pages={49114-49127},
  abstract={Several classes of advanced Internet of Things (IoT) applications, e.g., in the industrial manufacturing domain, call for Quality of Service (QoS) management to guarantee/control performance indicators, even in presence of many sources of “stochastic noise” in real deployment environments, from scarcely available bandwidth in a time window to concurrent usage of virtualized processing resources. This paper proposes a novel IoT-oriented middleware that i) considers and coordinates together different aspects of QoS monitoring, control, and management for different kinds of virtualized resources (from networking to processing) in a holistic way, and ii) specifically targets deployment environments where edge cloud resources are employed to enable the Serverless paradigm in the cloud continuum. The reported experimental results show how it is possible to achieve the desired QoS differentiation by coordinating heterogeneous mechanisms and technologies already available in the market. This demonstrates the feasibility of effective QoS-aware management of virtualized resources in the cloud-to-things continuum when considering a Serverless provisioning scenario, which is completely original in the related literature to the best of our knowledge.},
  keywords={Quality of service;Cloud computing;FAA;Internet of Things;Middleware;Process control;Method of moments;Edge cloud computing;FaaS;Internet of Things;interoperability;middleware;QoS management;serverless},
  doi={10.1109/ACCESS.2022.3173434},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{9766643,
  author={Bacchiani, Lorenzo and De Palma, Giuseppe and Sciullo, Luca and Bravetti, Mario and De Felice, Marco and Gabbrielli, Maurizio and Zavattaro, Gianluigi and Della Penna, Roberto and Iorizzo, Corrado and Livaldi, Andrea and Magnotta, Luca and Orsini, Mirko},
  booktitle={2022 5th Conference on Cloud and Internet of Things (CIoT)}, 
  title={SEAWALL: Seamless Low Latency Cloud Platforms for the Industry 4.0}, 
  year={2022},
  volume={},
  number={},
  pages={90-91},
  abstract={The paper presents the SEAWALL platform enabling heterogeneous data acquisition and low-latency processing for the Industry 4.0, developed within the homonymous project founded by the Italian BIREX industrial consortium. The architecture features cutting-edge technologies (such as Kubernetes, ISTIO, KubeEdge, W3C WoT), in order to support the seamless orchestration of workloads among the nodes of a cloud-edge continuum in QoS-aware scenarios where the latency requirement of the anomaly detection must be continuously assessed. The paper presents the industrial use-case from the SEAWALL project and the components of the cloud/edge architecture.},
  keywords={Industries;Cloud computing;Data acquisition;W3C;Computer architecture;Quality of service;Feature extraction;Industry 4.0;Cloud computing;Edge computing;Industrial Internet of Things (IIoT);Web of Things (WoT)},
  doi={10.1109/CIoT53061.2022.9766643},
  ISSN={},
  month={March},}@ARTICLE{9768117,
  author={Casadei, Roberto and Fortino, Giancarlo and Pianini, Danilo and Placuzzi, Andrea and Savaglio, Claudio and Viroli, Mirko},
  journal={IEEE Internet of Things Journal}, 
  title={A Methodology and Simulation-Based Toolchain for Estimating Deployment Performance of Smart Collective Services at the Edge}, 
  year={2022},
  volume={9},
  number={20},
  pages={20136-20148},
  abstract={Research trends are pushing artificial intelligence (AI) across the Internet of Things (IoT)–edge–fog–cloud continuum to enable effective data analytics, decision making, as well as the efficient use of resources for QoS targets. Approaches for collective adaptive systems (CASs) engineering, such as aggregate computing, provide declarative programming models and tools for dealing with the uncertainty and the complexity that may arise from scale, heterogeneity, and dynamicity. Crucially, aggregate computing architecture allows for “pulverization”: applications can be decomposed into many deployable micromodules that can be spread across the ICT infrastructure, thus allowing multiple potential deployment configurations for the same application logic. This article studies the deployment architecture of aggregate-based edge services and its implications in terms of performance and cost. The goal is to provide methodological guidelines and a model-based toolchain for the generation and simulation-based evaluation of potential deployments. First, we address this subject methodologically by proposing an approach based on deployment code generators and a simulation phase whose obtained solutions are assessed with respect to their performance and costs. We then tailor this approach to aggregate computing applications deployed onto an IoT–edge–fog–cloud infrastructure, and we develop a corresponding toolchain based on Protelis and EdgeCloudSim. Finally, we evaluate the approach and tools through a case study of edge multimedia streaming, where the edge ecosystem exhibits intelligence by self-organizing into clusters to promote load balancing in large-scale dynamic settings.},
  keywords={Aggregates;Computational modeling;Costs;Internet of Things;Programming;Computer architecture;Adaptive systems;Cloud services;collective services;cyber--physical systems;deployment methodology;edge intelligence;mobile and ubiquitous systems;pulverizable architectures;service middleware and platform;simulation},
  doi={10.1109/JIOT.2022.3172470},
  ISSN={2327-4662},
  month={Oct},}@INPROCEEDINGS{9764487,
  author={Malandrino, Francesco and Fabiana Chiasserini, Carla and Di Giacomo, Giuseppe},
  booktitle={2022 17th Wireless On-Demand Network Systems and Services Conference (WONS)}, 
  title={Energy-efficient Training of Distributed DNNs in the Mobile-edge-cloud Continuum}, 
  year={2022},
  volume={},
  number={},
  pages={1-4},
  abstract={We address distributed machine learning in multitier (e.g., mobile-edge-cloud) networks where a heterogeneous set of nodes cooperate to perform a learning task. Due to the presence of multiple data sources and computation-capable nodes, a learning controller (e.g., located in the edge) has to make decisions about (i) which distributed ML model structure to select, (ii) which data should be used for the ML model training, and (iii) which resources should be allocated to it. Since these decisions deeply influence one another, they should be made jointly. In this paper, we envision a new approach to distributed learning in multi-tier networks, which aims at maximizing ML efficiency. To this end, we propose a solution concept, called RightTrain, that achieves energy-efficient ML model training, while fulfilling learning time and quality requirements. RightTrain makes high-quality decisions in polynomial time. Further, our performance evaluation shows that RightTrain closely matches the optimum and outperforms the state of the art by over 50%.},
  keywords={Training;Wireless communication;Performance evaluation;Computational modeling;Soft sensors;Machine learning;Energy efficiency},
  doi={10.23919/WONS54113.2022.9764487},
  ISSN={},
  month={March},}@INPROCEEDINGS{9762406,
  author={Dustdar, Schahram},
  booktitle={2022 IEEE International Conference on Pervasive Computing and Communications (PerCom)}, 
  title={Keynote: Engineering the New Fabric of the Distributed Compute Continuum}, 
  year={2022},
  volume={},
  number={},
  pages={65-65},
  abstract={As humans, things, software and AI continue to become the entangled fabric of distributed systems, systems engineers and researchers are facing novel challenges. In this talk, we analyze the role of IoT, Edge, and Cloud, as well as AI in the co-evolution of distributed systems for the new decade. We identify challenges and discuss a roadmap that these new distributed systems have to address. We take a closer look at how a cyber-physical fabric will be complemented by AI operationalization to enable seamless end-to-end distributed systems.},
  keywords={Pervasive computing;Conferences;Fabrics;Software;Artificial intelligence},
  doi={10.1109/PerCom53586.2022.9762406},
  ISSN={2474-249X},
  month={March},}@ARTICLE{9762563,
  author={Habeeb, Fawzy and Alwasel, Khaled and Noor, Ayman and Jha, Devki Nandan and AlQattan, Duaa and Li, Yinhao and Aujla, Gagangeet Singh and Szydlo, Tomasz and Ranjan, Rajiv},
  journal={IEEE Transactions on Industrial Informatics}, 
  title={Dynamic Bandwidth Slicing for Time-Critical IoT Data Streams in the Edge-Cloud Continuum}, 
  year={2022},
  volume={18},
  number={11},
  pages={8017-8026},
  abstract={Edge computing has gained momentum in recent years, as complementary to cloud computing, for supporting applications (e.g., industrial control systems) that require time-critical communication guarantees. While edge computing can provide immediate analysis of streaming data from Internet of Things devices, those devices lack computing capabilities to guarantee reasonable performance for time-critical applications. To alleviate this critical problem, the prevalent trend is to offload these data analytic tasks from the edge devices to the cloud. However, existing offloading approaches are static in nature as they are unable to adapt varying workload and network conditions. To handle these issues, we present a novel distributed and quality of services based multilevel queue traffic scheduling system that can undertake semiautomatic bandwidth slicing to process time-critical incoming traffic in the edge-cloud environments. Our developed system shows a great enhancement in latency and throughput as well as reduction in energy consumption for edge-cloud environments.},
  keywords={Internet of Things;Cloud computing;Bandwidth;Quality of service;Microservice architectures;Ecosystems;Time factors;Bandwidth slicing;cloud;data stream;edge;Internet of Things (IoT);multiqueues;software-defined networking (SDN);time critical},
  doi={10.1109/TII.2022.3169971},
  ISSN={1941-0050},
  month={Nov},}@INPROCEEDINGS{9727215,
  author={},
  booktitle={2022 Seventh International Conference On Mobile And Secure Services (MobiSecServ)}, 
  title={Keynote Speech: 6G, revolution or continuity?}, 
  year={2022},
  volume={},
  number={},
  pages={i-i},
  abstract={Summary form only given, as follows. The complete presentation was not made available for publication as part of the conference proceedings. The 6G should begin to be specified in 2028 to be commercialized in 2030, ten years after the 5G. The 5G-Advanced will be released in 2025. Specifications begin to be well defined and give some indications if the 6G is presented as the continuation of the 5G. If there is a strong break, it will be to go to a completely distributed environment in which MEC data centers (Multi-Access Edge Computing) will be embedded in terminal equipment or in nodes located a few tens meters from the users. The solution that seems to be emerging is an aggregation of the two previous solutions using the Cloud Continuum, i.e. data centers ranging from embedded Edge to hyperscalers. Virtual machines that will support all applications, common services and digital infrastructure services will need to find the best position within the Cloud Continuum to optimize safety, quality of service and resiliency. Artificial intelligence will play a particularly important role in automating the entire system and optimizing controls.},
  keywords={6G mobile communication;Green products;Data centers;Cloud computing;5G mobile communication;Wireless fidelity;Virtual machining},
  doi={10.1109/MobiSecServ50855.2022.9727215},
  ISSN={2640-558X},
  month={Feb},}@INPROCEEDINGS{9700692,
  author={Faria, Nuno and Costa, Daniel and Pereira, José and Vilaça, Ricardo and Ferreira, Luís and Coelho, Fábio},
  booktitle={2022 IEEE 19th Annual Consumer Communications & Networking Conference (CCNC)}, 
  title={AIDA-DB: A Data Management Architecture for the Edge and Cloud Continuum}, 
  year={2022},
  volume={},
  number={},
  pages={1-6},
  abstract={There is an increasing demand for stateful edge computing for both complex Virtual Network Functions (VNFs) and application services in emerging 5G networks. Managing a mutable persistent state in the edge does however bring new architectural, performance, and dependability challenges. Not only it has to be integrated with existing cloud-based systems, but also cope with both operational and analytical workloads and be compatible with a variety of SQL and NoSQL database management systems. We address these challenges with AIDA-DB, a polyglot data management architecture for the edge and cloud continuum. It leverages recent development in distributed transaction processing for a reliable mutable state in operational workloads, with a flexible synchronization mechanism for efficient data collection in cloud-based analytical workloads.},
  keywords={Cloud computing;5G mobile communication;NoSQL databases;Computer architecture;Data collection;Synchronization;Reliability;Stateful edge;data management;polyglot processing;hybrid transactional analytical processing},
  doi={10.1109/CCNC49033.2022.9700692},
  ISSN={2331-9860},
  month={Jan},}@INBOOK{9622445,
  author={Montpetit, Marie‐José and Crespi, Noel},
  booktitle={Shaping Future 6G Networks: Needs, Impacts, and Technologies}, 
  title={Computing in the Network}, 
  year={2022},
  volume={},
  number={},
  pages={133-166},
  abstract={Recent advances in virtualization technologies and distributed networking architectures have led to an increased interest in jointly considering computation and forwarding in network nodes. This is spurred in great parts by the proliferation of edge computing as a complementary or even alternative to centralized cloud computing and supplementing data centers for data‐driven, time‐sensitive, and critical applications and telemetry. These trends have given rise to the concept of the edge‐cloud continuum, the melding of networking and computing with common and tightly integrated resource allocation capabilities from the edge of the network to the back‐end cloud infrastructure including computing and storage. The network is becoming more like a distributed computer board than the telephone network of yore: instead of providing connections and forwarding, the network can now be considered as an essential constituent of the applications themselves where the boundaries between the networking and computing domains are redefined. Although the joint optimization of communication and computation resource allocation has already been proposed in the past, it predated the current softwarization of networks, the development of new resource sharing paradigms in mobile networks, as well as the rise of data‐driven approaches including machine learning. The availability of new hardware architectures (e.g. Tofino) and programming frameworks (e.g. P4) makes it possible to perform some in‐network computing at line speed. In order to better understand the fundamental changes that computing will bring to the 6G era, this chapter examines the state of the art of the in‐network computation areas and how the edge‐cloud continuum should evolve to support the next generation of applications and service.},
  keywords={Internet;Computer architecture;Active networking;Virtualization;Cloud computing;Technological innovation;Hardware},
  doi={10.1002/9781119765554.ch10},
  ISSN={},
  publisher={IEEE},
  isbn={9781119765493},
  url={https://ieeexplore.ieee.org/document/9622445},}@ARTICLE{9615028,
  author={Fu, Kaihua and Zhang, Wei and Chen, Quan and Zeng, Deze and Guo, Minyi},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={Adaptive Resource Efficient Microservice Deployment in Cloud-Edge Continuum}, 
  year={2022},
  volume={33},
  number={8},
  pages={1825-1840},
  abstract={User-facing services are now evolving towards the microservice architecture where a service is built by connecting multiple microservice stages. Since the entire service is heavy, the microservice architecture shows the opportunity to only offload some microservice stages to the edge devices that are close to the end users. However, emerging techniques often result in the violation of Quality-of-Service (QoS) of microservice-based services in cloud-edge continuum, as they do not consider the communication overhead or the resource contention between microservices and external co-located tasks. We propose Nautilus, a runtime system that effectively deploys microservice-based user-facing services in cloud-edge continuum. Nautilus ensures the QoS of microservice-based user-facing services while minimizing the required computational resources, which is comprised of a communication-aware microservice mapper, a contention-aware resource manager and an IO-sensitive and load-aware microservice migration scheduler. The mapper divides the microservice graph into multiple partitions based on the communication overhead and maps the partitions to appropriate nodes. On each node, the resource manager determines the optimal resource allocation for its microservices based on reinforcement learning that may capture the complex contention behaviors. Once the microservices are suffered from external IO pressure, the IO-sensitive microservice scheduler migrates the critical one to idle nodes. Furthermore, when the load of microservices changes dynamically, the load-aware microservice scheduler migrates microservices from busy nodes to idle ones to ensure the QoS goal of the entire service. Our experimental results show that Nautilus can guarantee the required QoS target under external shared resources contention while the state-of-the-art suffers from QoS violations. Meanwhile, Nautilus reduces the computational resource usage by 23.9% and the network bandwidth usage by 53.4%, while achieving the required 99%-ile latency.},
  keywords={Quality of service;Cloud computing;Task analysis;Resource management;Computer architecture;Runtime;Bandwidth;Cloud-edge continuum;QoS;microservice resources management},
  doi={10.1109/TPDS.2021.3128037},
  ISSN={1558-2183},
  month={Aug},}@ARTICLE{9560071,
  author={Bachoumis, Athanasios and Andriopoulos, Nikos and Plakas, Konstantinos and Magklaras, Aristeidis and Alefragis, Panayiotis and Goulas, Georgios and Birbas, Alexios and Papalexopoulos, Alex},
  journal={IEEE Transactions on Cloud Computing}, 
  title={Cloud-Edge Interoperability for Demand Response-Enabled Fast Frequency Response Service Provision}, 
  year={2022},
  volume={10},
  number={1},
  pages={123-133},
  abstract={The massive penetration of Renewables into the energy mix and the existence of IoT-enabled Distributed Energy Resources (DERs) in the emerging smart grid, while a blessing towards de-carbonization, increase considerably the operations and planning functions of the grid. Cloud processing of IoT/DER data facilitates the deployment of various Demand-Response (DR) and other DER asset scenarios, the organization of distribution grids into Local Energy Markets (LEM) and the efficient computation of load forecasting and power flow. Cloud computing enables a plethora of service provisions to the grid including frequency response. The decentralized nature of DERs at the edge of the distribution grid requires nodal approaches for the computation of power grid congestion constraints and power flow solutions. We present here a cloud-edge continuum approach, anchored on the new generation of communications infrastructure, which expedites the computation time of the load and DER forecasting and optimal power flow calculations. The proposed approach allows the LEM operator to respond to Fast Frequency Response service procurement signals issued by the balancing authority requiring even sub-second latency for service settlement. The proposed cloud-edge architecture has been tested on the IEEE European Low Voltage Benchmark model and provides scalability and elasticity for various DR/DER configurations.},
  keywords={Cloud computing;Computer architecture;Real-time systems;Frequency response;Power system stability;Forecasting;Europe;Cloud demand response services;cloud-edge architecture;fast frequency response service;local energy markets},
  doi={10.1109/TCC.2021.3117717},
  ISSN={2168-7161},
  month={Jan},}@ARTICLE{9508839,
  author={Sharma, Vishal and Tan, Teik Guan and Singh, Saurabh and Sharma, Pradip Kumar},
  journal={IEEE Transactions on Industrial Informatics}, 
  title={Optimal and Privacy-Aware Resource Management in Artificial Intelligence of Things Using Osmotic Computing}, 
  year={2022},
  volume={18},
  number={5},
  pages={3377-3386},
  abstract={Critical infrastructure comprising on-demand devices, including secondary servers, comes into play when a situation like an overload is involved. The on-demand servers and devices require smart management solutions that form an integral part of Artificial Intelligence of Things (AIoT). This work considers AIoT as a combination of Mobile-Internet of Things (M-IoT) and AI requiring immediate response, secondary support system, and computational resources. Privacy in AIoT is always a concern when sharing information as intruders can eavesdrop on the settings of the system. This article uses an osmotic computing paradigm, which enables the derivation of strategies to decide on the methods of sharing services via optimal and privacy-aware resource management in AIoT. A safety competition is built on top of configuration rewards that help to attain privacy-by-design. The contributions of this article are expressed using theoretical analysis and numerical simulations.},
  keywords={Servers;Resource management;Privacy;Computational modeling;Safety;Solvents;Internet of Things;Internet of Things (IoT);mobility;osmotic computing;privacy-aware;resource management},
  doi={10.1109/TII.2021.3102471},
  ISSN={1941-0050},
  month={May},}@ARTICLE{9473013,
  author={Kimovski, Dragi and Mehran, Narges and Kerth, Christopher Emanuel and Prodan, Radu},
  journal={IEEE Transactions on Services Computing}, 
  title={Mobility-Aware IoT Application Placement in the Cloud – Edge Continuum}, 
  year={2022},
  volume={15},
  number={6},
  pages={3358-3371},
  abstract={The Edge computing extension of the Cloud services towards the network boundaries raises important placement challenges for IoT applications running in a heterogeneous environment with limited computing capacities. Unfortunately, existing works only partially address this challenge by optimizing a single or aggregate objective (e.g., response time), and not considering the edge devices’ mobility and resource constraints. To address this gap, we propose a novel mobility-aware multi-objective IoT application placement (mMAPO) method in the Cloud – Edge Continuum that optimizes completion time, energy consumption, and economic cost as conflicting objectives. mMAPO utilizes a Markov model for predictive analysis of the Edge device mobility and constrains the optimization to devices that do not frequently move through the network. We evaluate the quality of the mMAPO placements using simulation and real-world experimentation on two IoT applications. Compared to related work, mMAPO reduces the economic cost by 28 percent and decreases the completion time by 80 percent while maintaining a stable energy consumption.},
  keywords={Internet of Things;Cloud computing;Energy consumption;Optimization;Predictive models;Markov processes;Economics;Cloud;edge continuum;mobility;application placement;multi-objective optimization;energy consumption;cost},
  doi={10.1109/TSC.2021.3094322},
  ISSN={1939-1374},
  month={Nov},}@ARTICLE{9240037,
  author={Goethals, Tom and De Turck, Filip and Volckaert, Bruno},
  journal={IEEE Transactions on Cloud Computing}, 
  title={Extending Kubernetes Clusters to Low-Resource Edge Devices Using Virtual Kubelets}, 
  year={2022},
  volume={10},
  number={4},
  pages={2623-2636},
  abstract={In recent years, containers have gained popularity as a lightweight virtualization technology. This rise in popularity has gone hand in hand with the adoption of microservice architectures, mostly thanks to the scalable, ethereal, and isolated nature of containers. More recently, edge devices have become powerful enough to be able to run containerized microservices, while remaining flexible enough in terms of size and power to be deployed almost anywhere. This has triggered research into several container placement strategies involving edge networks, leading to concepts such as osmotic computing. While these container placement strategies are optimal in terms of workload placement, current container orchestrators are often not suitable for running on edge devices due to their high resource requirements. In this article, FLEDGE is presented as a Kubernetes-compatible container orchestrator based on Virtual Kubelets, aimed primarily at container orchestration on low-resource edge devices. Several aspects of low-resource container orchestration are examined, such as the choice of container runtime and how to realize container networking. A number of evaluations are performed to determine how FLEDGE compares to Kubernetes and K3S in terms of resource requirements, showing that it needs around 60MiB memory and 78MiB storage to run on a Raspberry Pi 3, including all dependencies, which is significantly less than both studied alternatives.},
  keywords={Containers;Cloud computing;Security;Standards;Software;Runtime;Virtual private networks;Edge networks;edge computing;container orchestration;containers;VPN},
  doi={10.1109/TCC.2020.3033807},
  ISSN={2168-7161},
  month={Oct},}@INPROCEEDINGS{9721323,
  author={Miyachi, Christine},
  booktitle={2021 Cloud Continuum}, 
  title={The Rise of Kubernetes}, 
  year={2021},
  volume={},
  number={},
  pages={1-5},
  abstract={Kubernetes has exploded since our last Community of Practice column, and the role of its vibrant community is a big part of why it continues to grow.},
  keywords={Technological innovation;Stability criteria;Software;Internet;Standards},
  doi={10.1109/CloudContinuum54760.2021.00002},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{9660813,
  author={Rana, Omer F.},
  booktitle={2021 Second International Conference on Intelligent Data Science Technologies and Applications (IDSTA)}, 
  title={Keynote Speech 2: Extending the Data Science pipeline: Integrating Machine Learning into Edge Environments}, 
  year={2021},
  volume={},
  number={},
  pages={2-2},
  abstract={Summary form only given, as follows. A record of the panel discussion was not made available for publication as part of the conference proceedings. Internet of Things (IoT) applications today involve data capture from sensors and devices that are close to the phenomenon being measured, with such data subsequently being transmitted to Cloud data centre for storage, analysis and visualisation. Currently devices used for data capture often differ from those that are used to subsequently carry out analysis on such data. Increasing availability of storage and processing devices closer to the data capture device, perhaps over a one-hop network connection or even directly connected to the IoT device itself, requires more efficient allocation of processing across such edge devices and data centres. Supporting machine learning & data analytics directly on edge devices also enables support for distributed (federated) learning, enabling user devices to be used directly in the inference or learning process. Scalability in this context needs to consider both cloud resources, data distribution and initial processing on edge resources closer to the user. This talk investigates how a data analytics pipeline can be deployed across the cloud-edge continuum. Understanding what should be executed at a data centre and what can be moved to an edge resource remains an important challenge -- especially with increasing capability of our edge devices. The following questions are addressed in this talk: How do we partition machine learning algorithms across Edge-Network-Cloud resources (often referred to as the "Cloud-Edge Continuum") based on constraints such as privacy, capacity and resilience? Can machine learning algorithms be adapted based on the characteristics of devices on which they are hosted? What does this mean for stability/ convergence vs. performance? Do we trade-off accuracy for “explainability” of results? Given a complex parameter space can “approximations” help with explaining the basis of results?},
  keywords={Cloud computing;Internet of Things;Data science;Data centers;Software;Pipelines;Performance evaluation},
  doi={10.1109/IDSTA53674.2021.9660813},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{9651638,
  author={Houmani, Zeina and Balouek-Thomert, Daniel and Caron, Eddy and Parashar, Manish},
  booktitle={2021 IEEE 33rd International Symposium on Computer Architecture and High Performance Computing (SBAC-PAD)}, 
  title={Enabling microservices management for Deep Learning applications across the Edge-Cloud Continuum}, 
  year={2021},
  volume={},
  number={},
  pages={137-146},
  abstract={Deep Learning has shifted the focus of traditional batch workflows to data-driven feature engineering on streaming data. In particular, the execution of Deep Learning workflows presents expectations of near-real-time results with user-defined acceptable accuracy. Meeting the objectives of such applications across heterogeneous resources located at the edge of the network, the core, and in-between requires managing trade-offs between the accuracy and the urgency of the results. However, current data analysis rarely manages the entire Deep Learning pipeline along the data path, making it complex for developers to implement strategies in realworld deployments. Driven by an object detection use case, this paper presents an architecture for time-critical Deep Learning workflows by providing a data-driven scheduling approach to distribute the pipeline across Edge to Cloud resources. Furthermore, it adopts a data management strategy that reduces the resolution of incoming data when potential trade-off optimizations are available. We illustrate the system&#x0027;s viability through a performance evaluation of the object detection use case on the Grid&#x0027;5000 testbed. We demonstrate that in a multi-user scenario, with a standard frame rate of 25 frames per second, the system speed-up data analysis up to 54.4&#x0025; compared to a Cloud-only-based scenario with an analysis accuracy higher than a fixed threshold.},
  keywords={Deep learning;Data analysis;Image edge detection;Pipelines;Object detection;Computer architecture;Time factors;Cloud computing;Edge computing;Microservices;Task allocation;Real-time processing;Computing Continuum;Deep Learning},
  doi={10.1109/SBAC-PAD53543.2021.00025},
  ISSN={2643-3001},
  month={Oct},}@INPROCEEDINGS{9647689,
  author={Kretsis, Aristotelis and Kokkinos, Panagiotis and Soumplis, Polyzois and Olmos, Juan Jose Vegas and Fehér, Marcell and Sipos, Márton and Lucani, Daniel E. and Khabi, Dmitry and Masouros, Dimosthenis and Siozios, Kostas and Bourgos, Paraskevas and Tsekeridou, Sofia and Zyulkyarov, Ferad and Karanastasis, Efstathios and Chondrogiannis, Efthymios and Andronikou, Vassiliki and Gomez, Aitor Fernandez and Panica, Silviu and Iuhasz, Gabriel and Nanos, Anastassios and Chalios, Charalampos and Varvarigos, Manos},
  booktitle={2021 IEEE International Mediterranean Conference on Communications and Networking (MeditCom)}, 
  title={SERRANO: Transparent Application Deployment in a Secure, Accelerated and Cognitive Cloud Continuum}, 
  year={2021},
  volume={},
  number={},
  pages={55-60},
  abstract={We are witnessing a wave of emerging cloud computing technologies and services that empower advanced applications from different vertical sectors, with diverse requirements. These trends give rise to a number of fundamental challenges that relate to the application deployment, the support of heterogeneous infrastructures and the provided security. In this setting, the SERRANO project steps in to define an intent-based paradigm of operating federated infrastructures consisting of edge, cloud and HPC resources, which will be realized through the SERRANO platform. Applications’ high-level requirements will be translated to infrastructure-aware configuration parameters. SERRANO orchestration will then provide adaptive and efficient access to secure by design and accelerated resources. In this way, SERRANO will support cloud-native applications and services towards the cloud continuum.},
  keywords={Computers;Cloud computing;Technological innovation;Privacy;Conferences;Computer architecture;Market research;cloud computing;edge computing;HPC;security;hardware acceleration;orchestration},
  doi={10.1109/MeditCom49071.2021.9647689},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{9651294,
  author={Balouek-Thomert, Daniel and Rodero, Ivan and Parashar, Manish},
  booktitle={2021 IEEE/ACM HPC for Urgent Decision Making (UrgentHPC)}, 
  title={Evaluating policy-driven adaptation on the Edge-to-Cloud Continuum}, 
  year={2021},
  volume={},
  number={},
  pages={11-20},
  abstract={Developing data-driven applications requires developers and service providers to orchestrate data-to-discovery pipelines across distributed data sources and computing units. Realizing such pipelines poses two major challenges: programming analytics that reacts at runtime to unforeseen events, and adaptation of the resources and computing paths between the edge and the cloud. While these concerns are interdependent, they must be separated during the design process of the application and the deployment operations of the infrastructure. This work proposes a system stack for the adaptation of distributed analytics across the computing continuum. We implemented this software stack to evaluate its ability to continually balance the computation or data movement’s cost with the value of operations to the application objectives. Using a disaster response application, we observe that the system can select appropriate configurations while managing trade-offs between user-defined constraints, quality of results, and resource utilization. The evaluation shows that our model is able to adapt to variations in the data input size, bandwidth, and CPU capacities with minimal deadline violations (close to 10%). This constitutes encouraging results to benefit and facilitate the creation of ad-hoc computing paths for urgent science and time-critical decision-making.},
  keywords={Adaptation models;Runtime;Computational modeling;Soft sensors;Decision making;Pipelines;Distributed databases;Cloud computing;Edge computing;Computing Continuum;Decision Model},
  doi={10.1109/UrgentHPC54802.2021.00007},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{9615526,
  author={Truong, Hong-Linh},
  booktitle={2021 17th International Conference on Network and Service Management (CNSM)}, 
  title={ASRE — Towards Application-specific Resource Ensembles across Edges and Clouds}, 
  year={2021},
  volume={},
  number={},
  pages={239-243},
  abstract={We research a new abstraction for resources for applications, called Application-specific Resource Ensembles (ASREs), across edge and cloud infrastructures. ASRE encapsulates diverse types of high-level resources, coupled with management APIs, that is provided for application-specific contexts. ASRE is designed with integrated mechanisms to manage its multidimensional quality through monitoring and control techniques. Instances of ASRE can be provisioned on-demand, with the elasticity and resilience capabilities, thus help to simplify the resource management in edge-cloud continuum.},
  keywords={Elasticity;Resource management;Monitoring;Resilience},
  doi={10.23919/CNSM52442.2021.9615526},
  ISSN={2165-963X},
  month={Oct},}@INPROCEEDINGS{9615332,
  author={Kampars, Janis and Tropins, Dainis and Matisons, Ralfs},
  booktitle={2021 62nd International Scientific Conference on Information Technology and Management Science of Riga Technical University (ITMS)}, 
  title={A Review of Application Layer Communication Protocols for the IoT Edge Cloud Continuum}, 
  year={2021},
  volume={},
  number={},
  pages={1-6},
  abstract={The IoT technological paradigm has become widespread and has found its place within industries such as smart cities, smart grids, smart homes, physical security, e-health, asset management, and logistics. Around 50 billion various devices will soon be connected to the Internet. A hot topic within the IoT field is edge computing, which adds extra computing capacity to the edge allowing to perform computationally intensive operations like execution of Deep Neural Networks possibly requiring specialized devices equipped with Graphical Processing Units. Optimal construction of solutions that span the IoT, edge, and cloud computing layers is still an open research area, and it is believed that edge computing is in its infancy. This article reviews application layer protocols that can be used to interconnect entities belonging to the three previously mentioned layers.},
  keywords={Performance evaluation;Cloud computing;Protocols;Smart cities;Smart homes;Smart grids;Security;AMQP;CoAP;DDS;edge computing;gRPC;IoT;MQTT;XMPP},
  doi={10.1109/ITMS52826.2021.9615332},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{9610437,
  author={Reisinger, Matthias and Frangoudis, Pantelis A. and Dustdar, Schahram},
  booktitle={2021 IEEE International Conference on Cloud Engineering (IC2E)}, 
  title={System support and mechanisms for adaptive edge-to-cloud DNN model serving}, 
  year={2021},
  volume={},
  number={},
  pages={278-279},
  abstract={We present an orchestration scheme for Deep Neural Network (DNN) model serving, capable of computation distribution over the device-to-cloud continuum and low-latency inference. Our system allows automated layer-wise splitting of DNN structures and their adaptive distribution over compute hosts, providing an execution environment for collaborative inference. Model deployment and its self-adaptation at runtime are implemented by optimization algorithms supported in a plug-in manner. These follow service and infrastructure provider criteria and constraints, expressed via well-defined interfaces. Our framework can serve diverse neural architectures, including DNNs with early exits, with zero to minimal modifications.},
  keywords={Deep learning;Adaptation models;Runtime;Adaptive systems;Computational modeling;Conferences;Inference algorithms},
  doi={10.1109/IC2E52221.2021.00046},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{9595618,
  author={Cao, Hung and Wachowicz, Monica and Craig, James},
  booktitle={2021 IEEE 7th World Forum on Internet of Things (WF-IoT)}, 
  title={Edge-Cloud Intelligence in Self-Diagnostic of Land Mobile Radio Systems}, 
  year={2021},
  volume={},
  number={},
  pages={645-650},
  abstract={IIoT sensors are usually deployed on a massive scale with stringent scalability, modularity, and interoperability requirements. It is indisputable that they produce a large amount of high-speed and heterogeneous data streams that pose many challenges to perform management, processing, and analytical tasks. This paper proposes an integrated edge-cloud continuum platform that can harvest IIoT data streams from a variety of sensors deployed at a remote RF site; and can harmonize different machine learning models for diagnosing problems that enhance infrastructure monitoring and long-term structural resilience. A real-world experiment was carried out to evaluate the proposed platform for supporting a self-diagnostic process for intelligent maintenance of Land Mobile Radio (LMR) infrastructures.},
  keywords={Radio frequency;Scalability;Machine learning;Maintenance engineering;Task analysis;Monitoring;Interoperability;cloud computing;edge computing;Land Mobile Radio Systems;Industrial Internet of Things;streaming analytics;intelligent maintenance},
  doi={10.1109/WF-IoT51360.2021.9595618},
  ISSN={},
  month={June},}@INPROCEEDINGS{9595051,
  author={Taneja, Mohit and Jalodia, Nikita and Malone, Paul and Misha, Eyal},
  booktitle={2021 IEEE 7th World Forum on Internet of Things (WF-IoT)}, 
  title={Methodical Analysis of a Fog Computing Assisted Animal-Welfare Software System in a Real-World Smart Dairy Farm IoT Deployment}, 
  year={2021},
  volume={},
  number={},
  pages={857-864},
  abstract={In the IoT era, the devices along the things-to-cloud continuum, present a unique opportunity to additionally serve as computing hubs. Termed Fog computing, this paradigm can be used to host applications and process data closer to the source. In this article, we present a methodical analysis of our fog enabled software system in an IoT enabled smart dairy farm. The developed software system uses locomotion data generated by wearables on cows’ feet to detect anomalies in their behaviour. We analyze the benefits of using a fog computing assisted approach for developing such IoT solutions. We use resource utilization as the performance metric for analyzing the benefits of leveraging the fog computing paradigm compared to the traditional cloud centric approach. The results suggest that a fog enabled software system brings benefits such as efficient utilization of computing resources, improved QoS etc. The evaluation indicates that there will be need of special design (including both low-level and high-level system design) re-configurations and also re-engineering of some components to provide higher scalability using less computational resources.},
  keywords={Measurement;Cloud computing;Wearable computers;Scalability;Quality of service;Software systems;Computational efficiency;Fog Computing;Methodical Analysis;Fog Enabled Software;Internet of Things (IoT);Smart Dairy Farming;Microservices},
  doi={10.1109/WF-IoT51360.2021.9595051},
  ISSN={},
  month={June},}@INPROCEEDINGS{9595628,
  author={Peltonen, Ella and Sojan, Arun and Päivärinta, Tero},
  booktitle={2021 IEEE 7th World Forum on Internet of Things (WF-IoT)}, 
  title={Towards Real-time Learning for Edge-Cloud Continuum with Vehicular Computing}, 
  year={2021},
  volume={},
  number={},
  pages={921-926},
  abstract={Sensor-driven IoT systems are well-known for their capacity to accelerate massive amounts of data in a comparatively short period of time. To have any use, the information delivery and decision making based on the data require efficient learning models together with dynamically deployed computing and network resources. The current cloud and high-performance computing infrastructures, as well as modern edge computing systems especially in the 5G and beyond networks, can be addressed to resolve these challenges. However, there are several application areas especially in vehicular and urban computing, where just harnessing more computational power does not solve computational and real-time requirements of the modern sensing systems that operate in mobile and context-dependent environments. For now, the mathematical challenges of distributed computing and real-time learning algorithms have not been profoundly addressed in the context of the IoT and real-world sensing applications. Data-driven systems also require giving full attention to information delivery, data management, data cleaning, and sensor fusion technologies that need to be equally distributed and real-time competent as the learning algorithms themselves. New software-defined computing and networking approaches and architectures are required to orchestrate the numerous connected resources dynamically, controllably, and securely along with the evolving needs. The key challenge here is to uniform collaboration between different aspects of the system, from data processing and delivery to the algorithms and learning models, not forgetting the computational capacity and networking capabilities, all this in real-time with real-world applications.},
  keywords={Cloud computing;5G mobile communication;Heuristic algorithms;Computational modeling;Distributed databases;Real-time systems;Data models;Edge-Cloud Continuum;Internet of Things;Vehicular Computing;Machine Learning;Artificial Intelligence;Automotive Software;Software-Defined Vehicle;Software-Defined Network;Smart Traffic.},
  doi={10.1109/WF-IoT51360.2021.9595628},
  ISSN={},
  month={June},}@INPROCEEDINGS{9590420,
  author={Zeiner, Herwig and Unterberger, Roland},
  booktitle={2021 8th International Conference on Future Internet of Things and Cloud (FiCloud)}, 
  title={Time-aware Data Spaces - A key Computing Unit in the Edge-to-Cloud Continuum}, 
  year={2021},
  volume={},
  number={},
  pages={250-255},
  abstract={Digital transformation requires new views and strategies for edge computing for Industrial Internet of Things applications. In this work, we elaborate the importance of time-aware data spaces as a conceptual entity for a digital and scaleable approach in a data-driven world. This work introduces these small data spaces deployed and distributed through edge analytic boxes. The concept time-aware data space is more suitable than single sensors for this type of application. It is particularly suitable in the edge-to-cloud continuum to build robust solutions and allow a new view on these types of applications. Moreover, we use this approach in a production environment. The requirements are a suitable application area for our time-aware data spaces. They can be used to monitor the environment, the machines or the production processes. Such an approach can also be integrated into other existing solutions with reasonable efforts.},
  keywords={Digital transformation;Distributed databases;Systems engineering and theory;Software;Production facilities;Sensors;Complexity theory;Edge;time-aware;data spaces;edge-to-cloud continuum},
  doi={10.1109/FiCloud49777.2021.00043},
  ISSN={},
  month={Aug},}@ARTICLE{9606830,
  author={Cheng, Zhipeng and Gao, Zhibin and Liwang, Minghui and Huang, Lianfen and Du, Xiaojiang and Guizani, Mohsen},
  journal={IEEE Network}, 
  title={Intelligent Task Offloading and Energy Allocation in the UAV-Aided Mobile Edge-Cloud Continuum}, 
  year={2021},
  volume={35},
  number={5},
  pages={42-49},
  abstract={The arrival of big data and the Internet of Things (IoT) era greatly promotes innovative in-network computing techniques, where the edge-cloud continuum becomes a feasible paradigm in handling multi-dimensional resources such as computing, storage, and communication. In this article, an energy constrained unmanned aerial vehicle (UAV)-aided mobile edge-cloud continuum framework is introduced, where the offloaded tasks from ground IoT devices can be cooperatively executed by UAVs acts as an edge server and cloud server connected to a ground base station (GBS), which can be seen as an access point. Specifically, a UAV is powered by the laser beam transmitted from a GBS, and can further charge IoT devices wirelessly. Here, an interesting task offloading and energy allocation problem is investigated by maximizing the long-term reward subject to executed task size and execution delay, under constraints such as energy causality, task causality, and cache causality. A federated deep reinforcement learning (FDRL) framework is proposed to learn the joint task offloading and energy allocation decision while reducing the training cost and preventing privacy leakage of DRL training. Numerical simulations are conducted to verify the effectiveness of our proposed scheme as compared to three baseline schemes.},
  keywords={Training data;Privacy;Power lasers;Reinforcement learning;Unmanned aerial vehicles;Resource management;Servers;Edge computing;Cloud computing},
  doi={10.1109/MNET.010.2100025},
  ISSN={1558-156X},
  month={Sep.},}@INPROCEEDINGS{9564352,
  author={Frangoudis, Pantelis A. and Reisinger, Matthias and Dustdar, Schahram},
  booktitle={2021 IEEE International Conference on Service-Oriented System Engineering (SOSE)}, 
  title={Recursive design for data-driven, self-adaptive IoT services}, 
  year={2021},
  volume={},
  number={},
  pages={33-44},
  abstract={We present a recursive approach to the design and operation of complex, data-driven IoT services, which are challenged by the traditional cloud-centric view of service delivery. To this end, we introduce a recursive IoT node abstraction, around which we sketch the architecture of a distributed runtime environment for the execution of such services, promoting self-adaptation to a first-class concept. Our framework aims to support services of arbitrary structure and complexity, dynamically configured and fluidly deployed along a heterogeneous device-to-cloud compute continuum, and operating according to provider and user intent. It features inherent privacy enhancements and aims to give users more control over their resources and data. We demonstrate how these principles can be applied to facilitate the composition, deployment and orchestration of complex machine learning workflows, which are becoming increasingly relevant for IoT applications.},
  keywords={Runtime environment;Data privacy;Service-oriented systems engineering;Conferences;Prototypes;Machine learning;Computer architecture},
  doi={10.1109/SOSE52839.2021.00009},
  ISSN={2642-6587},
  month={Aug},}@ARTICLE{9568870,
  author={Cholvi, Vicent and Echagüe, Juan and Anta, Antonio Fernández and Caro, Christopher Thraves},
  journal={IEEE Access}, 
  title={System Stability Under Adversarial Injection of Dependent Tasks}, 
  year={2021},
  volume={9},
  number={},
  pages={139516-139526},
  abstract={Technological changes (NFV, Osmotic Computing, Cyber-physical Systems) are making very important devising techniques to efficiently run a flow of jobs formed by dependent tasks in a set of servers. These problem can be seen as generalizations of the dynamic job-shop scheduling problem, with very rich dependency patterns and arrival assumptions. In this work, we consider a computational model of a distributed system formed by a set of servers in which jobs, that are continuously arriving, have to be executed. Every job is formed by a set of dependent tasks (i. e., each task may have to wait for others to be completed before it can be started), each of which has to be executed in one of the servers. The arrival of jobs and their properties is assumed to be controlled by a bounded adversary, whose only restriction is that it cannot overload any server. This model is a non-trivial generalization of the Adversarial Queuing Theory model of Borodin et al., and, like that model, focuses on the stability of the system: whether the number of jobs pending to be completed is bounded at all times. We show multiple results of stability and instability for this adversarial model under different combinations of the scheduling policy used at the servers, the arrival rate, and the dependence between tasks in the jobs.},
  keywords={Task analysis;Servers;Stability analysis;Computational modeling;Adaptation models;Processor scheduling;Dynamic scheduling;Tasks scheduling;task queuing;dependent tasks;adversarial queuing models;stability},
  doi={10.1109/ACCESS.2021.3119849},
  ISSN={2169-3536},
  month={},}
  @INPROCEEDINGS{9555989,
  author={Rosendo, Daniel and Costan, Alexandru and Antoniu, Gabriel and Simonin, Matthieu and Lombardo, Jean-Christophe and Joly, Alexis and Valduriez, Patrick},
  booktitle={2021 IEEE International Conference on Cluster Computing (CLUSTER)}, 
  title={Reproducible Performance Optimization of Complex Applications on the Edge-to-Cloud Continuum}, 
  year={2021},
  volume={},
  number={},
  pages={23-34},
  abstract={In more and more application areas, we are witnessing the emergence of complex workflows that combine computing, analytics and learning. They often require a hybrid execution infrastructure with IoT devices interconnected to cloud/HPC systems (aka Computing Continuum). Such workflows are subject to complex constraints and requirements in terms of performance, resource usage, energy consumption and financial costs. This makes it challenging to optimize their configuration and deployment. We propose a methodology to support the optimization of real-life applications on the Edge-to-Cloud Continuum. We implement it as an extension of E2Clab, a previously proposed framework supporting the complete experimental cycle across the Edge-to-Cloud Continuum. Our approach relies on a rigorous analysis of possible configurations in a controlled testbed environment to understand their behaviour and related performance tradeoffs. We illustrate our methodology by optimizing Pl@ntNet, a world-wide plant identification application. Our methodology can be generalized to other applications in the Edge-to-Cloud Continuum.},
  keywords={Performance evaluation;Instruction sets;Memory management;Graphics processing units;Production;Reproducibility of results;Time factors;Reproducibility;Methodology;Computing Continuum;Optimization},
  doi={10.1109/Cluster48925.2021.00043},
  ISSN={2168-9253},
  month={Sep.},}@INPROCEEDINGS{9557410,
  author={Alvarez-Napagao, Sergio and Ashmore, Boki and Barroso, Marta and Barrué, Cristian and Beecks, Christian and Berns, Fabian and Bosi, Ilaria and Chala, Sisay Adugna and Ciulli, Nicola and Garcia-Gasulla, Marta and Grass, Alexander and Ioannidis, Dimosthenis and Jakubiak, Natalia and Köpke, Karl and Lämsä, Ville and Megias, Pedro and Nizamis, Alexandros and Pastrone, Claudio and Rossini, Rosaria and Sànchez-Marrè, Miquel and Ziliotti, Luca},
  booktitle={2021 IEEE 19th International Conference on Industrial Informatics (INDIN)}, 
  title={knowlEdge Project –Concept, Methodology and Innovations for Artificial Intelligence in Industry 4.0}, 
  year={2021},
  volume={},
  number={},
  pages={1-7},
  abstract={AI is one of the biggest megatrends towards the 4th industrial revolution. Although these technologies promise business sustainability as well as product and process quality, it seems that the ever-changing market demands, the complexity of technologies and fair concerns about privacy, impede broad application and reuse of Artificial Intelligence (AI) models across the industry. To break the entry barriers for these technologies and unleash its full potential, the knowlEdge project will develop a new generation of AI methods, systems, and data management infrastructure. Subsequently, as part of the knowlEdge project we propose several major innovations in the areas of data management, data analytics and knowledge management including (i) a set of AI services that allows the usage of edge deployments as computational and live data infrastructure as well as a continuous learning execution pipeline on the edge, (ii) a digital twin of the shop-floor able to test AI models, (iii) a data management framework deployed along the edge-to-cloud continuum ensuring data quality, privacy and confidentiality, (iv) Human-AI Collaboration and Domain Knowledge Fusion tools for domain experts to inject their experience into the system, (v) a set of standardisation mechanisms for the exchange of trained AI models from one context to another, and (vi) a knowledge marketplace platform to distribute and interchange trained AI models. In this paper, we present a short overview of the EU Project knowlEdge –Towards Artificial Intelligence powered manufacturing services, processes, and products in an edge-to-cloud-knowledge continuum for humans [in-the-loop], which is funded by the Horizon 2020 (H2020) Framework Programme of the European Commission under Grant Agreement 957331. Our overview includes a description of the project’s main concept and methodology as well as the envisioned innovations.},
  keywords={Industries;Technological innovation;Analytical models;Process control;Europe;Collaboration;Tools;Artificial Intelligence;Machine Learning;Data Analytics;Industry 4.0;Smart Process Manufacturing;Human-AI Collaboration},
  doi={10.1109/INDIN45523.2021.9557410},
  ISSN={},
  month={July},}@INPROCEEDINGS{9556221,
  author={Garbugli, Andrea},
  booktitle={2021 IEEE International Conference on Smart Computing (SMARTCOMP)}, 
  title={PhD Forum Abstract: Ultra-low Latency Communication in TSN-based Virtual Environments}, 
  year={2021},
  volume={},
  number={},
  pages={414-415},
  abstract={The extension of cloud computing concepts to edge devices will lead to the coexistence of a wide range of applications with heterogeneous quality of service (QoS) requirements. Hence the need to move towards a more fluid model based on a continuum of virtual resources. In this paper, we propose a network virtualization model to support applications with ultra-low latency communication requirements and finally compare our results with those of a physical network.},
  keywords={Cloud computing;Fluids;Computational modeling;Conferences;Quality of service;Virtualization;time-sensitive networking;cloud continuum;network virtualization},
  doi={10.1109/SMARTCOMP52413.2021.00088},
  ISSN={2693-8340},
  month={Aug},}@INPROCEEDINGS{9555532,
  author={Apostolou, Dimitris and Verginadis, Yiannis and Mentzas, Gregoris},
  booktitle={2021 12th International Conference on Information, Intelligence, Systems & Applications (IISA)}, 
  title={In the Fog: Application Deployment for the Cloud Continuum}, 
  year={2021},
  volume={},
  number={},
  pages={1-7},
  abstract={Serverless and the Function-as-a-Service (FaaS) paradigms are seen as two enabling technologies for next-generation computing on the cloud continuum. This article discusses prominent frameworks to deploy and monitor applications that span the cloud continuum. It discusses associated challenges and proposes a novel architecture for a framework that manages intelligently multi-cloud, fog and edge resources in order to cope with the requirements of FaaS-enabled applications and services.},
  keywords={Cloud computing;Image edge detection;FAA;Telecommunication traffic;Tools;Throughput;Task analysis;cloud continuum;fog computing;serverless},
  doi={10.1109/IISA52424.2021.9555532},
  ISSN={},
  month={July},}@ARTICLE{9528423,
  author={Giménez-Alventosa, Vicent and Moltó, Germán and Segrelles, J. Damian},
  journal={IEEE Access}, 
  title={TaScaaS: A Multi-Tenant Serverless Task Scheduler and Load Balancer as a Service}, 
  year={2021},
  volume={9},
  number={},
  pages={125215-125228},
  abstract={A combination of distributed multi-tenant infrastructures, such as public Clouds and on-premises installations belonging to different organisations, are frequently used for scientific research because of the high computational requirements involved. Although resource sharing maximises their usage, it typically causes undesirable effects such as the noisy neighbour, producing unpredictable variations of the infrastructure computing capabilities. These fluctuations affect execution efficiency, even of loosely coupled applications, such as many Monte Carlo based simulation programs. This highlights the need of a service capable to handle workload distribution across multiple infrastructures to mitigate these unpredictable performance fluctuations. With this aim, this work introduces TaScaaS, a highly scalable and completely serverless service deployed on AWS to distribute loosely coupled jobs among several computing infrastructures, and load balance them using a completely asynchronous approach to cope with the performance fluctuations with minimum impact in the execution time. We demonstrate how TaScaaS is not only capable of handling these fluctuations efficiently, achieving reduction in execution times up to 45% in our experiments, but also split the jobs to be computed to meet the user-defined execution time.},
  keywords={Task analysis;Cloud computing;Monte Carlo methods;Time factors;Noise measurement;Hardware;Europe;Cloud computing;heterogeneous computing;load balance;serverless},
  doi={10.1109/ACCESS.2021.3109972},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{9524099,
  author={Bacciu, Davide and Akarmazyan, Siranush and Armengaud, Eric and Bacco, Manlio and Bravos, George and Calandra, Calogero and Carlini, Emanuele and Carta, Antonio and Cassarà, Pietro and Coppola, Massimo and Davalas, Charalampos and Dazzi, Patrizio and Degennaro, Maria Carmela and Di Sarli, Daniele and Dobaj, Juergen and Gallicchio, Claudio and Girbal, Sylvain and Gotta, Alberto and Groppo, Riccardo and Lomonaco, Vincenzo and Macher, Georg and Mazzei, Daniele and Mencagli, Gabriele and Michail, Dimitrios and Micheli, Alessio and Peroglio, Roberta and Petroni, Salvatore and Potenza, Rosaria and Pourdanesh, Farank and Sardianos, Christos and Tserpes, Konstantinos and Tagliabó, Fulvio and Valtl, Jakob and Varlamis, Iraklis and Veledar, Omar},
  booktitle={2021 IEEE International Conference on Omni-Layer Intelligent Systems (COINS)}, 
  title={TEACHING - Trustworthy autonomous cyber-physical applications through human-centred intelligence}, 
  year={2021},
  volume={},
  number={},
  pages={1-6},
  abstract={This paper discusses the perspective of the H2020 TEACHING project on the next generation of autonomous applications running in a distributed and highly heterogeneous environment comprising both virtual and physical resources spanning the edge-cloud continuum. TEACHING puts forward a human-centred vision leveraging the physiological, emotional, and cognitive state of the users as a driver for the adaptation and optimization of the autonomous applications. It does so by building a distributed, embedded and federated learning system complemented by methods and tools to enforce its dependability, security and privacy preservation. The paper discusses the main concepts of the TEACHING approach and singles out the main AI-related research challenges associated with it. Further, we provide a discussion of the design choices for the TEACHING system to tackle the aforementioned challenges},
  keywords={Privacy;Conferences;Education;Tools;Collaborative work;Physiology;Security;distributed neural networks;human-centred artificial intelligence;cyber-physical systems;ubiquitous and pervasive computing;edge artificial intelligence},
  doi={10.1109/COINS51742.2021.9524099},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{9500675,
  author={Dizdarević, Jasenka and Jukan, Admela},
  booktitle={ICC 2021 - IEEE International Conference on Communications}, 
  title={Experimental Benchmarking of HTTP/QUIC Protocol in IoT Cloud/Edge Continuum}, 
  year={2021},
  volume={},
  number={},
  pages={1-6},
  abstract={The most recent development in the underlying QUIC transport protocol has revived the interest in HTTP over QUIC (HTTP/3) as a communication protocol solution in cloud and edge computing. This development is notable especially given the rise in implementations of IoT edge/cloud continuum, a new computing paradigm that extends the cloud computing IoT via edge computing systems. In IoT cloud/edge continuum, benchmarking performance of the communication protocol of choice is critical. We focus for the first time on experimental benchmarking of HTTP/3 performance in an IoT cloud/edge continuum system. To benchmark the performance in terms of scalability and latency, we first implement HTTP/3 from a set of non-standardized open-source libraries, - which is challenge, and use the implementation in two main IoT scenarios: edge computing only (IoT devices running HTTP/3 clients and edge devices running an HTTP/3 server), and cloud/edge continuum (based on Google Firebase). Experimental results show that latency and scalability remain a challenge for HTTP/3, but its appeal also remains, in its wide adoption, embedded security and compatibility with existing networked systems.},
  keywords={Performance evaluation;Transport protocols;Cloud computing;Scalability;Benchmark testing;Libraries;Servers},
  doi={10.1109/ICC42927.2021.9500675},
  ISSN={1938-1883},
  month={June},}@INPROCEEDINGS{9499422,
  author={Galletta, Antonino and Sicari, Christian and Celesti, Antonio and Villari, Massimo},
  booktitle={2021 IEEE/ACM 21st International Symposium on Cluster, Cloud and Internet Computing (CCGrid)}, 
  title={OCE-DNS: an innovative Osmotic Computing Enabled Domain Name System}, 
  year={2021},
  volume={},
  number={},
  pages={642-648},
  abstract={Recently, the Osmotic computing paradigm has emerged as a solution to enable the Cloud-Edge-Internet of Things (IoT) continuum. Specifically, it allows dealing with the transparent deployment of distributed services on a combination of Cloud and Edge (or simply Osmotic) nodes, guaranteeing data proximity to end users and IoT devices. In order to optimize applications, software components called Micro ELements (MELs) have to be properly deployed and moved between the Cloud the Edge and the IoT. In this paper, we focus on the MEL addressability problem, intended as the capacity to communicate with the same MEL without caring about its possible migration in different nodes of the same Osmotic Infrastructure. Specifically, we discuss an Osmotic Computing Enabled Domain Name System (OCE-DNS) integrated with the Osmotic Infrastructure, used to address the MELs and to hide their migrations through the use of a dynamic and low latency Resource Record (RR) database containing the real position of the MELs. Specifically, a system prototype developed using a CoreDNS server and an Etcd cluster is discussed and tested showing a good performance in terms of response time and scalability. In order to validate our work, we tested the OCE-DNS in an Osmotic smart city.},
  keywords={Cloud computing;Smart cities;Scalability;Prototypes;Distributed databases;Dynamic scheduling;Domain Name System;Cloud Computing;Edge Computing;Internet of Things;Osmotic Computing;Service Migration;Domain Name System;Cloud Continuum},
  doi={10.1109/CCGrid51090.2021.00077},
  ISSN={},
  month={May},}@INPROCEEDINGS{9499432,
  author={Ferrer, Ana Juan and Becker, Sören and Schmidt, Florian and Thamsen, Lauritz and Kao, Odej},
  booktitle={2021 IEEE/ACM 21st International Symposium on Cluster, Cloud and Internet Computing (CCGrid)}, 
  title={Towards a Cognitive Compute Continuum: An Architecture for Ad-Hoc Self-Managed Swarms}, 
  year={2021},
  volume={},
  number={},
  pages={634-641},
  abstract={In this paper we introduce our vision of a Cognitive Computing Continuum to address the changing IT service provisioning towards a distributed, opportunistic, self-managed collaboration between heterogeneous devices outside the traditional data centre boundaries. The focal point of this continuum are cognitive devices, which have to make decisions autonomously using their on-board computation and storage capacity based on information sensed from their environment. Such devices are moving and cannot rely on fixed infrastructure elements, but instead realise on-the-fly networking and thus frequently join and leave temporal swarms. All this creates novel demands for the underlying architecture and resource management, which must bridge the gap from edge to cloud environments, while keeping the QoS parameters within required boundaries. The paper presents an initial architecture and a resource management framework for the implementation of this type of IT service provisioning.},
  keywords={Cloud computing;Data centers;Processor scheduling;Collaboration;Computer architecture;Quality of service;Sensors;Resource management;edge computing;cloud computing;compute continuum;mesh networks;IoT devices},
  doi={10.1109/CCGrid51090.2021.00076},
  ISSN={},
  month={May},}@ARTICLE{9481776,
  author={Scano, Davide and Paolucci, Francesco and Kondepu, Koteswararao and Sgambelluri, Andrea and Valcarenghi, Luca and Cugini, Filippo},
  journal={Journal of Optical Communications and Networking}, 
  title={Extending P4 in-band telemetry to user equipment for latency- and localization-aware autonomous networking with AI forecasting}, 
  year={2021},
  volume={13},
  number={9},
  pages={D103-D114},
  abstract={In beyond-5G networks, detailed end-to-end monitoring of specific application traffic will be required along with the access-backhaul-cloud continuum to enable low latency service due to local edge steering. Current monitoring solutions are confined to specific network segments. In-band network telemetry (INT) technologies for software defined network (SDN) programmable data planes based on the P4 language are effective in the backhaul network segment, although limited to inter-switch latency; therefore, link latencies including wireless and optical segments are excluded from INT monitoring. Moreover, information such as user equipment (UE) geolocation would allow detailed mobility monitoring and improved cloud-edge steering policies. However, the synchronization between latency and location information, typically provided by different platforms, is hard to achieve with current monitoring systems. In this paper, P4-based INT is proposed to be thoroughly extended involving UE. The INT mechanism is designed to provide synchronized and accurate end-to-end latency and geolocation information, enabling decentralized steering policies, i.e., involving UE and selected switches, without SDN controller intervention. The proposal also includes an artificial-intelligence-assisted forecast system able to predict latency and geolocation in advance and trigger faster edge steering.},
  keywords={Monitoring;5G mobile communication;Optical packet switching;Optical fiber networks;Location awareness;Geology;Telemetry},
  doi={10.1364/JOCN.425891},
  ISSN={1943-0639},
  month={Sep.},}@INPROCEEDINGS{9460542,
  author={Fu, Kaihua and Zhang, Wei and Chen, Quan and Zeng, Deze and Peng, Xin and Zheng, Wenli and Guo, Minyi},
  booktitle={2021 IEEE International Parallel and Distributed Processing Symposium (IPDPS)}, 
  title={QoS-Aware and Resource Efficient Microservice Deployment in Cloud-Edge Continuum}, 
  year={2021},
  volume={},
  number={},
  pages={932-941},
  abstract={User-facing services are now evolving towards the microservice architecture where a service is built by connecting multiple microservice stages. While an entire service is heavy, the microservice architecture shows the opportunity to only offload some microservice stages to the edge devices that are close to the end users. However, emerging techniques often result in the violation of Quality-of-Service (QoS) of microservice-based services in cloud-edge continuum, as they do not consider the communication overhead or the resource contention between microservices.We propose Nautilus, a runtime system that effectively deploys microservice-based user-facing services in cloud-edge continuum. It ensures the QoS of microservice-based user-facing services while minimizing the required computational resources. Nautilus is comprised of a communication-aware microservice mapper, a contention-aware resource manager and a load-aware microservice scheduler. The mapper divides the microservice graph into multiple partitions based on the communication overhead and maps the partitions to the nodes. On each node, the resource manager determines the optimal resource allocation for its microservices based on reinforcement learning that may capture the complex contention behaviors. The microservice scheduler monitors the QoS of the entire service, and migrates microservices from busy nodes to idle ones at runtime. Our experimental results show that Nautilus reduces the computational resource usage by 23.9% and the network bandwidth usage by 53.4%, while achieving the required 99%-ile latency.},
  keywords={Distributed processing;Runtime;Quality of service;Computer architecture;Reinforcement learning;Bandwidth;Resource management},
  doi={10.1109/IPDPS49936.2021.00102},
  ISSN={1530-2075},
  month={May},}@INPROCEEDINGS{9460584,
  author={Luckow, Andre and Rattan, Kartik and Jha, Shantenu},
  booktitle={2021 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)}, 
  title={Pilot-Edge: Distributed Resource Management Along the Edge-to-Cloud Continuum}, 
  year={2021},
  volume={},
  number={},
  pages={874-878},
  abstract={Many science and industry IoT applications necessitate data processing across the edge-to-cloud continuum to meet performance, security, cost, and privacy requirements. However, diverse abstractions and infrastructures for managing resources and tasks across the edge-to-cloud scenario are required. We propose Pilot-Edge as a common abstraction for resource management across the edge-to-cloud continuum. Pilot-Edge is based on the pilot abstraction, which decouples resource and workload management, and provides a Function-as-a-Service (FaaS) interface for application-level tasks. The abstraction allows applications to encapsulate common functions in high-level tasks that can then be configured and deployed across the continuum. We characterize Pilot-Edge on geographically distributed infrastructures using machine learning workloads (e. g., k-means and auto-encoders). Our experiments demonstrate how Pilot-Edge manages distributed resources and allows applications to evaluate task placement based on multiple factors (e. g., model complexities, throughput, and latency).},
  keywords={Industries;Distributed processing;Machine learning;FAA;Throughput;Data processing;Resource management;Edge;cloud;IoT;abstractions;machine learning},
  doi={10.1109/IPDPSW52791.2021.00130},
  ISSN={},
  month={June},}@INPROCEEDINGS{9458887,
  author={Luckow, Andre and Rattan, Kartik and Jha, Shantenu},
  booktitle={2021 IEEE 5th International Conference on Fog and Edge Computing (ICFEC)}, 
  title={Exploring Task Placement for Edge-to-Cloud Applications using Emulation}, 
  year={2021},
  volume={},
  number={},
  pages={79-83},
  abstract={A vast and growing number of IoT applications connect physical devices, such as scientific instruments, technical equipment, machines, and cameras, across heterogenous infrastructure from the edge to the cloud to provide responsive, intelligent services while complying with privacy and security requirements. However, the integration of heterogeneous IoT, edge, and cloud technologies and the design of end-to-end applications that seamlessly work across multiple layers and types of infrastructures is challenging. A significant issue is resource management and the need to ensure that the right type and scale of resources is allocated on every layer to fulfill the application's processing needs. As edge and cloud layers are increasingly tightly integrated, imbalanced resource allocations and sub-optimally placed tasks can quickly deteriorate the overall system performance. This paper proposes an emulation approach for the investigation of task placements across the edge-to-cloud continuum. We demonstrate that emulation can address the complexity and many degrees-of-freedom of the problem, allowing us to investigate essential deployment patterns and trade-offs. We evaluate our approach using a machine learning-based workload, demonstrating the validity by comparing emulation and real-world experiments. Further, we show that the right task placement strategy has a significant impact on performance - in our experiments, between 5% and 65% depending on the scenario.},
  keywords={Privacy;System performance;Instruments;Conferences;Emulation;Resource management;Internet of Things;Edge;cloud;IoT;resource management;emulation},
  doi={10.1109/ICFEC51620.2021.00019},
  ISSN={},
  month={May},}@INPROCEEDINGS{9458899,
  author={Lou, Shuangsheng and Agrawal, Gagan},
  booktitle={2021 IEEE 5th International Conference on Fog and Edge Computing (ICFEC)}, 
  title={Mapping IoT Applications on the Edge to Cloud Continuum with a Filter Stream Model}, 
  year={2021},
  volume={},
  number={},
  pages={61-65},
  abstract={In the context of developing streaming applications for IoT (or Edge Computing) environments, this paper presents a framework for automated deployment with an emphasis on optimizing latency in the presence of resource constraints. A dynamic programming based deployment algorithm is developed to make deployment decisions. With battery power being a key constraint, a major component of our work is a power model to help assess the power consumption of the edge devices at the runtime. Using three applications, we show the large reductions in both power consumption and response latency with our framework, as compared to a baseline involving cloud-only execution.},
  keywords={Power demand;Runtime;Wireless networks;Heuristic algorithms;Conferences;Computational modeling;Dynamic programming;Internet of Things;Streaming Applications;Resource constraints;Latency;Service Deployment},
  doi={10.1109/ICFEC51620.2021.00016},
  ISSN={},
  month={May},}@INPROCEEDINGS{9439129,
  author={EK, Sannara and PORTET, François and LALANDA, Philippe and VEGA, German},
  booktitle={2021 IEEE International Conference on Pervasive Computing and Communications (PerCom)}, 
  title={A Federated Learning Aggregation Algorithm for Pervasive Computing: Evaluation and Comparison}, 
  year={2021},
  volume={},
  number={},
  pages={1-10},
  abstract={Pervasive computing promotes the installation of connected devices in our living spaces in order to provide services. Two major developments have gained significant momentum recently: an advanced use of edge resources and the integration of machine learning techniques for engineering applications. This evolution raises major challenges, in particular related to the appropriate distribution of computing elements along an edge-to-cloud continuum. About this, Federated Learning has been recently proposed for distributed model training in the edge. The principle of this approach is to aggregate models learned on distributed clients in order to obtain a new, more general model. The resulting model is then redistributed to clients for further training. To date, the most popular federated learning algorithm uses coordinate-wise averaging of the model parameters for aggregation. However, it has been shown that this method is not adapted in heterogeneous environments where data is not identically and independently distributed (non-iid). This corresponds directly to some pervasive computing scenarios where heterogeneity of devices and users challenges machine learning with the double objective of generalization and personalization. In this paper, we propose a novel aggregation algorithm, termed FedDist, which is able to modify its model architecture (here, deep neural network) by identifying dissimilarities between specific neurons amongst the clients. This permits to account for clients' specificity without impairing generalization. Furthermore, we define a complete method to evaluate federated learning in a realistic way taking generalization and personalization into account. Using this method, FedDist is extensively tested and compared with three state-of-the-art federated learning algorithms on the pervasive domain of Human Activity Recognition with smartphones.},
  keywords={Pervasive computing;Training;Adaptation models;Machine learning algorithms;Computational modeling;Neurons;Machine learning;Federated Learning;algorithm;evaluation;Human Activity Recognition},
  doi={10.1109/PERCOM50583.2021.9439129},
  ISSN={2474-249X},
  month={March},}@ARTICLE{9434376,
  author={Nguyen, Tuan Anh and Min, Dugki and Choi, Eunmi and Lee, Jae-Woo},
  journal={IEEE Internet of Things Journal}, 
  title={Dependability and Security Quantification of an Internet of Medical Things Infrastructure Based on Cloud-Fog-Edge Continuum for Healthcare Monitoring Using Hierarchical Models}, 
  year={2021},
  volume={8},
  number={21},
  pages={15704-15748},
  abstract={Rising aggressive virus pandemics urge to conduct studies on dependability and security of modern computing systems to secure autonomous and continuous operations of healthcare systems. In that regard, we propose to quantify dependability and security measures of an Internet-of-Medical Things (IoMT) infrastructure relied on an integrated physical architecture of cloud/fog/edge (CFE) computing paradigms in this article. We propose a reliability/availability quantification methodology for the IoMT infrastructure using a hierarchical model of three levels: 1) fault tree (FT) of overall IoMT infrastructure consisting of CFE member systems; 2) FT of subsystems within CFE member systems; and 3) continuous-time Markov chain (CTMC) models of components/devices in the subsystems. We incorporate a number of failure modes for the underlying subsystems, including Mandel-bug related failures and non-Mandel bugs related failure, as well as failures due to cyber-security attacks on software subsystems. Five case-studies of configuration alternation and four operational scenarios of the IoMT infrastructure are considered to comprehend the dependability characteristics of the IoMT physical infrastructure. The metrics of interest include reliability over time, steady state availability (SSA), sensitivity of SSA wrt. selected mean time to failure—equivalent (MTTFeq) and mean time to recovery—equivalent (MTTReq), and sensitivity of SSA wrt. frequencies of cyber-security attacks on software subsystems. The analysis results help comprehend operational behaviors and properties of a typical IoMT infrastructure. The findings of this study can improve the design and implementation of real-world IoMT infrastructures consisting of cloud, fog, and edge computing paradigms.},
  keywords={Security;Medical services;Reliability;Computational modeling;Monitoring;Cloud computing;Data models;Availability;cloud computing;cyber security attack;edge computing;e-health monitoring;fog computing;hierarchical model;Internet of Medical Things (IoMT);reliability},
  doi={10.1109/JIOT.2021.3081420},
  ISSN={2327-4662},
  month={Nov},}@ARTICLE{9426992,
  author={Arulraj, Joy and Chatterjee, Abhijit and Daglis, Alexandros and Dhekne, Ashutosh and Ramachandran, Umakishore},
  journal={Computer}, 
  title={eCloud: A Vision for the Evolution of the Edge-Cloud Continuum}, 
  year={2021},
  volume={54},
  number={5},
  pages={24-33},
  abstract={We present a holistic vision for the edge-cloud ecosystem, with the intent of spurring the creation of next-generation technologies for futuristic applications that operate at computational-perception speeds to convert sensed data to actionable knowledge.},
  keywords={Ecosystems;Next generation networking},
  doi={10.1109/MC.2021.3059737},
  ISSN={1558-0814},
  month={May},}@ARTICLE{9418552,
  author={Nezami, Zeinab and Zamanifar, Kamran and Djemame, Karim and Pournaras, Evangelos},
  journal={IEEE Access}, 
  title={Decentralized Edge-to-Cloud Load Balancing: Service Placement for the Internet of Things}, 
  year={2021},
  volume={9},
  number={},
  pages={64983-65000},
  abstract={The Internet of Things (IoT) requires a new processing paradigm that inherits the scalability of the cloud while minimizing network latency using resources closer to the network edge. On the one hand, building up such flexibility within the edge-to-cloud continuum consisting of a distributed networked ecosystem of heterogeneous computing resources is challenging. On the other hand, IoT traffic dynamics and the rising demand for low-latency services foster the need for minimizing the response time and a balanced service placement. Load-balancing for fog computing becomes a cornerstone for cost-effective system management and operations. This paper studies two optimization objectives and formulates a decentralized load-balancing problem for IoT service placement: (global) IoT workload balance and (local) quality of service (QoS), in terms of minimizing the cost of deadline violation, service deployment, and unhosted services. The proposed solution, EPOS Fog, introduces a decentralized multi-agent system for collective learning that utilizes edge-to-cloud nodes to jointly balance the input workload across the network and minimize the costs involved in service execution. The agents locally generate possible assignments of requests to resources and then cooperatively select an assignment such that their combination maximizes edge utilization while minimizes service execution cost. Extensive experimental evaluation with realistic Google cluster workloads on various networks demonstrates the superior performance of EPOS Fog in terms of workload balance and QoS, compared to approaches such as First Fit and exclusively Cloud-based. The results confirm that EPOS Fog reduces service execution delay up to 25% and the load-balance of network nodes up to 90%. The findings also demonstrate how distributed computational resources on the edge can be utilized more cost-effectively by harvesting collective intelligence.},
  keywords={Internet of Things;Cloud computing;Edge computing;Quality of service;Delays;Servers;Computer architecture;Agent;cloud computing;collective learning;distributed optimization;edge computing;fog computing;Internet of Things (IoT);load-balancing;service placement},
  doi={10.1109/ACCESS.2021.3074962},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{9385525,
  author={Paraskevoulakou, Efterpi and Kyriazis, Dimosthenis},
  booktitle={2021 24th Conference on Innovation in Clouds, Internet and Networks and Workshops (ICIN)}, 
  title={Leveraging the serverless paradigm for realizing machine learning pipelines across the edge-cloud continuum}, 
  year={2021},
  volume={},
  number={},
  pages={110-117},
  abstract={The exceedingly exponential-growing data rate highlighted numerous requirements and several approaches have been released to maximize the added-value of cloud and edge resources. Whereas data scientists utilize algorithmic models in order to transform datasets and extract actionable knowledge, a key challenge is oriented towards abstracting the underline layers: the ones enabling the management of infrastructure resources and the ones responsible to provide frameworks and components as services. In this sense, the serverless approach features as the novel paradigm of new cloud-related technology, enabling the agile implementation of applications and services. The concept of Function as a Service (FaaS) is introduced as a revolutionary model that offers the means to exploit serverless offerings. Developers have the potential to design their applications with the necessary scalability in the form of nanoservices without addressing themselves the way the infrastructure resources should be deployed and managed. By abstracting away the underlying hardware allocations, the data scientist concentrates on the business logic and critical problems of Machine Learning (ML) algorithms. This paper introduces an approach to realize the provision of ML Functions as a Service (i.e., ML-FaaS), by exploiting the Apache OpenWhisk event-driven, distributed serverless platform. The presented approach tackles also composite services that consist of single ones i.e., workflows of ML tasks including processes such as aggregation, cleaning, feature extraction, and analytics; thus, reflecting the complete data path. We also illustrate the operation of the approach mentioned above and assess its performance and effectiveness exploiting a holistic, end-toend anti-fraud detection machine learning pipeline.},
  keywords={Pipelines;FAA;Feature extraction;Data models;Task analysis;Pipeline processing;Business;machine learning;artificial intelligence;serverless;function as a service;cloud computing;edge computing},
  doi={10.1109/ICIN51074.2021.9385525},
  ISSN={2472-8144},
  month={March},}@INPROCEEDINGS{9458062,
  author={Douhara, Ryuki and Hsu, Ying-Feng and Yoshihisa, Tomoki and Matsuda, Kazuhiro and Matsuoka, Morito},
  booktitle={2020 International Conference on Computational Science and Computational Intelligence (CSCI)}, 
  title={Kubernetes-based Workload Allocation Optimizer for Minimizing Power Consumption of Computing System with Neural Network}, 
  year={2020},
  volume={},
  number={},
  pages={1269-1275},
  abstract={Edge computing has been attracting attention due to the spread of the Internet of Things. For edge computing, containerized applications are deployed on multiple machines, and Kubernetes is an essential platform for container orchestration. In this paper, we introduce a Kubernetes based power consumption centric workload allocation optimizer (WAO), including scheduler and load balancer. By using WAO built with power consumption and response time models for actual edge computing system, 9.9% power consumption was reduced compared to original Kubernetes load balancer. This result indicates that the WAO developed in this study exhibits promising potential for task allocation modules as a micro service platform.},
  keywords={Power demand;Scientific computing;Computational modeling;Neural networks;Predictive models;Resource management;Time factors;kubernetes;edge computing;neural network;osmotic computing},
  doi={10.1109/CSCI51800.2020.00238},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{9443969,
  author={Kimovski, Dragi and Bogatinoska, Dijana C. and Mehran, Narges and Karadimce, Aleksandar and Paunkoska, Natasa and Prodan, Radu and Marina, Ninoslav},
  booktitle={2020 IEEE Intl Conf on Parallel & Distributed Processing with Applications, Big Data & Cloud Computing, Sustainable Computing & Communications, Social Computing & Networking (ISPA/BDCloud/SocialCom/SustainCom)}, 
  title={Cloud — Edge Offloading Model for Vehicular Traffic Analysis}, 
  year={2020},
  volume={},
  number={},
  pages={746-753},
  abstract={The proliferation of smart sensing and computing devices, capable of collecting a vast amount of data, has made the gathering of the necessary vehicular traffic data relatively easy. However, the analysis of these big data sets requires computational resources, which are currently provided by the Cloud Data Centers. Nevertheless, the Cloud Data Centers can have unacceptably high latency for vehicular analysis applications with strict time requirements. The recent introduction of the Edge computing paradigm, as an extension of the Cloud services, has partially moved the processing of big data closer to the data sources, thus addressing this issue. Unfortunately, this unlocked multiple challenges related to resources management. Therefore, we present a model for scheduling of vehicular traffic analysis applications with partial task offloading across the Cloud - Edge continuum. The approach represents the traffic applications as a set of interconnected tasks composed into a workflow that can be partially offloaded to the Edge. We evaluated the approach through a simulated Cloud - Edge environment that considers two representative vehicular traffic applications with a focus on video stream analysis. Our results show that the presented approach reduces the application response time up to eight times while improving energy efficiency by a factor of four.},
  keywords={Analytical models;Data centers;Processor scheduling;Image edge detection;Computational modeling;Streaming media;Energy efficiency;Edge offloading;Cloud - Edge continuum;Application Scheduling;Particle Swarm Optimization},
  doi={10.1109/ISPA-BDCloud-SocialCom-SustainCom51426.2020.00119},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{9319337,
  author={Dustdar, Schahram and Murturi, Ilir},
  booktitle={2020 IEEE Second International Conference on Cognitive Machine Intelligence (CogMI)}, 
  title={Towards Distributed Edge-based Systems}, 
  year={2020},
  volume={},
  number={},
  pages={1-9},
  abstract={In the past few years, researchers from academia and industry stakeholders suggest adding more computational resources (i.e., storage, networking, and processing) closer to the end-users and IoT domain, respectively, at the edge of the network. Such computation entities perceived as edge devices aim to overcome high-latency issues between the cloud and the IoT domain. Thus, processing IoT data streams closer to the end-users and IoT domain can solve several operational challenges. Since then, a plethora of application-specific IoT systems are introduced, mainly hard-coded, inflexible, and limited extensibility for future changes. Additionally, most IoT systems maintain a centralized design to operate without considering the dynamic nature of edge networks. In this paper, we discuss some of the research issues, challenges, and potential solutions to enable: i) deploying edge functions on edge resources in a distributed manner and ii) deploying and scaling edge applications on-premises of Edge-Cloud infrastructure. Additionally, we discuss in detail the three-tier Edge-Cloud architecture. Finally, we introduce a conceptual framework that aims to enable easy configuration and deployment of edge-based systems on top of heterogeneous edge infrastructure and present our vision within a smart city scenario.},
  keywords={Internet of Things;Cloud computing;Computer architecture;Servers;Computational modeling;Software as a service;Smart cities;Edge-Cloud Continuum;Edge-based Systems;Distributed Edge Functions},
  doi={10.1109/CogMI50398.2020.00021},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{9315757,
  author={Kaur, Akashdeep and Kumar, Rajesh and Saxena, Sharad},
  booktitle={2020 Sixth International Conference on Parallel, Distributed and Grid Computing (PDGC)}, 
  title={Osmotic Computing and Related Challenges: A Survey}, 
  year={2020},
  volume={},
  number={},
  pages={378-383},
  abstract={Internet of Things (IoT) is associated with a worldwide network of interconnecting devices which are further connected to the internet, thus considerably increasing the number, range and type of devices. These devices provide anywhere and anytime connection to anyone. The IoT devices produce a large volume of data which necessitates data management. Osmotic Computing (OC), a new paradigm is driven by an increase in the resource capability or capacity at the network edge. The process of OC represents how to migrate services across the data centre to the network edge. Thus, it implies the dynamic management of macroservices and microservices across edge and cloud data centres. The goal of this work is to identify key findings of OC.},
  keywords={Cloud computing;Internet of Things;Osmosis;Data centers;Solvents;Edge computing;Computer architecture;Osmotic Computing;IoT;Microservices;Service Migration;MicroELements},
  doi={10.1109/PDGC50313.2020.9315757},
  ISSN={2573-3079},
  month={Nov},}@INPROCEEDINGS{9302804,
  author={Spillner, Josef and Gkikopoulos, Panagiotis and Buzachis, Alina and Villari, Massimo},
  booktitle={2020 IEEE/ACM 13th International Conference on Utility and Cloud Computing (UCC)}, 
  title={Rule-Based Resource Matchmaking for Composite Application Deployments across IoT-Fog-Cloud Continuums}, 
  year={2020},
  volume={},
  number={},
  pages={336-341},
  abstract={Where shall my new shiny application run? Hundreds of such questions are asked by software engineers who have many cloud services at their disposition, but increasingly also many other hosting options around managed edge devices and fog spectrums, including for functions and container hosting (FaaS/CaaS). Especially for composite applications prevalent in this field, the combinatorial deployment space is exploding. We claim that a systematic and automated approach is unavoidable in order to scale functional decomposition applications further so that each hosting facility is fully exploited. To support engineers while they transition from cloud-native to continuum-native, we provide a rule-based matchmaker called RBMM that combines several decision factors typically present in software description formats and applies rules to them. Using the MaestroNG orchestrator and OsmoticToolkit, we also contribute an integration of the matchmaker into an actual deployment environment.},
  keywords={Software;Tools;Cloud computing;Computational modeling;Security;Topology;Runtime;Cloud Computing;Osmotic Computing;Fog Computing;Deployment;Matchmaking},
  doi={10.1109/UCC48980.2020.00053},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{9289875,
  author={Infiesta, José Takeru and Guimarães, Carlos and Contreras, Luis M. and de la Oliva, Antonio},
  booktitle={2020 IEEE Conference on Network Function Virtualization and Software Defined Networks (NFV-SDN)}, 
  title={GANSO: Automate Network Slicing at the Transport Network Interconnecting the Edge}, 
  year={2020},
  volume={},
  number={},
  pages={161-166},
  abstract={5G and Edge computing are two technologies set to impose a paradigm shift from today's traditional networking solutions. In particular, transport networks, which connect distinct computing infrastructures, must guarantee a wide range of performance requirements from coexisting network services. 5G network slicing enables such capability by providing the flexibility to support multiple and isolated virtual networks over the same and shared infrastructure. This paper introduces the GST And Network Slice Operator (GANSO) framework for automating the creation of network slices over SDN architectures, focusing on transport networks interconnecting Edge data centers. To characterise the type of network slice to be deployed, it uses Generic network Slice Templates (GSTs). Initially, five GST attributes are implemented in a proof-of-concept prototype, namely through configurable User Data Access and Rate Limit parameters. It is then validated in a scenario considering the instantiation of network slices over the transport network for different virtual applications hosted across the edge-to-cloud continuum.},
  keywords={Data centers;5G mobile communication;Network slicing;Prototypes;Network function virtualization;Resource management;Software defined networking;Network Slicing;GST;SDN;Transport;Edge},
  doi={10.1109/NFV-SDN50289.2020.9289875},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{9296170,
  author={Hati, Sourav and De, Debashis},
  booktitle={2020 Fifth International Conference on Research in Computational Intelligence and Communication Networks (ICRCICN)}, 
  title={OBSC:Osmotic BlockChain based framework for Smart City Environment}, 
  year={2020},
  volume={},
  number={},
  pages={143-148},
  abstract={Osmotic computing gives a novel worldview in brilliant city design. Numerous analysts have performed to create and to made sure about shrewd city engineering of the internet of-things (IoT) worldview. Security is the fundamental worry of the present exploration. In this situation, BlockChain starts in the time of the IoT worldview. In this proposed work, the creators concentrate on the information security, administration inertness and force utilization of the framework. The proposed feasible smart city technology has ordered into three unique levels, for example, physical level, edge level, and cloud level. Where the edge level is acquainted with the neighborhood BlockChain application and the cloud is utilized for worldwide and computational reason. BlockChain application is structured on the Amazon web administrations interface. The smart city engineering is ready to lessen error just as force utilization is diminished utilizing BlockChain applications. AWS CloudWatch observing apparatus and it additionally shows the status of the worldwide BlockChain database.},
  keywords={Cloud computing;Blockchain;Servers;Power demand;Smart cities;Internet of Things;Osmosis;Internet of Things;Quality of Life;Quality of Service;Cloud computing;Edge Computing;Osmotic Computing;BlockChain;Amazon Web Services},
  doi={10.1109/ICRCICN50933.2020.9296170},
  ISSN={},
  month={Nov},}@ARTICLE{9296826,
  author={Aguzzi, Cristiano and Gigli, Lorenzo and Sciullo, Luca and Trotta, Angelo and Di Felice, Marco},
  journal={IEEE Access}, 
  title={From Cloud to Edge: Seamless Software Migration at the Era of the Web of Things}, 
  year={2020},
  volume={8},
  number={},
  pages={228118-228135},
  abstract={The Web of Things (WoT) standard recently promoted by the W3C constitutes a promising approach to devise interoperable IoT systems able to cope with the heterogeneity of software platforms and devices. The WoT architecture envisages interconnected IoT scenarios characterized by a multitude of Web Things (WTs) that interact according to well-defined software interfaces; at the same time, it assumes static allocations of WTs to hosting devices, and it does not cope with the intrinsic dynamicity of IoT environments in terms of time-varying network and computational loads. In this paper, we extend the WoT paradigm for cloud-edge continuum deployments, hence supporting dynamic orchestration and mobility of WTs among the available computational resources. Differently from state-of-art Mobile Edge Computing (MEC) approaches, we heavily exploit the W3C WoT, and specifically its capability to standardize the software interfaces of the WTs, in order to propose the concept of a Migratable WoT (M-WoT), in which WTs are seamlessly allocated to hosts according to their dynamic interactions. Three main contributions are proposed in this paper. First, we describe the architecture of the M-WoT framework, by focusing on the stateful migration of WTs and on the management of the WT handoff process. Second, we rigorously formulate the WT allocation as a multi-objective optimization problem, and propose a graph-based heuristic. Third, we describe a container-based implementation of M-WoT and a twofold evaluation, through which we assess the performance of the proposed migration policy in a distributed edge computing setup and in a real-world IoT monitoring scenario.},
  keywords={Software;W3C;Computer architecture;Internet of Things;Resource management;Cloud computing;Standards;Web of things (WoT);edge/cloud computing;service migration;software architecture;performance evaluation},
  doi={10.1109/ACCESS.2020.3045632},
  ISSN={2169-3536},
  month={},}@INBOOK{9259599,
  author={Zoualfaghari, Mohammad Hossein and Beddus, Simon and Taherizadeh, Salman},
  booktitle={The Internet of Things: From Data to Insight}, 
  title={Edge Computing}, 
  year={2020},
  volume={},
  number={},
  pages={21-35},
  abstract={Edge computing provides data processing geographically close to assets such as sensors, actuators, Internet of Things (IoT) objects, and humans. Practically, edge computing devices can be located in the customer's premises or at the edge of the communication service provider's network adjacent to the access network. This chapter provides a comprehensive overview of edge computing including: fundamentals of edge computing; edge computing architecture; and the way to implement edge computing solutions. It also includes a modern approach of zero‐touch device on‐boarding that enables devices to power on and automatically register themselves within the owner's centralized IoT platform very quickly, along with creating a privacy‐protected and a secure device baseline. The chapter also outlines various real‐world applications of edge computing. An attractive field of further research would be the investigation of additional modern computing techniques such as fog and osmotic computing, and how these approaches can extend and enhance edge computing capabilities.},
  keywords={Edge computing;Cloud computing;Sensors;Servers;Internet of Things;Security;Actuators},
  doi={10.1002/9781119545293.ch3},
  ISSN={},
  publisher={Wiley},
  isbn={9781119545286},
  url={https://ieeexplore.ieee.org/document/9259599},}@ARTICLE{9233375,
  author={Silva, Daniel Maniglia Amancio Da and Sofia, Rute C.},
  journal={IEEE Access}, 
  title={A Discussion on Context-Awareness to Better Support the IoT Cloud/Edge Continuum}, 
  year={2020},
  volume={8},
  number={},
  pages={193686-193694},
  abstract={This article debates on notions of context-awareness as a relevant asset of networking and computing architectures for an Internet of Things (IoT), in particular in regards to a smoother support of the the networking operation between Cloud and Edge. Specifically, the paper debates on notions of context-awareness and goes over different types of context-awareness indicators that are being applied to Edge selection algorithms, covering the approaches currently used, the role of the algorithms applied, their scope, and contemplated performance metrics. Lastly, the paper provides guidelines for future research in the context of Cloud-Edge and the application of context-awareness to assist in a higher degree of automation of the network and, as consequence, a better support of the Cloud to Edge continuum.},
  keywords={Cloud computing;Intelligent sensors;Computer architecture;Smart cities;Context-awareness;Internet of Things (IoT);edge/fog computing},
  doi={10.1109/ACCESS.2020.3032388},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{9219597,
  author={Galletta, Antonino and Fazio, Maria and Celesti, Antonio and Villari, Massimo},
  booktitle={2020 IEEE Symposium on Computers and Communications (ISCC)}, 
  title={On the Applicability of Secret Share Algorithms for Osmotic Computing}, 
  year={2020},
  volume={},
  number={},
  pages={1-6},
  abstract={Osmotic Computing (OC) is an innovative computation paradigm that runs services on Cloud, Edge, and Internet of Things (IoT) resources based on their workload. Services are encapsulated in container images stored into a central repository on the Cloud. OC suffers from privacy and security issues, for example, hackers could attack the repository and download all container images. Furthermore, network latency could delay the deployment of services in Edge nodes. A possible solution to solve such problems is to employ Secret Share techniques to split the images of services into chunks and distribute them among Edge devices. This work aims at assessing the applicability of these techniques for OC employing the Redundant Residue Number System (RRNS) to split and store Micro-Elements (MELs). We made our analyses for different OC scenarios composed of 10, 100 and 1000 nodes running 1000 MELs each. Furthermore, we considered several degrees of redundancy from 0 to 7. From experimental analyses, we found that the reliability of the system increase with the increasing of the redundancy but the security decreases.},
  keywords={Cloud computing;Privacy;Image edge detection;Redundancy;Urban areas;Logic gates;Containers;Secret Share;Osmotic Computing;Smart Cities;RRNS},
  doi={10.1109/ISCC50000.2020.9219597},
  ISSN={2642-7389},
  month={July},}@INPROCEEDINGS{9170993,
  author={Kassir, Saadallah and Veciana, Gustavo de and Wang, Nannan and Wang, Xi and Palacharla, Paparao},
  booktitle={2020 7th IEEE International Conference on Cyber Security and Cloud Computing (CSCloud)/2020 6th IEEE International Conference on Edge Computing and Scalable Cloud (EdgeCom)}, 
  title={Service Placement for Real-Time Applications: Rate-Adaptation and Load-Balancing at the Network Edge}, 
  year={2020},
  volume={},
  number={},
  pages={207-215},
  abstract={Mobile Edge Computing may become a prevalent platform to support applications where mobile devices have limited compute, storage, energy and/or data privacy concerns. In this paper, we study the efficient provisioning and management of compute resources in the Edge-to-Cloud continuum for different types of real-time applications with timeliness requirements depending on application-level update rates and communication/compute delays. We begin by introducing a highly stylized network model allowing us to study the salient features of this problem including its sensitivity to compute vs. communication costs, application requirements, and traffic load variability. We then propose an online decentralized service placement algorithm, based on estimating network delays and adapting application update rates, which achieves high service availability. Our results exhibit how placement can be optimized and how a load-balancing strategy can achieve near-optimal service availability in large networks.},
  keywords={Cloud computing;Sensitivity;Multi-access edge computing;Conferences;Telecommunication traffic;Real-time systems;Mobile handsets;Edge Computing;Fog Network Dimensioning;Rate Adaptation;Service Placement;Real-Time Applications},
  doi={10.1109/CSCloud-EdgeCom49738.2020.00044},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{9144760,
  author={Carvalho, Liliana I. and da Silva, Daniel Maniglia A. and Sofia, Rute Carvalho},
  booktitle={2020 Fifth International Conference on Fog and Mobile Edge Computing (FMEC)}, 
  title={Leveraging Context-awareness to Better Support the IoT Cloud-Edge Continuum}, 
  year={2020},
  volume={},
  number={},
  pages={356-359},
  abstract={Novel Internet of Things (IoT) requirements derived from a broader interconnection of heterogeneous devices have pushed the horizons of Cloud computing and are giving rise to a wider decentralisation of applications and data centers. An answer to the underlying network concerns, such as the need to lower the resulting latency due to heavy computation needs, or safety aspects, gave rise to Edge/Fog computing, where IoT functionality can be also supported closer to data sources. While it is today feasible to perform some IoT functionality on the Edge, the orchestration of operations between Edge and Cloud requires an automated support, where context-awareness plays a key role in assisting the network in deciding when and where to store data and to perform computation. This work is focused on the application of context-awareness to support a smoother operation of the Edge to Cloud operation, aiming at lowering latency, in particular when real-time or close-to-real-time data exchange is present.},
  keywords={Edge computing;Cloud computing;Sensors;Quality of service;Computer architecture;Internet of Things;Programming},
  doi={10.1109/FMEC49853.2020.9144760},
  ISSN={},
  month={April},}@INPROCEEDINGS{9134320,
  author={Martín, Cristian and Torres, Daniel R. and Díaz, Manuel and Rubio, Bartolomé},
  booktitle={2020 9th Mediterranean Conference on Embedded Computing (MECO)}, 
  title={FogPi: A Portable Fog Infrastructure through Raspberry Pis}, 
  year={2020},
  volume={},
  number={},
  pages={1-3},
  abstract={Nowadays, Fog computing is facing the requirements of time-sensitive applications in the IoT-cloud continuum. These requirements are decisive for mission-critical applications like structural health monitoring. In this paper, a portable Fog computing infrastructure, known as FogPi, is presented. This infrastructure has been designed around Raspberry Pi, which offers a low-cost and scalable solution for running containerized applications. FogPi allows the deployment, management, and orchestration of Docker containers and is especially suitable for environments where the limited Internet connection and reduced budgets limit the adoption of Fog and Edge deployments.},
  keywords={Performance evaluation;Cloud computing;Three-dimensional displays;Modal analysis;Mission critical systems;Containers;Load management},
  doi={10.1109/MECO49872.2020.9134320},
  ISSN={2637-9511},
  month={June},}@ARTICLE{9125436,
  author={Rasool, Saqib and Saleem, Afshan and Iqbal, Muddessar and Dagiuklas, Tasos and Bashir, Ali Kashif and Mumtaz, Shahid and Otaibi, Sattam Al},
  journal={IEEE Internet of Things Magazine}, 
  title={Blockchain-Enabled Reliable Osmotic Computing for Cloud of Things: Applications and Challenges}, 
  year={2020},
  volume={3},
  number={2},
  pages={63-67},
  abstract={Cloud of Things (CoT) refers to an IoT solution consuming the cloud services of a single cloud vendor. In this article, we have introduced the concept of a MultiCoT (http://www.MultiCoT.com) solution which refers to the collaborative execution of an IoT solution by multiple cloud vendors. Cloudlets and ad-hoc clouds are the extensions of centralized cloud services, closer to the user, in the form of fog and edge computing layers respectively and the Osmotic Computing (OC) serves as a glue by accomplishing the seamless compute sharing across these layers. The OC can also be integrated within a MultiCoT solution for extending it across three computational layers of cloud, fog and edge. However, this can only be achieved after establishing enough trust among all the vendors that are working in collaboration to simultaneously serve a particular MultiCoT solution. Blockchain has been already proven for establishing trust and supporting reliable interactions among independently operating entities. Hence, it can be used for establishing trust among the multiple cloud vendors serving a single MultiCoT solution. In this article, we have presented the importance of using the proactive Blockchain-enabled Osmotic Manager (B-OM) for improving the reliability of OC. We have also highlighted the blockchain features that can improve the reliability of OC by establishing trust among the independently operating vendors of a MultiCoT solution, followed by the challenges associated with the integration of blockchain and OC along with the future research directions for achieving the proposed integration.},
  keywords={Cloud computing;Blockchain;Reliability;Smart contracts;Consensus algorithm;Edge computing;Mobile handsets},
  doi={10.1109/IOTM.0001.1900101},
  ISSN={2576-3199},
  month={June},}@INPROCEEDINGS{9120680,
  author={Hou, Shiming and Li, Hongjia and Yang, Chang and Wang, Liming},
  booktitle={2020 IEEE Wireless Communications and Networking Conference (WCNC)}, 
  title={A New Privacy-Preserving Framework based on Edge-Fog-Cloud Continuum for Load Forecasting}, 
  year={2020},
  volume={},
  number={},
  pages={1-8},
  abstract={As an essential part to intelligently fine-grained scheduling, planning and maintenance in smart grid and energy internet, short-term load forecasting makes great progress recently owing to the big data collected from smart meters and the leap forward in machine learning technologies. However, the centralized computing topology of classical electric information system, where individual electricity consumption data are frequently transmitted to the cloud center for load forecasting, tends to violate electric consumers’ privacy as well as to increase the pressure on network bandwidth. To tackle the tricky issues, we propose a privacy-preserving framework based on the edge-fog-cloud continuum for smart grid. Specifically, 1) we gravitate the training of load forecasting models and forecasting workloads to distributed smart meters so that consumers’ raw data are handled locally, and only the forecasting outputs that have been protected are reported to the cloud center via fog nodes; 2) we protect the local forecasting models that imply electricity features from model extraction attacks by model randomization; 3) we exploit a shuffle scheme among smart meters to protect the data ownership privacy, and utilize a re-encryption scheme to guarantee the forecasting data privacy. Finally, through comprehensive simulation and analysis, we validate our proposed privacy-preserving framework in terms of privacy protection, and computation and communication efficiency.},
  keywords={Data privacy;Cloud computing;Load forecasting;Computational modeling;Predictive models;Data models;Smart meters},
  doi={10.1109/WCNC45663.2020.9120680},
  ISSN={1558-2612},
  month={May},}@INPROCEEDINGS{9101225,
  author={Alkhabbas, Fahed and Murturi, Ilir and Spalazzese, Romina and Davidsson, Paul and Dustdar, Schahram},
  booktitle={2020 IEEE International Conference on Software Architecture (ICSA)}, 
  title={A Goal-Driven Approach for Deploying Self-Adaptive IoT Systems}, 
  year={2020},
  volume={},
  number={},
  pages={146-156},
  abstract={Engineering Internet of Things (IoT) systems is a challenging task partly due to the dynamicity and uncertainty of the environment including the involvement of the human in the loop. Users should be able to achieve their goals seamlessly in different environments, and IoT systems should be able to cope with dynamic changes. Several approaches have been proposed to enable the automated formation, enactment, and self-adaptation of goal-driven IoT systems. However, they do not address deployment issues. In this paper, we propose a goal-driven approach for deploying self-adaptive IoT systems in the Edge-Cloud continuum. Our approach supports the systems to cope with the dynamicity and uncertainty of the environment including changes in their deployment topologies, i.e., the deployment nodes and their interconnections. We describe the architecture and processes of the approach and the simulations that we conducted to validate its feasibility. The results of the simulations show that the approach scales well when generating and adapting the deployment topologies of goal-driven IoT systems in smart homes and smart buildings.},
  keywords={Topology;Cloud computing;Computer architecture;Internet of Things;Buildings;Adaptation models;Software;Deploying Self adaptive IoT Systems;Goal driven IoT Systems;Edge-Cloud Continuum;Software Architecture},
  doi={10.1109/ICSA47634.2020.00022},
  ISSN={},
  month={March},}@INPROCEEDINGS{9095740,
  author={Alkhabbas, Fahed and Spalazzese, Romina and Cerioli, Maura and Leotta, Maurizio and Reggio, Gianna},
  booktitle={2020 IEEE International Conference on Software Architecture Companion (ICSA-C)}, 
  title={On the Deployment of IoT Systems: An Industrial Survey}, 
  year={2020},
  volume={},
  number={},
  pages={17-24},
  abstract={Internet of Things (IoT) systems are complex and multifaceted, and the design of their architectures needs to consider many aspects at a time. Design decisions concern, for instance, the modeling of software components and their interconnections, as well as where to deploy the components within the available hardware infrastructure in the Edge-Cloud continuum. A relevant and challenging task, in this context, is to identify optimal deployment models due to all the different aspects involved, such as extra-functional requirements of the system, heterogeneity of the hardware resources concerning their processing and storage capabilities, and constraints like legal issues and operational cost limits. To gain insights about the deployment decisions concerning IoT systems in practice, and the factors that influence those decisions, we report about an industrial survey we conducted with 66 IoT architects from 18 countries across the world. Each participant filled in a questionnaire that comprises 15 questions. By analyzing the collected data, we have two main findings: (i) architects rely on the Cloud more than the Edge for deploying the software components of IoT systems, in the majority of the IoT application domains; and (ii) the main factors driving deployment decisions are four: reliability, performance, security, and cost.},
  keywords={Hardware;Software;Computer architecture;Cloud computing;Unified modeling language;Sociology;Statistics;Industrial Survey;Deployment of IoT Systems;Deployment Decisions Drivers;Edge-Cloud Continuum},
  doi={10.1109/ICSA-C50368.2020.00012},
  ISSN={},
  month={March},}@INPROCEEDINGS{9188238,
  author={Pohl, Angela and Greese, Mirko and Cosenza, Biagio and Juurlink, Ben},
  booktitle={2019 International Conference on High Performance Computing & Simulation (HPCS)}, 
  title={A Performance Analysis of Vector Length Agnostic Code}, 
  year={2019},
  volume={},
  number={},
  pages={159-164},
  abstract={Vector extensions are a popular mean to exploit data parallelism in applications. Over recent years, the most commonly used extensions have been growing in vector length and amount of vector instructions. However, code portability remains a problem when speaking about a compute continuum. Hence, vector length agnostic (VLA) architectures have been proposed for the future generations of ARM and RISC-V processors. With these architectures, code is vectorized independently of the vector length of the target hardware platform. It is therefore possible to tune software to a generic vector length. To understand the performance impact of VLA code compared to vector length specific code, we analyze the current capabilities of code generation for ARM's SVE architecture. Our experiments show that VLA code reaches about 90% of the performance of vector length specific code, i.e. a 10% overhead is inferred due to global predication of instructions. Furthermore, we show that code performance is not increasing proportionally with increasing vector lengths due to the higher memory demands.},
  keywords={Neon;Hardware;Computer architecture;Program processors;Registers;Kernel;Benchmark testing;vectorization;SIMD;vector length agnostic;SVE},
  doi={10.1109/HPCS48598.2019.9188238},
  ISSN={},
  month={July},}@INPROCEEDINGS{9088011,
  author={Jin, Yi and Xu, Jiawei and Huan, Yuxiang and Yan, Yulong and Zheng, Lirong and Zou, Zhuo},
  booktitle={2019 32nd IEEE International System-on-Chip Conference (SOCC)}, 
  title={Energy-Aware Workload Allocation for Distributed Deep Neural Networks in Edge-Cloud Continuum}, 
  year={2019},
  volume={},
  number={},
  pages={213-217},
  abstract={This paper presents an energy-aware workload allocation framework for Distributed Deep Neural Networks (DNNs) in the Edge-Cloud continuum. As opposed to conventional approaches where the inference is performed in a standalone device, a computing-communication mode is proposed to distribute computing tasks of different layers of DNNs to different levels of the Edge-Cloud network to achieve the minimum energy cost per inference. The optimal exit layer (EL) can be determined where the intermediate data of the neural networks are transmitted to the higher level in the Edge-Cloud continuum. Case studies are illustrated for AlexNet and VGG-16 considering a set of DNN processors and wireless interfaces. Using the GPU GTX1080 with 22.8 GOPS/W and the WiFi with 10 nJ/bit transmission efficiency, the optimized energy consumption for AlexNet is estimated to be 0.016 J when the inference exits from the edge at the EL2 (Conv1) layer. For VGG-16, the optimal EL is EL1 with the minimum inference cost of 0.0482 J.},
  keywords={},
  doi={10.1109/SOCC46988.2019.1570554761},
  ISSN={2164-1706},
  month={Sep.},}@INPROCEEDINGS{8969621,
  author={Buzachis, Alina and Galletta, Antonino and Celesti, Antonio and Carnevale, Lorenzo and Villari, Massimo},
  booktitle={2019 IEEE Symposium on Computers and Communications (ISCC)}, 
  title={Towards Osmotic Computing: a Blue-Green Strategy for the Fast Re-Deployment of Microservices}, 
  year={2019},
  volume={},
  number={},
  pages={1-6},
  abstract={The rapid development of Cloud, Edge, Fog Computing and Internet of Things (IoT) technologies has played a key role in the Industry 4.0 evolution. In this context, the Osmotic Computing paradigm, theorized in 2016 as integration between a centralized Cloud layer and Edge and/or IoT layers, has further emphasized the Industry 4.0 objectives including productivity and Quality of Services (QoS). This emerging paradigm proposes a new elastic management model of microservices, where deployment and migration strategies are strongly related to the underlaying infrastructure requirements (i.e., load balancing, reliability, availability, and so on) and applications (i.e., anomalies detection, awareness of the context, proximity, QoS, and so on). Specifically, knowing that an Osmotic application must have a failover behavior (highly horizontally/vertically scalable, 24 hours 24 available, fault-tolerant and secure), this paper highlights the Osmotic ecosystem platform focusing on the implementation of a blue-green mechanism for the fast re-deployment of microservices, exploiting emerging technologies, such as Docker, Kubernetes, Agento and MongoDB. Experiments shows the time required to arrange, deploy and destroy microservices.},
  keywords={Cloud computing;Computer architecture;Containers;Internet of Things;Quality of service;Monitoring;Measurement;Osmotic Computing;Cloud Computing;Edge Computing;IoT;Orchestration;Microservice.},
  doi={10.1109/ISCC47284.2019.8969621},
  ISSN={2642-7389},
  month={June},}@INPROCEEDINGS{8939171,
  author={Cao, Hung and Wachowicz, Monica},
  booktitle={2019 Sixth International Conference on Internet of Things: Systems, Management and Security (IOTSMS)}, 
  title={Analytics Everywhere for Streaming IoT Data}, 
  year={2019},
  volume={},
  number={},
  pages={18-25},
  abstract={Exploring new insights from IoT data means not only providing higher-level intelligence in a timely way but also generating long-term predictions and decisions from historical IoT data. This paper aims to explore the synergy of various data rates, message passing, and processing algorithms to support streaming analytics at the edge, fog, and cloud computing environments. Towards this end, we present an IoT architecture that is capable of capturing, managing, processing, analyzing, and visualizing IoT data streams. For validation purposes, a smart parking scenario is used to evaluate our architecture.},
  keywords={IoT data streams;streaming analytics;smart parking;IoT architecture;integrated fabric;edge/fog/cloud continuum},
  doi={10.1109/IOTSMS48152.2019.8939171},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{8821021,
  author={Kochovski, Petar and Sakellariou, Rizos and Bajec, Marko and Drobintsev, Pavel and Stankovski, Vlado},
  booktitle={2019 IEEE International Parallel and Distributed Processing Symposium (IPDPS)}, 
  title={An Architecture and Stochastic Method for Database Container Placement in the Edge-Fog-Cloud Continuum}, 
  year={2019},
  volume={},
  number={},
  pages={396-405},
  abstract={Databases as software components may be used to serve a variety of smart applications. Currently, the Internet of Things (IoT), Artificial Intelligence (AI) and Cloud technologies are used in the course of projects such as the Horizon 2020 EU-Korea DECENTER project in order to implement four smart applications in the domains of Smart Homes, Smart Cities, Smart Construction and Robot Logistics. In these smart applications the Big Data pipeline starts from various sensor and video streams to which AI and feature extraction methods are applied. The resulting information is stored in database containers, which have to be placed on Edge, Fog or Cloud infrastructures. The placement decision depends on complex application requirements, including Quality of Service (QoS) requirements. Information that must be considered when making placement decisions includes the expected workload, the list of candidate infrastructures, geolocation, connectivity and similar. Software engineers currently perform such decisions manually, which usually leads to QoS threshold violations. This paper aims to automate the process of making such decisions. Therefore, the goals of this paper are to: (1) develop a decision making method for database container placement; (2) formally verify each placement decision and provide probability assurances to the software engineer for high QoS; and (3) design and implement a new architecture that automates the whole process. A new optimisation method is introduced, which is based on the theory and practice of stochastic Markov Decision Processes (MDP). It uses as input monitoring data from the container runtime, the expected workload and user-related metrics in order to automatically construct a probabilistic finite automaton. The generated automaton is used for both automated decision making and placement success verification. The method is implemented in Java. It also uses the PRISM model-checking tool. Kubernetes is used in order to automate the whole process when orchestrating database containers across Edge, Fog and Cloud infrastructures. Experiments are performed for NoSQL Cassandra database containers for three representative workloads of 50000 (workload 1), 200000 (workload 2) and 500000 (workload 3) CRUD database operations. Five computing infrastructures serve as candidates for database container placement. The new MDP-based method is compared with the widely used Analytic Hierarchy Process (AHP) method. The obtained results are used to analyse container placement decisions. When using the new MDP based method there were no QoS violations in any of the placement cases, while when using the AHP based method the placement results in some QoS threshold violations in all workload cases. Due to its properties, the new MDP method is particularly suitable for implementation. The paper also describes a multi-tier distributed computing system that uses multi-level (infrastructure, container, application) monitoring metrics and Kubernetes in order to orchestrate database containers across Edge, Fog and Cloud nodes. This architecture demonstrates fully automated decision making and high QoS container operation.},
  keywords={Containers;Quality of service;Databases;Software;Cloud computing;Decision making;Probabilistic logic;Cloud;Fog;Edge;storage;probabilistic decision making;containers},
  doi={10.1109/IPDPS.2019.00050},
  ISSN={1530-2075},
  month={May},}@INPROCEEDINGS{8795320,
  author={Karamoozian, Amir and Hafid, Abdelhakim and Aboulhamid, El Mostapha},
  booktitle={2019 Fourth International Conference on Fog and Mobile Edge Computing (FMEC)}, 
  title={On the Fog-Cloud Cooperation: How Fog Computing can address latency concerns of IoT applications}, 
  year={2019},
  volume={},
  number={},
  pages={166-172},
  abstract={Fog computing emerged as a new computing paradigm which moves the computing power to the proximity of users, from core to the edge of the network. It is known as the extension of Cloud computing and it offers inordinate opportunities for real-time and latency-sensitive IoT applications. An IoT application consists of a set of dependent Processing Elements (PEs) defined as operations performed on data streams and can be modeled as a Directed Acyclic Graph (DAG). Each PE performs a variety of low-level computation on the incoming data such as aggregation or filtering. A key challenge is to decide how to distribute such PEs over the resources, in order to minimize the overall response time of the entire PE graph. This problem is known as distributed PE scheduling and placement problem. In this work, we try to address the question of how fog computing paradigm can help reducing the IoT application response time by efficiently distributing PE graphs over the Fog-Cloud continuum. We mathematically formulate the fundamental characteristics of IoT application and Fog infrastructure, then model the system as an optimization problem using Gravitational Search Algorithm (GSA) meta-heuristic technique. Our proposed GSA model is evaluated by comparing it with a well-known evolutionary algorithm in the literature via simulation. Also, a comparative analysis with the legacy cloud infrastructure is done in order to show the significant impact of fog presence on the performance of PE processing. Evaluation of our model demonstrates the efficiency of our approach comparing to the current literature.},
  keywords={Internet of Things;IoT stream processing;Fog/Cloud Computing;Scheduling and Placement optimization},
  doi={10.1109/FMEC.2019.8795320},
  ISSN={},
  month={June},}@ARTICLE{8781958,
  author={Villari, Massimo and Fazio, Maria and Dustdar, Schahram and Rana, Omer and Jha, Devki Nandan and Ranjan, Rajiv},
  journal={Computer}, 
  title={Osmosis: The Osmotic Computing Platform for Microelements in the Cloud, Edge, and Internet of Things}, 
  year={2019},
  volume={52},
  number={8},
  pages={14-26},
  abstract={Rapid growth and evolution in the number, functionalities, and scope of Internet of Things devices is evident. We present osmotic computing as a new paradigm able to respond to resource heterogeneity, secure data exchange, and efficient microservices deployment across federated cloud systems.},
  keywords={Internet of Things;Cloud computing;Osmosis;Data centers;Edge computing;Computational modeling;Sensors},
  doi={10.1109/MC.2018.2888767},
  ISSN={1558-0814},
  month={Aug},}@INPROCEEDINGS{8771621,
  author={Zou, Zhuo and Jin, Yi and Nevalainen, Paavo and Huan, Yuxiang and Heikkonen, Jukka and Westerlund, Tomi},
  booktitle={2019 IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS)}, 
  title={Edge and Fog Computing Enabled AI for IoT-An Overview}, 
  year={2019},
  volume={},
  number={},
  pages={51-56},
  abstract={In recent years, Artificial Intelligence (AI) has been widely deployed in a variety of business sectors and industries, yielding numbers of revolutionary applications and services that are primarily driven by high-performance computation and storage facilities in the cloud. On the other hand, embedding intelligence into edge devices is highly demanded by emerging applications such as autonomous systems, human-machine interactions, and the Internet of Things (IoT). In these applications, it is advantageous to process data near or at the source of data to improve energy & spectrum efficiency and security, and decrease latency. Although the computation capability of edge devices has increased tremendously during the past decade, it is still challenging to perform sophisticated AI algorithms in these resource-constrained edge devices, which calls for not only low-power chips for energy efficient processing at the edge but also a system-level framework to distribute resources and tasks along the edge-cloud continuum. In this overview, we summarize dedicated edge hardware for machine learning from embedded applications to sub-mW “always-on” IoT nodes. Recent advances of circuits and systems incorporating joint design of architectures and algorithms will be reviewed. Fog computing paradigm that enables processing at the edge while still offering the possibility to interact with the cloud will be covered, with focus on opportunities and challenges of exploiting fog computing in AI as a bridge between the edge device and the cloud.},
  keywords={Cloud computing;Edge computing;Artificial intelligence;Computer architecture;Hardware;Internet of Things;Computational modeling;Internet of Things;Artificial Intelligence;Edge AI;Machine Learning;Fog computing;Edge computing;Embedded Processor},
  doi={10.1109/AICAS.2019.8771621},
  ISSN={},
  month={March},}@ARTICLE{8683979,
  author={Gamal, Marwa and Rizk, Rawya and Mahdi, Hani and Elnaghi, Basem E.},
  journal={IEEE Access}, 
  title={Osmotic Bio-Inspired Load Balancing Algorithm in Cloud Computing}, 
  year={2019},
  volume={7},
  number={},
  pages={42735-42744},
  abstract={Cloud computing is increasing rapidly as a successful paradigm presenting on-demand infrastructure, platform, and software services to clients. Load balancing is one of the important issues in cloud computing to distribute the dynamic workload equally among all the nodes to avoid the status that some nodes are overloaded while others are underloaded. Many algorithms have been suggested to perform this task. Recently, worldview is turning into a new paradigm for optimization search by applying the osmosis theory from chemistry science to form osmotic computing. Osmotic computing is aimed to achieve balance in highly distributed environments. The main goal of this paper is to propose a hybrid metaheuristics technique which combines the osmotic behavior with bio-inspired load balancing algorithms. The osmotic behavior enables the automatic deployment of virtual machines (VMs) that are migrated through cloud infrastructures. Since the hybrid artificial bee colony and ant colony optimization proved its efficiency in the dynamic environment in cloud computing, the paper then exploits the advantages of these bio-inspired algorithms to form an osmotic hybrid artificial bee and ant colony (OH_BAC) optimization load balancing algorithm. It overcomes the drawbacks of the existing bio-inspired algorithms in achieving load balancing between physical machines. The simulation results show that OH_BAC decreases energy consumption, the number of VMs migrations and the number of shutdown hosts compared to existing algorithms. In addition, it enhances the quality of services (QoSs) which is measured by service level agreement violation (SLAV) and performance degradation due to migrations (PDMs).},
  keywords={Cloud computing;Load management;Heuristic algorithms;Osmosis;Birds;Software;Ant colony optimization;Ant colony optimization;artificial bee colony;bio-inspired systems;cloud computing;load balancing;metaheuristics;osmotic computing},
  doi={10.1109/ACCESS.2019.2907615},
  ISSN={2169-3536},
  month={},}@ARTICLE{8643424,
  author={Qiao, Xiuquan and Ren, Pei and Dustdar, Schahram and Liu, Ling and Ma, Huadong and Chen, Junliang},
  journal={Proceedings of the IEEE}, 
  title={Web AR: A Promising Future for Mobile Augmented Reality—State of the Art, Challenges, and Insights}, 
  year={2019},
  volume={107},
  number={4},
  pages={651-666},
  abstract={Mobile augmented reality (Mobile AR) is gaining increasing attention from both academia and industry. Hardware-based Mobile AR and App-based Mobile AR are the two dominant platforms for Mobile AR applications. However, hardware-based Mobile AR implementation is known to be costly and lacks flexibility, while the App-based one requires additional downloading and installation in advance and is inconvenient for cross-platform deployment. In comparison, Web-based AR (Web AR) implementation can provide a pervasive Mobile AR experience to users thanks to the many successful deployments of the Web as a lightweight and cross-platform service provisioning platform. Furthermore, the emergence of 5G mobile communication networks has the potential to enhance the communication efficiency of Mobile AR dense computing in the Web-based approach. We conjecture that Web AR will deliver an innovative technology to enrich our ways of interacting with the physical (and cyber) world around us. This paper reviews the state-of-the-art technology and existing implementations of Mobile AR, as well as enabling technologies and challenges when AR meets the Web. Furthermore, we elaborate on the different potential Web AR provisioning approaches, especially the adaptive and scalable collaborative distributed solution which adopts the osmotic computing paradigm to provide Web AR services. We conclude this paper with the discussions of open challenges and research directions under current 3G/4G networks and the future 5G networks. We hope that this paper will help researchers and developers to gain a better understanding of the state of the research and development in Web AR and at the same time stimulate more research interest and effort on delivering life-enriching Web AR experiences to the fast-growing mobile and wireless business and consumer industry of the 21st century.},
  keywords={Augmented reality;5G mobile communication;Performance evaluation;Mobile handsets;Cloud computing;Research and development;Communication networks;5G;augmented reality (AR);cloud computing;edge computing;mixed reality;mobile augmented reality (Mobile AR);osmotic computing;virtual reality (VR);Web-based augmented reality (Web AR)},
  doi={10.1109/JPROC.2019.2895105},
  ISSN={1558-2256},
  month={April},}@INPROCEEDINGS{8627111,
  author={Kahvazadeh, Sarang and Masip-Bruin, Xavi and Diaz, Rodrigo and Marín-Tordera, Eva and Jurnet, Alejandro and Garcia, Jordi},
  booktitle={2018 3rd Cloudification of the Internet of Things (CIoT)}, 
  title={Towards An Efficient Key Management and Authentication Strategy for Combined Fog-to-Cloud Continuum Systems}, 
  year={2018},
  volume={},
  number={},
  pages={1-7},
  abstract={Fog-to-cloud systems have emerged as a novel concept intended to improve service performance by considering fog and cloud resources in a coordinated way. In such a heterogeneous scenario, security provisioning becomes necessary, hence novel security solutions must be designed to handle the highly distributed fog-to-cloud nature. In the security area, key distribution and authentication are referred to as two critical pillars for a successful security deployment. Unfortunately, traditional centralized key distribution and authentication approaches do not meet the particularities brought by a Fog-to-cloud system due to its distributed nature. In this paper, we propose a novel distributed key management and authentication (DKMA) strategy to make Fog-to-cloud systems as secure as possible. The paper ends up presenting some results assessing the benefits of the proposed strategy in terms of traffic and delay reduction.},
  keywords={Authentication;Cloud computing;Servers;Proposals;Internet of Things;Elliptic curves;IoT;cloud computing;fog computing;fog-to-cloud computing;security;key distribution and authentication},
  doi={10.1109/CIOT.2018.8627111},
  ISSN={},
  month={July},}@INPROCEEDINGS{8622867,
  author={Souza, Arthur and Cacho, Nélio and Noor, Ayman and Jayaraman, Prem Prakash and Romanovsky, Alexander and Ranjan, Rajiv},
  booktitle={2018 IEEE 20th International Conference on High Performance Computing and Communications; IEEE 16th International Conference on Smart City; IEEE 4th International Conference on Data Science and Systems (HPCC/SmartCity/DSS)}, 
  title={Osmotic Monitoring of Microservices between the Edge and Cloud}, 
  year={2018},
  volume={},
  number={},
  pages={758-765},
  abstract={Osmotic computing is a new IoT application programming paradigm that's driven by the significant increase in resource capacity/capability at the network edge, along with support for data transfer protocols that enable such resources to interact more seamlessly with Cloud-based services. Much of the difficulty in QoS and performance monitoring of IoT applications in an Osmotic computing environment is due to the massive scale and heterogeneity (IoT + Edge + Cloud) of computing environments. To, this end, this work presents an integrated monitoring system for monitoring IoT applications decomposed as microservices and executed in an Osmotic computing environment. A real-world smart parking IoT application is used for an experimental evaluation and for demonstrating the effectiveness of the proposed approach. Through rigorous experimental evaluation, we validate the Osmotic monitoring system ability to holistically identify variation in CPU, memory, and network latency of microservices deployed across Cloud and Edge layers.},
  keywords={Monitoring;Cloud computing;Containers;Internet of Things;Quality of service;Measurement;Computational modeling;cross-layer monitoring, QoS, Edge},
  doi={10.1109/HPCC/SmartCity/DSS.2018.00129},
  ISSN={},
  month={June},}@INPROCEEDINGS{8605756,
  author={Buzachis, Alina and Villari, Massimo},
  booktitle={2018 IEEE/ACM International Conference on Utility and Cloud Computing Companion (UCC Companion)}, 
  title={Basic Principles of Osmotic Computing: Secure and Dependable MicroElements (MELs) Orchestration Leveraging Blockchain Facilities}, 
  year={2018},
  volume={},
  number={},
  pages={47-52},
  abstract={In recent years, the rapid development of Cloud, Edge and Internet of Things (IoT) technologies has accelerated the advancement trends forcing applications and information systems (IS) to evolve. In this new ecosystem, ISs are federated and usually highly distributed becoming complex and very dynamic that have to extend not only through the Cloud/Edge and IoT layers but also the federated organizational boundaries. In this context, Osmotic Computing (OC) is a new paradigm driven by the significant increase in capacity/capability of resources in highly distributed and federated environments, that solves problems related to the deployment, networking and security of microservices called MicroElements (MEL) that are composed and interconnected over Cloud/Edge and IoT infrastructures with specified levels of QoS and security constraints. In this federated collaborative system, each organization needs to have proper administration and security policies to maintain data security while allowing selective sharing of resources. Classical models of access control are not effective in protecting resources while allowing users to access to the resources within their privileges. Blockchain is an underlying technology that could help organizations to improve access control systems through consensus mechanisms, and underlying features of immutability, transparency, auditability, and cryptography. In this work, we propose a MELs orchestration approach through a Software Defined Membrane (SDMem) that leverages Blockchain facilities obeying the osmosis principles.},
  keywords={Blockchain;Cloud computing;Access control;Organizations;Ecosystems;Biological system modeling;Cloud Computing, Edge Computing, IoT, Osmotic Computing, Blockchain, Hyperledger Fabric},
  doi={10.1109/UCC-Companion.2018.00033},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{8599591,
  author={Souza, Arthur and Wen, Zhenyu and Cacho, Nelio and Romanovsky, Alexander and James, Philip and Ranjan, Rajiv},
  booktitle={2018 IEEE 11th Conference on Service-Oriented Computing and Applications (SOCA)}, 
  title={Using Osmotic Services Composition for Dynamic Load Balancing of Smart City Applications}, 
  year={2018},
  volume={},
  number={},
  pages={145-152},
  abstract={Edge computing takes computation away from the Cloud closer to the physical world. Therefore, it reduces the cost of communication bandwidth between IoT devices and the Cloud. However, Edge computing imposes certain limitations in computation power because due to poor hardware capacity of the devices. This restriction may significantly affect the performance of the deployed applications, especially Smart City applications. This limitations also could be aggravated by unpredictable human behaviors wich will easily make the Edge computation node overloaded. Osmotic computing is a new IoT application programming paradigm that provides an opportunity to balance the workload between Edge and Cloud therefore to overcome the load imbalance problem of Smart City applications. To this end, we propose an Osmotic Execution Framework that leverages state-of-the-art microservices techniques to deploy and execute a Smart City application in a distributed environment including Edge and Cloud. Finally, we evaluate load balancing through latency time analysis of our framework with a real-world smart parking application.},
  keywords={Smart cities;Cloud computing;Load management;Computer architecture;Edge computing;Middleware;Sensors;services framework, microservices, osmotic computing, scalability},
  doi={10.1109/SOCA.2018.00029},
  ISSN={2163-2871},
  month={Nov},}@INPROCEEDINGS{8587095,
  author={Pacheco, Alberto and Cano, Pablo and Flores, Ever and Trujillo, Edgar and Marquez, Pedro},
  booktitle={2018 Congreso Internacional de Innovación y Tendencias en Ingeniería (CONIITI)}, 
  title={A Smart Classroom Based on Deep Learning and Osmotic IoT Computing}, 
  year={2018},
  volume={},
  number={},
  pages={1-5},
  abstract={The biggest growth rate of network traffic in the coming years will be for smartphones and Internet-connected devices, which relentless tend to perform increasingly demanding tasks on continuously increasing amounts of data. Machine Learning and Edge Computing are emerging as effective paradigms for processing huge amounts of data supplied by the Internet of Things and Smart Cities. An osmotic computing architecture for an IoT smart classroom is used for testing a deep learning model for person recognition. A comparative performance study and analysis was made by means of selecting a single deep learning model, that it was tried to be adapted to run over the cloud, a fog microserver and a mobile edge computing device. The results obtained shown some promising results and also limitations for the edge and fog computing side that will need to be addressed in order to minimize latencies and achieve real-time responses for the present IoT application.},
  keywords={Performance evaluation;Computational modeling;Computer architecture;Edge computing;Cloud computing;Mobile Edge Computing;Deep Learning;Cloud Computing;Internet of Things;Smart Living;Smart Buildings},
  doi={10.1109/CONIITI.2018.8587095},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{8588117,
  author={Salazar Ch., Gustavo D. and Venegas, Carlos and Baca, Michael and Rodríguez, Ismael and Marrone, Luis},
  booktitle={2018 IEEE 2nd Colombian Conference on Robotics and Automation (CCRA)}, 
  title={Open Middleware proposal for IoT focused on Industry 4.0}, 
  year={2018},
  volume={},
  number={},
  pages={1-6},
  abstract={The arrival of hyper-connectivity and digitization through Cloud/Fog Computing in the productive industry, and together with an adequate analysis and treatment of data generated in this new industrial digital world, are giving rise to the well-known 4th Industrial revolution, with the sole purpose of automating processes more effectively, therefore, new information and communication technologies have a determining role; however, the lack of standardization and unified criteria for the development of cross-cutting platforms are a problem for the proper deployment of IoT, heart of 4th Industrial Revolution. This research raises the possibility of using an MQTT-minded middleware, with MQTT as an on-demand messaging protocol, taking advantage of its native characteristics and benefits in order to achieve an adequate implementation ecosystem for this new paradigm in automation and process controls. A proof-of-concept testbed was developed to support the selection of MQTT as the IoT Middleware protocol proposal; as well as a High-Level Osmotic-type Middleware Architecture solution for the new 21st Century Industry was developed.},
  keywords={Middleware;Protocols;Standards;Loss measurement;Industries;Internet of Things;MQTT;CoAP;IoT;4  th  Industrial Revolution;Open middleware;Cloud/Fog Computing;Osmotic Computing},
  doi={10.1109/CCRA.2018.8588117},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{8591008,
  author={Sosa, Román and Kiraly, Csaba and Parra Rodriguez, Juan D.},
  booktitle={2018 IEEE International Conference on Cloud Computing Technology and Science (CloudCom)}, 
  title={Offloading Execution from Edge to Cloud: A Dynamic Node-RED Based Approach}, 
  year={2018},
  volume={},
  number={},
  pages={149-152},
  abstract={Fog computing enables use cases where data produced in end devices are stored, processed, and acted on directly at the edges of the network, yet computation can be offloaded to more powerful instances through the edge to cloud continuum. Such offloading mechanism is especially needed in case of modern multi-purpose IoT gateways, where both demand and operation conditions can vary largely between deployments. To facilitate the development and operations of gateways, we implement offloading directly as part of the IoT rapid prototyping process embedded in the software stack, based on Node-RED. We evaluate the implemented method using an image processing example, and compare various offloading strategies based on resource consumption and other system metrics, highlighting the differences in handling demand and service levels reached.},
  keywords={Logic gates;Cloud computing;Software;Task analysis;Rapid prototyping;Measurement;Internet of Things;Fog computing, dynamic offloading, Internet of Things, IoT gateways},
  doi={10.1109/CloudCom2018.2018.00039},
  ISSN={2330-2186},
  month={Dec},}@INPROCEEDINGS{8538675,
  author={Filocamo, Basilio and Galletta, Antonino and Fazio, Maria and Ruiz, Javier Alonso and Sotelo, Miguel Ángel and Villari, Massimo},
  booktitle={2018 IEEE Symposium on Computers and Communications (ISCC)}, 
  title={An Innovative Osmotic Computing Framework for Self Adapting City Traffic in Autonomous Vehicle Environment}, 
  year={2018},
  volume={},
  number={},
  pages={01267-01270},
  abstract={In recent years, autonomous driving is becoming a very hot topic for both researchers and car manufacturers. Indeed, around the world new discoveries have been published. In this work we present an innovative Osmotic Computing solution for self adapting city traffic in autonomous vehicle environment. The Vehicular-to-Vehicular (V2V) and Vehicular to Edge-Cloud (V2EC) interactions inside specific areas of the City are considered: the interconnections. The Framework we are creating is able to adapt on a Dynamic Environment where Vehicles, Pedestrians and Physical Infrastructures can interact each other, offering continuous information on interconnections status and city traffic in general.},
  keywords={Automobiles;Urban areas;Autonomous vehicles;Roads;Vehicular ad hoc networks;Computers;Cloud computing;Autonomous Vehicle;Autonomous driving;Osmotic Computing;Cloud Computing;Edge Computing;IoT and Microservices.},
  doi={10.1109/ISCC.2018.8538675},
  ISSN={1530-1346},
  month={June},}@INPROCEEDINGS{8538546,
  author={Villari, Massimo and Galletta, Antonino and Celesti, Antonino and Carnevale, Lorenzo and Fazio, Maria},
  booktitle={2018 IEEE Symposium on Computers and Communications (ISCC)}, 
  title={Osmotic Computing: Software Defined Membranes meet Private/Federated Blockchains}, 
  year={2018},
  volume={},
  number={},
  pages={01292-01297},
  abstract={This paper presents an innovative solution to manage security and trustiness in Osmotic Computing. Osmotic Computing dynamically manages Cloud, Edge and IoT resources across federated environments set up by different and cooperating stakeholders. In this context, the Software Defined Membrane (SDMem) is the main component responsible to orchestrate the osmotic transfer of microelements (MELs) across different environments straightening the security needs of such a complex ecosystem. The basic idea presented in this paper is to leverage Private Blockchain technologies in SDMem implementation over federated systems. Data access activities will be logged in a private distributed Blockchain-based ledger. This will allow to have a certified, non-repudiable record of all the data accessed performed by distributed computing, thus assuring the overall ownership and integrity of data and processes running in MELs. The resulting SDMem solution allow us to isolate data and workflows in distributed environments where heterogeneous resources and devices are exploited.},
  keywords={Bitcoin;Peer-to-peer computing;Software;Distributed databases;Fabrics;Osmotic Computing;Blockchain;federation;microservices},
  doi={10.1109/ISCC.2018.8538546},
  ISSN={1530-1346},
  month={June},}@INPROCEEDINGS{8538714,
  author={Buzachis, Alina and Bernava, Giuseppe Massimo and Busà, Mario and Pioggia, Giovanni and Villari, Massimo},
  booktitle={2018 IEEE Symposium on Computers and Communications (ISCC)}, 
  title={Towards Osmotic Computing: Future Prospect for the Health Information Technology (HIT) Systems of ISASI-CNR (ME)}, 
  year={2018},
  volume={},
  number={},
  pages={01255-01260},
  abstract={During the last decade, the healthcare topic has moved on the top of the development agenda not only for private organizations but also for public administrations. The information technology advances in the healthcare sector have designed an innovative model, the so-called eHealth, that leverages the Cloud Computing paradigm. Even more, with the medical devices (seen as IoT devices) proliferation, there have been introduced new challenges for the Cloud-IoT centric infrastructure. In this context, traditional Health Information Technology (HIT) systems present several limitations, such as scalability, faulttolerance, interoperability, data management and so on. Starting from the experience reported at ISASI-CNR (ME), a healthcare and research center, in this paper, we motivate the need to move the traditional HIT systems into innovative infrastructures based on the Osmotic Computing paradigm. In particular, we introduce two real uses cases, Ataxia and Dyslexia projects.},
  keywords={Electronic healthcare;Cloud computing;Organizations;Information technology;Computational modeling;Interoperability;eHealth;HIT systems;Osmotic Computing;IoT;Cloud Computing;Edge Computing},
  doi={10.1109/ISCC.2018.8538714},
  ISSN={1530-1346},
  month={June},}@INPROCEEDINGS{8537865,
  author={Buzachis, Alina and Bernava, Giuseppe Massimo and Busa, Mario and Pioggia, Giovanni and Villari, Massimo},
  booktitle={2018 IEEE 4th International Conference on Collaboration and Internet Computing (CIC)}, 
  title={Towards the Basic Principles of Osmotic Computing: A Closed-Loop Gamified Cognitive Rehabilitation Flow Model}, 
  year={2018},
  volume={},
  number={},
  pages={446-452},
  abstract={The Internet of Medical Things (IoMT) is a sweeping revolution in the healthcare industry, with IoT quickly establishing itself as a critical part of modern healthcare. The rapid proliferation of such IoMT devices can bring limitations to the current Cloud-IoT centric infrastructures which are not designed to handle huge volumes and velocity of data generated. To address this problem, it is necessary to revisit the network architecture, pushing some data, processing and services directly on the edge nodes of the network where the data originates, away from the centralized Cloud. In this context, Osmotic Computing (OC) aims to provide a new paradigm for the integration between a centralized Cloud layer and Edge/IoT layers. The deployment and migration strategies through the Cloud and Edge layers depend on the infrastructures and applications requirements. This scientific work promotes the basic principles behind the OC paradigm and proposes a closed-loop OC flow model applied to a gamified cognitive rehabilitation use case. Moreover, the use case introduces the development of a customized virtual reality system based on a serious game which allows the patient to carry out physical and cognitive rehabilitation therapies using a natural user interface based on Microsoft Kinect. eas.},
  keywords={Medical services;Cloud computing;Internet of Things;Games;Computational modeling;Solid modeling;osmotic-computing;cloud-computing;edge-computing;healthcare;IoMT;serious-games;gamification},
  doi={10.1109/CIC.2018.00067},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{8537855,
  author={Longo, Antonella and De Matteis, Andrea and Zappatore, Marco},
  booktitle={2018 IEEE 4th International Conference on Collaboration and Internet Computing (CIC)}, 
  title={Urban Pollution Monitoring Based on Mobile Crowd Sensing: An Osmotic Computing Approach}, 
  year={2018},
  volume={},
  number={},
  pages={380-387},
  abstract={Traditional urban pollution monitoring systems suffer of the sole presence of fixed stations. Data gathered from such devices are precise, thanks to the equipment quality and to established and robust measuring protocols, but these sampled data are located in very limited areas and collected by discontinuous monitoring campaigns. The spread of mobile technologies has fostered the development of new approaches like Mobile Crowd Sensing (MCS), offering the chance of using mobile devices, even personal ones, as sensors of urban data. Nevertheless, one of the open challenges is the management of the integration of heterogeneous data flows, different from types, technical specifications (e.g. diverse transmission protocols) and semantics. Osmotic computing aims at creating an abstract level between the mobile devices and the cloud, enabling opportunistic filtering and the addition of metadata for improving the data processing flow. This work focuses on the design and the development of the middleware which integrates data coming from mobile and IoT devices specifically deployed in urban contexts using the Osmotic Computing paradigm.},
  keywords={Sensors;Cloud computing;Monitoring;Middleware;Urban areas;Edge computing;Computer architecture;Mobile Crowd Sensing, Osmotic Computing, Service Oriented Architecture, Smart Cities},
  doi={10.1109/CIC.2018.00057},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{8537849,
  author={Oyekanlu, Emmanuel},
  booktitle={2018 IEEE 4th International Conference on Collaboration and Internet Computing (CIC)}, 
  title={Osmotic Collaborative Computing for Machine Learning and Cybersecurity Applications in Industrial IoT Networks and Cyber Physical Systems with Gaussian Mixture Models}, 
  year={2018},
  volume={},
  number={},
  pages={326-335},
  abstract={To implement machine learning algorithms and other useful algorithms in industrial Internet of Things (IIoT), new computing approaches are needed to prevent costs associated with having to install state of the art edge analytic devices. A suitable approach may include collaborative edge computing using available, resource-constrained IoT edge analytic hardware. In this paper, collaborative computing method is used to construct a popular and very useful waveform for IoT analytics, the Gaussian Mixture Model (GMM). GMM parameters are learned in the cloud, but the GMMs are constructed at the IIoT edge layer. GMMs are constructed using C28x, a ubiquitous, low-cost, embedded digital signal processor (DSP) that is widely available in many pre-existing IIoT infrastructures and in many edge analytic devices. Several GMMs including 2-GMM and 3-GMMs are constructed using the C28x DSP and Embedded C to show that GMM designs could be achieved in form of an osmotic microservice from the IIoT edge to the IIoT fog layer. Designed GMMs are evaluated using their differential and zero-crossings and are found to satisfy important waveform design criteria. At the fog layer, constructed GMMs are then applied for novelty detection, an IIoT cybersecurity and fault-monitoring application and are found to be able to detect anomalies in IIoT machine data using Hampel identifier, 3-Sigma rule, and the Boxplot rule. The osmotic collaborative computing method advocated in this paper will be crucial in ensuring the possibility of shifting many complex applications such as novelty detection and other machine learning based cybersecurity applications to edges of large scale IoT networks using low-cost widely available DSPs.},
  keywords={Hardware;Collaboration;Image edge detection;Software;Edge computing;Machine learning;osmotic computing, collaborative computing gaussian mixture model, embedded systems, machine learning, algorithms, hardware},
  doi={10.1109/CIC.2018.00051},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{8527474,
  author={Oyekanlu, Emmanuel},
  booktitle={2018 IEEE First International Conference on Artificial Intelligence and Knowledge Engineering (AIKE)}, 
  title={Distributed Osmotic Computing Approach to Implementation of Explainable Predictive Deep Learning at Industrial IoT Network Edges with Real-Time Adaptive Wavelet Graphs}, 
  year={2018},
  volume={},
  number={},
  pages={179-188},
  abstract={Challenges associated with developing analytics solutions at the edge of large scale Industrial Internet of Things (IIoT) networks close to where data is being generated in most cases involves developing analytics solutions from ground up. However, this approach increases IoT development costs and system complexities, delay time to market, and ultimately lowers competitive advantages associated with delivering next-generation IoT designs. To overcome these challenges, existing, widely available, hardware can be utilized to successfully participate in distributed edge computing for IIoT systems. In this paper, an osmotic computing approach is used to illustrate how distributed osmotic computing and existing low-cost hardware may be utilized to solve complex, compute-intensive Explainable Artificial Intelligence (XAI) deep learning problem from the edge, through the fog, to the network cloud layer of IIoT systems. At the edge layer, the C28x digital signal processor (DSP), an existing low-cost, embedded, real-time DSP that has very wide deployment and integration in several IoT industries is used as a case study for constructing real-time graph-based Coiflet wavelets that could be used for several analytic applications including deep learning pre-processing applications at the edge and fog layers of IIoT networks. Our implementation is the first known application of the fixed-point C28x DSP to construct Coiflet wavelets. Coiflet Wavelets are constructed in the form of an osmotic microservice, using embedded low-level machine language to program the C28x at the network edge. With the graph-based approach, it is shown that an entire Coiflet wavelet distribution could be generated from only one wavelet stored in the C28x based edge device, and this could lead to significant savings in memory at the edge of IoT networks. Pearson correlation coefficient is used to select an edge generated Coiflet wavelet and the selected wavelet is used at the fog layer for pre-processing and denoising IIoT data to improve data quality for fog layer based deep learning application. Parameters for implementing deep learning at the fog layer using LSTM networks have been determined in the cloud. For XAI, communication network noise is shown to have significant impact on results of predictive deep learning at IIoT network fog layer.},
  keywords={Hardware;Wavelet analysis;Cloud computing;Logic gates;Real-time systems;Explainable Artificial Intelligence;Deep Learning;Real-Time;Industrial IoT;Wavelet Graph;Data Quality;Distributed Computing},
  doi={10.1109/AIKE.2018.00042},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{8418107,
  author={Carnevale, Lorenzo and Celesti, Antonio and Galletta, Antonino and Dustdar, Schahram and Villari, Massimo},
  booktitle={2018 32nd International Conference on Advanced Information Networking and Applications Workshops (WAINA)}, 
  title={From the Cloud to Edge and IoT: a Smart Orchestration Architecture for Enabling Osmotic Computing}, 
  year={2018},
  volume={},
  number={},
  pages={419-424},
  abstract={The latest technological and conceptual developments have destroyed the centralized Cloud Computing model, moving Cloud services in emerging ICT infrastructures such as Edge, Fog and Internet of Things (IoT) that are closer to end users. Specifically, current Cloud computing programming models and resource orchestration techniques are challenged by the recent evolution of the IoT phenomenon because smart devices are becoming more and more pervasive, powerful and inexpensive. Therefore, services need to be place near such devices. In this regard, the Osmotic Computing aims to provide a new computing paradigm based on the deployment and migration strategies related to the infrastructures and applications requirements across Cloud, Edge, Fog an IoT layers. In this scientific paper, we investigate the Smart Orchestration of a new software abstraction called MicroELement (MEL), that encapsulates resources, services and data necessary to run IoT applications. Several use cases are presented for describing the Artificial Intelligence processes that enables the MELs deployment.},
  keywords={Cloud computing;Computer architecture;Computational modeling;Containers;Quality of service;Internet of Things;Osmotic Computing;Edge Computing;Cloud Computing;IoT;Orchestration;Elasticity;Artificial Intelligence},
  doi={10.1109/WAINA.2018.00122},
  ISSN={},
  month={May},}@INPROCEEDINGS{8358729,
  author={Buzachis, Alina and Galletta, Antonino and Carnevale, Lorenzo and Celesti, Antonio and Fazio, Maria and Villari, Massimo},
  booktitle={2018 IEEE 2nd International Conference on Fog and Edge Computing (ICFEC)}, 
  title={Towards Osmotic Computing: Analyzing Overlay Network Solutions to Optimize the Deployment of Container-Based Microservices in Fog, Edge and IoT Environments}, 
  year={2018},
  volume={},
  number={},
  pages={1-10},
  abstract={In recent years, the rapid growth of new Cloud technologies acted as an enabling factor for the adoption of microservices based architecture that leverages container virtualization in order to build modular and robust systems. As the number of containers running on hosts increases, it becomes essential to have tools to manage them in a simple, straightforward manner and with a high level of abstraction. Osmotic Computing is an emerging research field that studies the migration, deployment and optimization of microservices from the Cloud to Fog, Edge, and Internet of Things (IoT) environments. However, in order to achieve Osmotic Computing environments, connectivity issues have to be addressed. This paper investigates these connectivity issues leveraging different network overlays. In particular, we analyze the performance of four network overlays that are OVN, Calico, Weave, and Flannel. Our results give a concrete overview in terms of overhead and performances for each proposed overlay solution, helping us to understand which the best overlay solution is. Specifically, we deployed CoAP and FTP microservices which helped us to carry out these benchmarks and collect the results in terms of transfer times.},
  keywords={Cloud computing;Containers;Internet of Things;Computer architecture;Edge computing;Ecosystems},
  doi={10.1109/CFEC.2018.8358729},
  ISSN={},
  month={May},}@ARTICLE{8354707,
  author={Rausch, Thomas and Dustdar, Schahram and Ranjan, Rajiv},
  journal={IEEE Cloud Computing}, 
  title={Osmotic Message-Oriented Middleware for the Internet of Things}, 
  year={2018},
  volume={5},
  number={2},
  pages={17-25},
  abstract={Message-oriented middleware is a key technology in today's Internet of Things (IoT). Centralized message brokers facilitate decoupled device-to-device communication and can transparently scale to handle many millions of messages per second. However, Cloud-based solutions, such as AWS IoT or Azure IoT Hub, are challenged to satisfy the stringent Quality of Service (QoS) and privacy requirements of many modern IoT scenarios. Such scenarios are complex because they are not only distributed, but dynamic, as elements physically move, fail, and/or (dis-)connect to/from the network. Instead, distributed middleware needs to leverage the everincreasing amount of resources at the edge of the network to provide reliable, ultra-low-latency, and privacy-aware message routing. But the heterogeneity and volatility inherent to Edge resources, and the unpredictability of mobile clients, make it extremely challenging to provide resilient coordination mechanisms and guaranteed message delivery. Applying Osmotic Computing principles to message-oriented middleware opens new opportunities for solving these challenges.},
  keywords={Cloud computing;Logic gates;Quality of service;Protocols;Routing;Method of moments;Cloud Computing;iot;message oriented middleware;internet of things;osmotic computing},
  doi={10.1109/MCC.2018.022171663},
  ISSN={2325-6095},
  month={Mar},}@INPROCEEDINGS{8345538,
  author={Maksimović, Mirjana},
  booktitle={2018 17th International Symposium INFOTEH-JAHORINA (INFOTEH)}, 
  title={The role of Osmotic computing in Internet of Things}, 
  year={2018},
  volume={},
  number={},
  pages={1-4},
  abstract={The evolution of the Internet of Things (IoT) considerably increases number, type and range of smart Internet-enabled devices that provide the connection of anyone, anywhere, anyhow, and anytime, therefore revolutionizing almost every aspect of our lives (e.g., education, healthcare, industry, transport, agriculture, etc.). The Internet-aware devices produce rapidly increased IoT data volumes what implies necessity for efficient execution of IoT data management tasks. Alongside well-known concepts of Cloud, Fog and Edge computing, a term Osmotic computing appears as a support for efficient execution of IoT services and applications across different computing infrastructures. This paper introduces basic principles of Osmotic computing and analyzes its significance in the IoT vision. Therefore, the main benefits as well as challenges for the Osmotic computing utilization in IoT have been discussed.},
  keywords={Cloud computing;Edge computing;Internet of Things;Task analysis;Servers;Resource management;Osmotic computing;Internet of Things (IoT);Cloud computing;Fog computing;Edge computing},
  doi={10.1109/INFOTEH.2018.8345538},
  ISSN={},
  month={March},}@ARTICLE{8306912,
  author={Vaidyanathan, Kaushik and Morris, Daniel H. and Avci, Uygar E. and Liu, Huichu and Karnik, Tanay and Wang, Hong and Young, Ian A.},
  journal={IEEE Journal on Exploratory Solid-State Computational Devices and Circuits}, 
  title={Improving Energy Efficiency of Low-Voltage Logic by Technology-Driven Design}, 
  year={2018},
  volume={4},
  number={1},
  pages={10-18},
  abstract={Reducing  $V_{\mathbf {DD}}$  while keeping leakage current low is critical for minimizing energy consumption for systems across the compute-continuum, especially in IoT. Emerging low- $V_{\mathbf {DD}}$  logic devices such as tunnel FET (TFETs) offer better low- $V_{\mathbf {DD}}$  performance than conventional MOSFETs but lack performance at high- $V_{\mathbf {DD}}$ . To assess TFETs, and other transistors optimized for low- $V_{\mathbf {DD}}$  operation, we propose a technology-driven design framework. Our framework adapts standard industry flows and tools to optimize the design of logic blocks with full consideration of the tradeoffs possible with the future generation device  $I$ – $V$  characteristics and interconnect. Proposed approach optimizes design implementation to improve projected power-performance and area, as well as, expected accuracy of the projections. TFET improves energy efficiency by 2.35 $\times$  and 1.35 $\times$  over MOSFET at low- and high-performance points, respectively, for industrial design test cases. Accuracy of the energy efficiency and performance projections is improved by 71% and 40%, respectively.},
  keywords={TFETs;MOSFET;Integrated circuit modeling;Performance evaluation;Logic gates;Integrated circuit interconnections;Internet of Things;Cell library;circuit-device interaction;interconnect;Internet of Things (IoT);synthesis;tunnel FETs (TFETs)},
  doi={10.1109/JXCDC.2018.2812242},
  ISSN={2329-9231},
  month={June},}@INPROCEEDINGS{8281912,
  author={Okafor, K. C. and Ugwoke, F. N. and Obayi, A. A.},
  booktitle={2017 IEEE 3rd International Conference on Electro-Technology for National Development (NIGERCON)}, 
  title={Evaluation of virtualized osmotic cloud network using discrete event Branch-and-Bound heuristics}, 
  year={2017},
  volume={},
  number={},
  pages={425-437},
  abstract={During heavy traffic transactions on a network, there is an extreme impact on network resources such as bare metals, routers, I/Os, enterprise applications and services. The arrival rates usually exceed service rates despite Ethernet TCP windowing and layer-3 fair queuing. This is unacceptable in Osmotic computing paradigm which houses machine to machine cloud elasticity especially for IoT plug and play edge devices. This research proposes Fog and server consolidation (SC) in distributed high performance data centers (D-HPDCs) as a middleware solution to solve the problem. A candidate scheme called green virtualization is used to share the capabilities of physical servers (bare metals) by splitting resources among operating systems that host an on-demand smart grid application. AType-I virtual machine hypervisor is used to mitigate the various pitfalls in legacy datacenters (DCs) such as resource availability, query response time, scalability and network quality of service (QoS). MATLAB SimEvent simulation is used to realize a case-based Branch-and-Bound heuristics as an optimization scheme in the green virtualized DC. Within the elasticity zone, performance evaluation between Type-I virtualized and non-virtualized DC is carried out. The benefits of virtualized DCs using cloud elasticity design framework is highlighted. The results showed that the Type-1 virtualized DC scenario had better QoS performance metrics compared with the non-virtualized DC. Consequently, SC using virtualization is shown to be efficient for supporting multi-constrained DC environments.},
  keywords={Cloud computing;Elasticity;Servers;Virtualization;Virtual machine monitors;Quality of service;Data centers;Cloud Visualization;Large Scale Data centers;Discrete Event Simulation;Optimization;Heuristics},
  doi={10.1109/NIGERCON.2017.8281912},
  ISSN={2377-2697},
  month={Nov},}@ARTICLE{8260823,
  author={Morshed, Ahsan and Jayaraman, Prem Prakash and Sellis, Timos and Georgakopoulos, Dimitrios and Villari, Massimo and Ranjan, Rajiv},
  journal={IEEE Cloud Computing}, 
  title={Deep Osmosis: Holistic Distributed Deep Learning in Osmotic Computing}, 
  year={2017},
  volume={4},
  number={6},
  pages={22-32},
  abstract={Emerging availability (and varying complexity and types) of Internet of Things (IoT) devices, along with large data volumes that such devices (can potentially) generate, can have a significant impact on our lives, fuelling the development of critical next-generation services and applications in a variety of application domains (e.g. healthcare, smart grids, finance, disaster management, agriculture, transportation and water management). Deep learning technology, which has in the past been used successfully in computer vision and language modelling is now finding application in new domains driven by availability of diverse and large datasets. One such example is the advances in medical diagnostics and prediction by using Deep Learning technologies to improve human health. However, transferring large data streams (a requirement of Deep Learning technologies for achieving high accuracy) to centralised locations such as Cloud datacentre environments, in a timely and reliable manner, is being seen as a key limitation of expanding the application horizons of such technologies. To this end, various paradigms, including Osmotic Computing, have been proposed that promotes distribution of data analysis tasks across Cloud and Edge computing environments. However, these existing paradigms fail to provide a detailed account of how technologies such as deep learning can be orchestrated and take advantage of the cloud, edge and mobile edge environments in a holistic manner. In other words, the focus of this Blue Skies piece is to analyze the research challenges involved with developing a new class of holistic distributed deep learning algorithms that are “resource and data aware”, and which are able to account for underlying heterogeneous data and data models, resource (cloud vs. edge vs. mobile edge) models and data availability while executing – trading accuracy for execution time, etc.},
  keywords={Machine learning;Cloud computing;Computational modeling;Data models;Biological system modeling;Mobile communication;Distributed databases;deep learning;osmosis;holistic;cloud IoT;distributed},
  doi={10.1109/MCC.2018.1081070},
  ISSN={2325-6095},
  month={November},}@ARTICLE{7912282,
  author={Nardelli, Matteo and Nastic, Stefan and Dustdar, Schahram and Villari, Massimo and Ranjan, Rajiv},
  journal={IEEE Cloud Computing}, 
  title={Osmotic Flow: Osmotic Computing + IoT Workflow}, 
  year={2017},
  volume={4},
  number={2},
  pages={68-75},
  abstract={The rapid evolution of Internet of Things (IoT) devices (e.g., sensors and gateways) and the almost ubiquitous connectivity (e.g., 4G, Wi-Fi, RFID/NFC, Bluetooth, IEEE 802.15.4) are forcing us to radically rethink how to effectively deal with massive volume, velocity, and variety of big data produced by such IoT devices. There are currently 6.4 billion IoT devices in use around the world and their number, capabilities, as well as the scope of their use, keeps growing rapidly.},
  keywords={Data models;Computational modeling;Data analysis;Analytical models;Cloud computing;Intelligent sensors;cloud;blue skies;Internet of Things (IoT);Osmotic Flow;data transformation;edge computing},
  doi={10.1109/MCC.2017.22},
  ISSN={2325-6095},
  month={March},}@ARTICLE{7901470,
  author={Chiang, Mung and Ha, Sangtae and Risso, Fulvio and Zhang, Tao and Chih-Lin, I.},
  journal={IEEE Communications Magazine}, 
  title={Clarifying Fog Computing and Networking: 10 Questions and Answers}, 
  year={2017},
  volume={55},
  number={4},
  pages={18-20},
  abstract={Fog computing is an end-to-end horizontal architecture that distributes computing, storage, control, and networking functions closer to users along the cloud-to-thing continuum. The word “edge” may carry different meanings. A common usage of the term refers to the edge network as opposed to the core network, with equipment such as edge routers, base stations, and home gateways. In that sense, there are several differences between fog and edge. First, fog is inclusive of cloud, core, metro, edge, clients, and things. The fog architecture will further enable pooling, orchestrating, managing, and securing the resources and functions distributed in the cloud, anywhere along the cloud-to-thing continuum, and on the things to support end-to-end services and applications. Second, fog seeks to realize a seamless continuum of computing services from the cloud to the things rather than treating the network edges as isolated computing platforms. Third, fog envisions a horizontal platform that will support the common fog computing functions for multiple industries and application domains, including but not limited to traditional telco services. Fourth, a dominant part of edge is mobile edge, whereas the fog computing architecture will be flexible enough to work over wireline as well as wireless networks. },
  keywords={Edge computing;Computer architecture;Cloud computing;Network security;Standards;Cyber-physical systems},
  doi={10.1109/MCOM.2017.7901470},
  ISSN={1558-1896},
  month={April},}@ARTICLE{7883896,
  author={Sharma, Vishal and You, Ilsun and Kumar, Ravinder and Kim, Pankoo},
  journal={IEEE Access}, 
  title={Computational Offloading for Efficient Trust Management in Pervasive Online Social Networks Using Osmotic Computing}, 
  year={2017},
  volume={5},
  number={},
  pages={5084-5103},
  abstract={Pervasive social networking (PSN) aims at bridging the gap between the services and users by providing a platform for social communication irrespective of the time and location. With the advent of a new era of high-speed telecommunication services, mobile users have evolved to a large extent demanding secure, private, and trustworthy services. Online social networks have evolved as pervasive online social networks (POSNs), which uses a common platform to connect users from hybrid applications. Trust has always been a concern for these networks. However, existing approaches tend to provide application-specific trust management, thus resulting in the cost of excessive network resource utilization and high computations. In this paper, a pervasive trust management framework is presented for POSNs, which is capable of generating high trust value between the users with a lower cost of monitoring. The proposed approach uses a flexible mixture model to develop the system around six different properties, and then utilizes the concept of osmotic computing to perform computational offloading, which reduces the number of computations as well as computational time. The novel concepts of lock door policy and intermediate state management procedure are used to allow trust visualization by providing efficient identification of trustworthy and untrustworthy users. The proposed approach is capable of predicting user ratings efficiently with extremely low errors, which are in the range of ±2. The effectiveness of the proposed approach is demonstrated using theoretical and numerical analyses along with data set-based simulations.},
  keywords={Social network services;Monitoring;Mobile communication;Peer-to-peer computing;Mixture models;Reliability;Mathematical model;Pervasive social networks;online social networks;trust management;osmotic computing;trust visualization},
  doi={10.1109/ACCESS.2017.2683159},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{7876215,
  author={Carrega, A. and Repetto, M.},
  booktitle={2017 International Conference on Computing, Networking and Communications (ICNC)}, 
  title={A network-centric architecture for building the cloud continuum}, 
  year={2017},
  volume={},
  number={},
  pages={701-705},
  abstract={The growing interest in distributed, context-aware and data-sensitive applications is pushing the evolution of computing infrastructures from centralized to distributed models, which could effectively tackle the execution of complex software frameworks over geographical scale. The concept of cloud continuum that extends computing infrastructures beyond the data center boundary will require new architectural paradigms that overcome the evident limitations intrinsic in mere cloud federation and that enable effective and efficient interaction between the cloud and the physical environment. In this paper, we discuss why and how telecommunication networks could be the most effective infrastructure to create a distributed, pervasive, carrier-grade cloud continuum, by acting as the core federation paradigm for the dynamic and flexible composition of data centers, networks and IoT platforms.},
  keywords={},
  doi={10.1109/ICCNC.2017.7876215},
  ISSN={},
  month={Jan},}@ARTICLE{7802525,
  author={Villari, Massimo and Fazio, Maria and Dustdar, Schahram and Rana, Omer and Ranjan, Rajiv},
  journal={IEEE Cloud Computing}, 
  title={Osmotic Computing: A New Paradigm for Edge/Cloud Integration}, 
  year={2016},
  volume={3},
  number={6},
  pages={76-83},
  abstract={Osmotic computing is a new paradigm to support the efficient execution of Internet of Things (IoT) services and applications at the network edge. This paradigm is founded on the need for a holistic distributed system abstraction enabling the deployment of lightweight microservices on resource-constrained IoT platforms at the network edge, coupled with more complex microservices running on large-scale datacenters. This paradigm is driven by the significant increase in resource capacity/capability at the network edge, along with support for data transfer protocols that enable such resources to interact more seamlessly with datacenter-based services. This installment of "Blue Skies" discusses osmotic computing features, challenges, and future directions.},
  keywords={Cloud computing;Internet of Things;Quality of service;Computational modeling;Edge computing;Containers;Adaptation models;cloud computing;Internet of Things;edge computing;edge cloud integration},
  doi={10.1109/MCC.2016.124},
  ISSN={2325-6095},
  month={Nov},}@INPROCEEDINGS{6651872,
  author={Barton, John D.},
  booktitle={2013 IEEE International Test Conference (ITC)}, 
  title={Keynote address wednesday: Compute continuum and the nonlinear validation challenge}, 
  year={2013},
  volume={},
  number={},
  pages={9-9},
  abstract={Summary form only given. Intel architecture scales from Exa-scale computing to hand-held and deeply embedded devices. A consistent architecture spanning many product domains brings benefits to silicon and product developers. But it also creates a validation challenge that is nonlinear in nature due to the differences in product complexity, use cases, and user expectations. In this talk, John will address how Intel views the reliability/resilience of large scale systems, how we test for user experience that might help users decide what is good for them, how we attempt to balance all the conflicting validation requirements in today's rapidly evolving landscape spanning consumption devices with short life spans to enterprise applications with very high uptime and reliability expectations. In addition, he will comment on the developments in formal methods and their applicability to large-scale commercial validation/verification efforts.},
  keywords={},
  doi={10.1109/TEST.2013.6651872},
  ISSN={2378-2250},
  month={Sep.},}@INPROCEEDINGS{6874276,
  author={Quinn, Geoffrey S. and Visintini, Fabio and Niemann, K.Olaf},
  booktitle={2012 4th Workshop on Hyperspectral Image and Signal Processing: Evolution in Remote Sensing (WHISPERS)}, 
  title={Considering the implications of species on pigment estimation from leaf spectroscopy}, 
  year={2012},
  volume={},
  number={},
  pages={1-4},
  abstract={Foliar pigment concentrations have the potential to provide information regarding the physiological status of vegetation. Since foliar pigments cause wavelength specific absorption, these spectral regions and metrics derived there from, have been applied to estimate pigment concentrations. Some literature suggests that foliar attributes not related to chlorophyll concentrations influence the reflectance-pigment relationship. To investigate the appropriateness of these relationships across species with different pigment types and potentially different mesophyll cell structure, a dataset was collected throughout fall senescence. This dataset provided a wide range of pigment levels for five dissimilar tree species. Regression models were generated and compared. This data determined that the widely applied red edge position is sensitive to different tree species. Not only were different model coefficients found but occasionally different functions. The continuum removed and depth normalized left area appears to be a more robust alternative to REP for estimating chlorophyll.},
  keywords={Pigments;Reflectivity;Measurement;Absorption;Hyperspectral imaging;Spectroscopy;chlorophyll;red edge;continuum removal},
  doi={10.1109/WHISPERS.2012.6874276},
  ISSN={2158-6276},
  month={June},}@INPROCEEDINGS{5751502,
  author={Ilderem, Vida},
  booktitle={2010 IEEE/ACM/IFIP International Conference on Hardware/Software Codesign and System Synthesis (CODES+ISSS)}, 
  title={Embedded market: Challenges and opportunities}, 
  year={2010},
  volume={},
  number={},
  pages={1-1},
  abstract={There is a convergence trend in the computing, communication and consumer markets and with a forecast of an additional 1 billion connected computing users by 2015, it is of high value to provide a common experience between the devices. Intel's vision of Compute Continuum will enable the users to realize the potential of a seamless cross-device experience with more consistency and accessibility to their information. The convergence trend and the Compute Continuum make System-on-Chip [SoC] a key ingredient for the embedded markets. At Intel Labs, we are focusing on delivering differentiating technology solutions to enable our business partners to successfully capture their targeted market segments. We are working on a variety of research that will enable modular system architecture and silicon technology breakthroughs for rapid customization and integration facilitating faster time-to-market. Intel's vision along with some technology challenges and possible solutions will be highlighted.},
  keywords={System-on-a-chip;Convergence;Focusing;Silicon;Computer architecture;Business;Hardware;Compute Continuum;System-on-a-Chip},
  doi={10.1145/1878961.1878963},
  ISSN={},
  month={Oct},}@ARTICLE{10375689,
  author={Wei, Hung-Yu and Zhang, Tao and Hsing, T. Russell and Zuckerman, Doug},
  journal={IEEE Communications Magazine}, 
  title={Future Trends in Fog/Edge Computing and Networking}, 
  year={2023},
  volume={61},
  number={12},
  pages={38-39},
  abstract={Fog/edge computing and networking offers flexible operational capabilities across the thing-to-cloud continuum, catering to a variety of applications with low-latency requirements and enhanced data privacy. These fog/edge technologies are set to play pivotal roles in future computing systems and 6G wireless communications. They have also demonstrated substantial potential for integration with Machine Learning (ML) technologies. ML can enable smart fogedge computing, while fog/edge infrastructures can also support low-latency ML-based applications.},
  keywords={Special issues and sections;Edge computing;Cloud computing;Machine learning;Low latency communication},
  doi={10.1109/MCOM.2023.10375689},
  ISSN={1558-1896},
  month={December},}@INPROCEEDINGS{9721344,
  author={Yousif, Mazin},
  booktitle={2021 Cloud Continuum}, 
  title={Column: From the Editor: Welcome to the Continuum}, 
  year={2021},
  volume={},
  number={},
  pages={1-3},
  abstract={It is not an exaggeration to say that cloud computing has become the foundation for all innovations-social, business, technological, financial, and more. It has become the buzzword in every indus-try. I have dealt with many clients, and the first word in their mind is cloud, followed by many questions. They ask, “When can we move our workloads to the cloud?,” or, “What is the complexity and what are the challenges for moving workloads to the cloud?,” or, “Is cloud the foundation for digital transformation?,” or, “Can you help me understand the edge-cloud con-tinuum and where edge and fog play in it?” It is a fact that cloud computing has chartered a path of growth and success.},
  keywords={},
  doi={10.1109/CloudContinuum54760.2021.00001},
  ISSN={},
  month={Nov},}@ARTICLE{9606835,
  author={Zeng, Deze and Ansari, Nirwan and Montpetit, Marie-José and Schooler, Eve M. and Tarchi, Daniele},
  journal={IEEE Network}, 
  title={Guest Editorial: In-Network Computing: Emerging Trends for the Edge-Cloud Continuum}, 
  year={2021},
  volume={35},
  number={5},
  pages={12-13},
  abstract={Recent advances in virtualization technologies (e.g., uniker-nels, containers, and virtual machines), the move to data driven approaches and softwarized networking technologies (e.g., SDN, NFV, and data plane programming) have invigorated a new focus on combining computation and communication in distributed systems. At the same time, the proliferation of edge computing, a complementary and at times alternative solution to centralized cloud computing, has resulted in an edge-cloud continuum of applications and services. Edge computing offers more proximate resources closer to where the service is needed and supports emerging applications (e.g., self-driving vehicles, autonomous systems, and VR/AR) with stringent requirements of fast response, low delay, high bandwidth, trust-sensitivity, and/or continued operation, despite intermittent or incomplete connectivity. These trends have converged into the concept of Computing in the Network (COIN), the integration of in-network computation and network processing in a common framework. COIN naturally fits within the edge-cloud continuum, where expanded resource distribution and tightly integrated computing-networking capabilities are provisioned from the edge to the cloud infrastructure including at points in between.},
  keywords={},
  doi={10.1109/MNET.2021.9606835},
  ISSN={1558-156X},
  month={Sep.},}@INPROCEEDINGS{10185765,
  author={Fortino, Giancarlo},
  booktitle={2023 International Conference on Multimedia Computing, Networking and Applications (MCNA)}, 
  title={Keynote Speech 1: Integrating Machine Learning and Multi-Agent Systems for Fully Enabling Device-Edge-Cloud Continuum in Complex IoT Worlds}, 
  year={2023},
  volume={},
  number={},
  pages={1-1},
  abstract={Recently the device-edge-cloud paradigm is gaining momentum due to the benefits it could provide for the development of highly effective, efficient, and complex IoT ecosystems of diversified scale. However, there are many issues related to unsupervised control aspects that need to be addressed in order to fully realize the approach and make it fully operative in real complex environments. In order to address such issues, in this talk, we propose an holistic integration of machine learning and multi-agent systems to create a data-driven control architecture capable to autonomically monitor and control the device-edge-cloud continuum. This objective is being developed in the context of the Horizon Europe project named MLSysOps (https://mlsysops.eu/). Some use cases will be proposed to elucidate our current findings.},
  keywords={},
  doi={10.1109/MCNA59361.2023.10185765},
  ISSN={},
  month={June},}@ARTICLE{9237349,
  author={Milojicic, Dejan},
  journal={Computer}, 
  title={The Edge-to-Cloud Continuum}, 
  year={2020},
  volume={53},
  number={11},
  pages={16-25},
  abstract={Computer hosts a virtual roundtable with three experts to discuss the opportunities and obstacles regarding edge-to-cloud technology.},
  keywords={Cloud computing;Edge computing},
  doi={10.1109/MC.2020.3007297},
  ISSN={1558-0814},
  month={Nov},}
